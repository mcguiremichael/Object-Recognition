{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from resnet_yolo import resnet50\n",
    "from yolo_loss import YoloLoss\n",
    "from dataset import VocDetectorDataset\n",
    "from eval_voc import evaluate\n",
    "from predict import predict_image\n",
    "from config import VOC_CLASSES, COLORS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO network hyperparameters\n",
    "B = 2  # number of bounding box predictions per cell\n",
    "S = 14  # width/height of network output grid (larger than 7x7 from paper since we use a different network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement Yolo we will rely on a pretrained classifier as the backbone for our detection network. PyTorch offers a variety of models which are pretrained on ImageNet in the [`torchvision.models`](https://pytorch.org/docs/stable/torchvision/models.html) package. In particular, we will use the ResNet50 architecture as a base for our detector. This is different from the base architecture in the Yolo paper and also results in a different output grid size (14x14 instead of 7x7).\n",
    "\n",
    "Models are typically pretrained on ImageNet since the dataset is very large (> 1million images) and widely used. The pretrained model provides a very useful weight initialization for our detector, so that the network is able to learn quickly and effictively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained model\n"
     ]
    }
   ],
   "source": [
    "load_network_path = None\n",
    "pretrained = True\n",
    "\n",
    "# use to load a previously trained network\n",
    "if load_network_path is not None:\n",
    "    print('Loading saved network from {}'.format(load_network_path))\n",
    "    net = resnet50().to(device)\n",
    "    net.load_state_dict(torch.load(load_network_path))\n",
    "else:\n",
    "    print('Load pre-trained model')\n",
    "    net = resnet50(pretrained=pretrained).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Yolo loss component coefficients (as given in Yolo v1 paper)\n",
    "lambda_coord = 5\n",
    "lambda_noobj = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = YoloLoss(S, B, lambda_coord, lambda_noobj)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Pascal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Pascal is a small dataset (5000 in train+val) we have combined the train and val splits to train our detector. This is not typically a good practice, but we will make an exception in this case to be able to get reasonable detection results with a comparatively small object detection dataset.\n",
    "\n",
    "The train dataset loader also using a variety of data augmentation techniques including random shift, scaling, crop, and flips. Data augmentation is slightly more complicated for detection dataset since the bounding box annotations must be kept consistent through the transformations.\n",
    "\n",
    "Since the output of the dector network we train is an SxSx(B*5+C), we use an encoder to convert the original bounding box coordinates into relative grid bounding box coordinates corresponding to the the expected output. We also use a decoder which allows us to convert the opposite direction into image coordinate bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset\n",
      "Loaded 5011 train images\n"
     ]
    }
   ],
   "source": [
    "file_root_train = 'VOCdevkit_2007/VOC2007/JPEGImages/'\n",
    "annotation_file_train = 'voc2007.txt'\n",
    "\n",
    "train_dataset = VocDetectorDataset(root_img_dir=file_root_train,dataset_file=annotation_file_train,train=True, S=S)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "print('Loaded %d train images' % len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset\n",
      "Loaded 4950 test images\n"
     ]
    }
   ],
   "source": [
    "file_root_test = 'VOCdevkit_2007/VOC2007test/JPEGImages/'\n",
    "annotation_file_test = 'voc2007test.txt'\n",
    "\n",
    "test_dataset = VocDetectorDataset(root_img_dir=file_root_test,dataset_file=annotation_file_test,train=False, S=S)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "print('Loaded %d test images' % len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 1 / 50\n",
      "Learning Rate for this epoch: 0.001\n",
      "[130.32976  399.8045    53.38546    6.983316]\n",
      "[116.84744  397.64694   55.863056   5.432756]\n",
      "[104.16557   390.8115     41.25812     4.1775203]\n",
      "[117.62138   371.07217    57.86422     5.5735893]\n",
      "[153.4714   354.92096   75.37401    8.778036]\n",
      "Epoch [1/50], Iter [5/502] Loss: 59.2544, average_loss: 57.0276\n",
      "[105.092476 331.49854   35.727917   5.930462]\n",
      "[128.78607   304.85712    57.0192      6.3410287]\n",
      "[ 80.45647   283.14722    30.569878    4.3683343]\n",
      "[131.66133  256.62082   64.34158    6.655981]\n",
      "[ 78.954895  224.1379     38.423485    3.9347196]\n",
      "Epoch [1/50], Iter [10/502] Loss: 34.5451, average_loss: 50.2991\n",
      "[ 68.55029   197.9098     36.515728    3.1990955]\n",
      "[ 96.26031   175.35289    40.835056    4.3319163]\n",
      "[ 45.814785  152.20897    28.291645    2.6232255]\n",
      "[ 64.629005 132.72334   30.256529   4.550273]\n",
      "[ 98.53529  120.949295  43.737946   4.253804]\n",
      "Epoch [1/50], Iter [15/502] Loss: 26.7476, average_loss: 42.5429\n",
      "[ 97.12025  105.312965  54.980774   4.940464]\n",
      "[78.898865 94.075554 47.132534  3.743638]\n",
      "[108.9912     83.00626    60.194084    4.9184666]\n",
      "[82.97365   73.67194   39.038433   2.8118968]\n",
      "[78.83853   65.80081   29.338428   2.8001645]\n",
      "Epoch [1/50], Iter [20/502] Loss: 17.6778, average_loss: 37.5001\n",
      "[56.649033  58.151825  27.15519    2.8030515]\n",
      "[85.53445  51.340557 50.299225  4.038909]\n",
      "[61.403507  46.0851    22.923702   1.9717087]\n",
      "[76.5903   40.9686   33.241264  3.251437]\n",
      "[117.53431    36.750618   48.66822     4.6514926]\n",
      "Epoch [1/50], Iter [25/502] Loss: 20.7605, average_loss: 33.3202\n",
      "[50.366737  33.312374  43.91584    3.7864666]\n",
      "[45.13739   30.466932  28.402153   2.8118267]\n",
      "[72.70412   27.809048  41.408043   3.5154462]\n",
      "[72.53516   25.559132  39.70017    4.1126385]\n",
      "[52.069893  23.74237   32.38891    3.6136026]\n",
      "Epoch [1/50], Iter [30/502] Loss: 11.1815, average_loss: 29.8913\n",
      "[76.185455 21.941345 60.530807  4.903897]\n",
      "[41.52994   20.696102  30.500538   2.9121978]\n",
      "[86.526855 19.304134 50.23316   6.138692]\n",
      "[51.111664 18.319563 28.483025  2.862037]\n",
      "[79.02209   17.351095  49.71428    3.7856905]\n",
      "Epoch [1/50], Iter [35/502] Loss: 14.9873, average_loss: 27.5413\n",
      "[39.912144  16.564466  34.94312    3.0201256]\n",
      "[107.41405   15.619209  85.15023    7.681014]\n",
      "[80.79083   14.9852495 53.4594     6.6147046]\n",
      "[83.89978   14.434353  27.951536   4.3506637]\n",
      "[61.5574    13.834368  37.18182    3.9597464]\n",
      "Epoch [1/50], Iter [40/502] Loss: 11.6533, average_loss: 25.8819\n",
      "[54.09122   13.315328  35.44418    3.1832669]\n",
      "[58.50945   12.850513  49.618874   3.4824023]\n",
      "[59.879906  12.379021  36.937138   4.4180245]\n",
      "[70.08284  11.960313 41.19359   4.308975]\n",
      "[60.915855  11.606268  48.12168    3.9623322]\n",
      "Epoch [1/50], Iter [45/502] Loss: 12.4606, average_loss: 24.3312\n",
      "[54.342472 11.241118 45.994324  4.182036]\n",
      "[38.448666 10.945403 22.068344  3.464127]\n",
      "[35.661865 10.619744 25.164328  2.823769]\n",
      "[52.648605  10.301104  52.77538    5.0585723]\n",
      "[36.38396   10.0713215 29.340515   3.7064934]\n",
      "Epoch [1/50], Iter [50/502] Loss: 7.9502, average_loss: 22.8286\n",
      "[42.044937  9.795921 40.50614   5.606487]\n",
      "[80.928444   9.469189  72.92891    5.3867173]\n",
      "[57.580925   9.307379  35.38346    6.2517395]\n",
      "[34.480877   9.161208  30.88691    3.1946843]\n",
      "[50.335102   8.917024  33.736496   4.4705005]\n",
      "Epoch [1/50], Iter [55/502] Loss: 9.7459, average_loss: 21.7539\n",
      "[40.686626   8.7485695 28.658056   2.6684783]\n",
      "[25.691303   8.574422  20.879173   3.4503264]\n",
      "[59.87317    8.339534  40.693596   4.3193088]\n",
      "[30.930939  8.223412 29.385014  2.616034]\n",
      "[34.434597   8.0768175 27.496834   4.643091 ]\n",
      "Epoch [1/50], Iter [60/502] Loss: 7.4651, average_loss: 20.6051\n",
      "[30.518316   7.9484086 29.102509   3.0438702]\n",
      "[74.40644    7.739433  34.23147    5.0261884]\n",
      "[54.13895   7.623838 46.00093   4.190853]\n",
      "[33.636677   7.4979267 34.14503    3.9010234]\n",
      "[71.37165   7.351417 39.787895  5.659453]\n",
      "Epoch [1/50], Iter [65/502] Loss: 12.4170, average_loss: 19.8006\n",
      "[64.189224   7.2493973 34.3597     4.994634 ]\n",
      "[50.3458     7.1550612 35.774166   4.8366375]\n",
      "[63.94864    7.014669  54.60122    6.1473966]\n",
      "[62.57486    6.914528  39.001923   6.3619385]\n",
      "[75.79231   6.818435 53.079643  4.935846]\n",
      "Epoch [1/50], Iter [70/502] Loss: 14.0626, average_loss: 19.2378\n",
      "[39.0817     6.7715592 32.093845   3.5502172]\n",
      "[48.000767  6.655562 36.723217  4.274233]\n",
      "[73.432304   6.5434794 33.431763   5.1726556]\n",
      "[40.634914   6.4873443 30.573263   4.0733976]\n",
      "[36.410095   6.418159  24.599745   4.1256623]\n",
      "Epoch [1/50], Iter [75/502] Loss: 7.1554, average_loss: 18.5540\n",
      "[45.690464   6.2951145 51.393528   4.991033 ]\n",
      "[23.725594   6.2594156 18.674536   3.3992054]\n",
      "[36.74822    6.196326  19.851435   4.2595673]\n",
      "[63.301544   6.0614257 46.63746    6.1447315]\n",
      "[25.552761   6.0254283 22.879044   4.66865  ]\n",
      "Epoch [1/50], Iter [80/502] Loss: 5.9126, average_loss: 17.9053\n",
      "[33.39134    5.9432044 31.831686   5.940085 ]\n",
      "[50.709152   5.8813343 28.0762     4.517729 ]\n",
      "[44.877724   5.7946987 45.62597    4.2376156]\n",
      "[41.72945    5.7363024 40.213356   4.5847535]\n",
      "[86.574844   5.6432467 53.558254   6.8296394]\n",
      "Epoch [1/50], Iter [85/502] Loss: 15.2606, average_loss: 17.4541\n",
      "[37.34793    5.635793  24.01192    4.8314295]\n",
      "[54.476254   5.5337663 38.46788    7.3339653]\n",
      "[41.61249    5.5143013 18.896502   3.989762 ]\n",
      "[42.791424   5.4607544 22.893314   3.9320078]\n",
      "[57.670517   5.395683  39.960495   4.6756043]\n",
      "Epoch [1/50], Iter [90/502] Loss: 10.7702, average_loss: 16.9627\n",
      "[58.782745  5.315349 47.64907   7.278782]\n",
      "[35.70551   5.278484 33.22744   5.385599]\n",
      "[26.412233   5.2671323 16.009964   4.0512385]\n",
      "[20.96174    5.2075677 18.478172   4.113058 ]\n",
      "[47.175194   5.13352   32.31597    5.1101017]\n",
      "Epoch [1/50], Iter [95/502] Loss: 8.9735, average_loss: 16.4792\n",
      "[45.00057    5.0930986 31.40581    5.6242275]\n",
      "[34.801132   5.058849  26.54612    5.0090995]\n",
      "[23.812393   5.022484  14.155655   4.7388067]\n",
      "[51.497547   4.9305315 41.396408   6.771093 ]\n",
      "[38.45312    4.9112554 33.266464   4.7550454]\n",
      "Epoch [1/50], Iter [100/502] Loss: 8.1386, average_loss: 16.0475\n",
      "[57.39081   4.870443 35.309578  5.17265 ]\n",
      "[50.981693  4.815758 40.822605  5.34006 ]\n",
      "[28.028568   4.8059063 25.206823   4.2706165]\n",
      "[32.659344   4.7608013 25.888348   4.7267833]\n",
      "[80.07322    4.6916957 40.090824   5.8237634]\n",
      "Epoch [1/50], Iter [105/502] Loss: 13.0680, average_loss: 15.7269\n",
      "[16.349247   4.699783  16.172531   3.0376015]\n",
      "[46.141872   4.6253333 44.57199    4.8562737]\n",
      "[29.07774    4.6056886 22.829008   3.602941 ]\n",
      "[23.882267   4.573951  23.002495   3.5767567]\n",
      "[43.17094    4.5256276 27.522488   4.97272  ]\n",
      "Epoch [1/50], Iter [110/502] Loss: 8.0192, average_loss: 15.3173\n",
      "[39.570877   4.4964905 23.906597   4.320692 ]\n",
      "[21.595802  4.474712 16.927067  4.24582 ]\n",
      "[19.5861     4.4430056 20.146328   3.6045458]\n",
      "[23.994246   4.397371  20.362616   5.5804296]\n",
      "[24.535402   4.360102  32.09948    3.1001928]\n",
      "Epoch [1/50], Iter [115/502] Loss: 6.4095, average_loss: 14.8998\n",
      "[48.001534   4.303153  40.656555   7.5953126]\n",
      "[23.36518    4.3005943 28.042784   3.8493419]\n",
      "[40.31914    4.2448773 32.443306   7.4689326]\n",
      "[41.4235     4.2131343 37.14399    5.9411273]\n",
      "[37.894978   4.196132  24.037937   4.9491034]\n",
      "Epoch [1/50], Iter [120/502] Loss: 7.1078, average_loss: 14.6160\n",
      "[44.200577   4.175972  30.247183   4.6793957]\n",
      "[32.018047  4.141468 24.434301  5.622628]\n",
      "[39.53913    4.098232  31.4447     6.0059094]\n",
      "[35.49964    4.0729604 28.546202   5.895955 ]\n",
      "[42.605995   4.0379353 40.670223   5.560566 ]\n",
      "Epoch [1/50], Iter [125/502] Loss: 9.2875, average_loss: 14.3493\n",
      "[29.609688   4.0343695 22.01373    4.8573914]\n",
      "[45.25016    3.9717517 33.56105    6.85924  ]\n",
      "[57.109528   3.9425757 41.314278   8.35233  ]\n",
      "[37.478516   3.9411838 21.898712   4.427399 ]\n",
      "[32.462936   3.9276576 23.695467   4.6884837]\n",
      "Epoch [1/50], Iter [130/502] Loss: 6.4775, average_loss: 14.1000\n",
      "[31.32506    3.8878558 33.580338   5.1592903]\n",
      "[31.674606   3.8728197 17.210073   4.110022 ]\n",
      "[19.17264    3.8619213 22.557516   3.5937526]\n",
      "[38.68013    3.8157234 28.334251   5.368652 ]\n",
      "[22.481762   3.7995098 17.723492   4.237916 ]\n",
      "Epoch [1/50], Iter [135/502] Loss: 4.8243, average_loss: 13.8033\n",
      "[43.94175    3.7631457 26.081413   6.389563 ]\n",
      "[26.324043   3.7541084 23.217123   4.6793084]\n",
      "[28.812883   3.733923  22.792473   4.2990475]\n",
      "[42.658054   3.6985016 27.947842   6.344022 ]\n",
      "[23.786882   3.6900246 28.065596   3.09202  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [140/502] Loss: 5.8635, average_loss: 13.5511\n",
      "[44.337013   3.6513588 31.83587    7.412561 ]\n",
      "[38.393463   3.6397355 32.426765   4.471245 ]\n",
      "[49.743713   3.6039064 37.39313    5.3660197]\n",
      "[32.965538   3.6015487 24.319304   4.56653  ]\n",
      "[54.507267   3.5586138 39.70413    5.7929134]\n",
      "Epoch [1/50], Iter [145/502] Loss: 10.3563, average_loss: 13.3813\n",
      "[30.089823   3.5680833 23.565063   3.8616295]\n",
      "[40.935856   3.527861  30.6499     6.2028785]\n",
      "[31.082539   3.5128403 23.35329    6.1994123]\n",
      "[41.62277    3.4852793 35.429768   6.142234 ]\n",
      "[30.328262   3.4749699 28.233131   4.995074 ]\n",
      "Epoch [1/50], Iter [150/502] Loss: 6.7031, average_loss: 13.1754\n",
      "[37.50492    3.4576204 24.961002   6.535663 ]\n",
      "[33.837547   3.4444911 17.4099     5.0495424]\n",
      "[35.672688  3.42737  27.53334   4.75581 ]\n",
      "[55.255547   3.3844733 41.517403   5.752062 ]\n",
      "[54.799343   3.360301  40.743515   7.6506715]\n",
      "Epoch [1/50], Iter [155/502] Loss: 10.6554, average_loss: 13.0188\n",
      "[13.796848   3.3867245 14.669651   2.6064932]\n",
      "[33.435707  3.342424 21.494564  5.861949]\n",
      "[18.705587   3.3440297 16.083904   3.270634 ]\n",
      "[17.288315   3.3283503 16.49057    3.9603622]\n",
      "[33.48712    3.2985103 22.12363    6.47573  ]\n",
      "Epoch [1/50], Iter [160/502] Loss: 6.5385, average_loss: 12.7660\n",
      "[39.233147  3.27113  36.179512  5.600529]\n",
      "[20.753677   3.2713373 18.336838   5.6609793]\n",
      "[28.024921   3.2390797 30.013084   6.9564643]\n",
      "[32.51575    3.2346325 24.172207   4.2182436]\n",
      "[28.392315   3.2099173 34.438816   4.303652 ]\n",
      "Epoch [1/50], Iter [165/502] Loss: 7.0345, average_loss: 12.5822\n",
      "[38.377274   3.1888285 33.73736    4.8042316]\n",
      "[22.27898    3.1852677 18.201561   4.3886247]\n",
      "[29.39804    3.1632318 30.694904   4.3849335]\n",
      "[39.09085    3.1473188 23.226023   6.003894 ]\n",
      "[17.529243   3.1449165 13.9301605  3.3368244]\n",
      "Epoch [1/50], Iter [170/502] Loss: 3.7941, average_loss: 12.3917\n",
      "[33.95477    3.1172996 30.305769   5.6266723]\n",
      "[19.212643  3.10974  22.597063  4.379877]\n",
      "[18.56496    3.0979443 17.20936    5.0580134]\n",
      "[20.928213  3.07895  20.254128  4.97488 ]\n",
      "[66.011925   3.0243423 54.990063   7.5503607]\n",
      "Epoch [1/50], Iter [175/502] Loss: 13.1577, average_loss: 12.2360\n",
      "[16.114847   3.0553796 15.92952    3.408128 ]\n",
      "[43.0012     3.0268488 26.188555   4.6971407]\n",
      "[69.829185  2.98547  46.914387  8.374981]\n",
      "[36.82135    2.9947329 29.158054   6.5673757]\n",
      "[26.11583    2.9870963 22.799068   4.7583966]\n",
      "Epoch [1/50], Iter [180/502] Loss: 5.6660, average_loss: 12.1048\n",
      "[40.252907   2.9632766 21.828083   6.1370516]\n",
      "[24.701643   2.953327  20.57079    6.4722133]\n",
      "[32.828552  2.946495 24.927368  4.708082]\n",
      "[26.839708   2.92942   24.484009   5.6437764]\n",
      "[51.19021    2.9105818 32.184155   6.642217 ]\n",
      "Epoch [1/50], Iter [185/502] Loss: 9.2927, average_loss: 11.9637\n",
      "[47.816547   2.8870735 36.82543    7.1756387]\n",
      "[50.751904   2.8688614 37.48928    7.897162 ]\n",
      "[21.202316   2.8841467 23.399948   4.073331 ]\n",
      "[32.774982   2.8439617 43.44318    6.4126773]\n",
      "[33.30339    2.845378  36.47339    6.9594135]\n",
      "Epoch [1/50], Iter [190/502] Loss: 7.9582, average_loss: 11.8648\n",
      "[25.72483    2.8391337 24.715614   6.7626967]\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    \n",
    "    # Update learning rate late in training\n",
    "    if epoch == 30 or epoch == 40:\n",
    "        learning_rate /= 10.0\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate\n",
    "    \n",
    "    print('\\n\\nStarting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "    print('Learning Rate for this epoch: {}'.format(learning_rate))\n",
    "    \n",
    "    total_loss = 0.\n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        images, target = images.to(device), target.to(device)\n",
    "        temp = target.cpu().numpy()\n",
    "        \"\"\"\n",
    "        print(\"classes\", np.max(temp) - np.min(temp))\n",
    "        print(temp.shape)\n",
    "        print(np.sum(temp[0,:,:,:10], axis=2))\n",
    "        print(np.sum(temp[0,:,:,10:], axis=2))\n",
    "        print(target[0].data.shape)\n",
    "        print(torch.max(target[0], 2))\n",
    "        \"\"\"\n",
    "        pred = net(images)\n",
    "        loss = criterion(pred,target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, average_loss: %.4f'\n",
    "                  % (epoch+1, num_epochs, i+1, len(train_loader), loss.item(), total_loss / (i+1)))\n",
    "    \n",
    "    # evaluate the network on the test data\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        net.eval()\n",
    "        for i, (images, target) in enumerate(test_loader):\n",
    "            images, target = images.to(device), target.to(device)\n",
    "\n",
    "            pred = net(images)\n",
    "            loss = criterion(pred,target)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "    \n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        print('Updating best test loss: %.5f' % best_test_loss)\n",
    "        torch.save(net.state_dict(),'best_detector.pth')\n",
    "\n",
    "    torch.save(net.state_dict(),'detector.pth')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "# select random image from test set\n",
    "image_name = random.choice(test_dataset.fnames)\n",
    "image = cv2.imread(os.path.join(file_root_test, image_name))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print('predicting...')\n",
    "result = predict_image(net, image_name, root_img_directory=file_root_test)\n",
    "for left_up, right_bottom, class_name, _, prob in result:\n",
    "    color = COLORS[VOC_CLASSES.index(class_name)]\n",
    "    cv2.rectangle(image, left_up, right_bottom, color, 2)\n",
    "    label = class_name + str(round(prob, 2))\n",
    "    text_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    p1 = (left_up[0], left_up[1] - text_size[1])\n",
    "    cv2.rectangle(image, (p1[0] - 2 // 2, p1[1] - 2 - baseline), (p1[0] + text_size[0], p1[1] + text_size[1]),\n",
    "                  color, -1)\n",
    "    cv2.putText(image, label, (p1[0], p1[1] + baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, 8)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate on Test\n",
    "\n",
    "To evaluate detection results we use mAP (mean of average precision over each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(net, test_dataset_file=annotation_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
