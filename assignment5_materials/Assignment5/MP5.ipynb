{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "from agent import *\n",
    "from model import *\n",
    "from config import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialise our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lifes(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3\n",
    "rewards, episodes = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. \n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigai/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 1.0   memory length: 160   epsilon: 1.0    steps: 160     evaluation reward: 1.0\n",
      "episode: 1   score: 2.0   memory length: 377   epsilon: 1.0    steps: 217     evaluation reward: 1.5\n",
      "episode: 2   score: 2.0   memory length: 594   epsilon: 1.0    steps: 217     evaluation reward: 1.6666666666666667\n",
      "episode: 3   score: 2.0   memory length: 799   epsilon: 1.0    steps: 205     evaluation reward: 1.75\n",
      "episode: 4   score: 2.0   memory length: 1001   epsilon: 1.0    steps: 202     evaluation reward: 1.8\n",
      "episode: 5   score: 0.0   memory length: 1125   epsilon: 1.0    steps: 124     evaluation reward: 1.5\n",
      "episode: 6   score: 0.0   memory length: 1261   epsilon: 1.0    steps: 136     evaluation reward: 1.2857142857142858\n",
      "episode: 7   score: 2.0   memory length: 1464   epsilon: 1.0    steps: 203     evaluation reward: 1.375\n",
      "episode: 8   score: 0.0   memory length: 1599   epsilon: 1.0    steps: 135     evaluation reward: 1.2222222222222223\n",
      "episode: 9   score: 4.0   memory length: 1859   epsilon: 1.0    steps: 260     evaluation reward: 1.5\n",
      "episode: 10   score: 2.0   memory length: 2064   epsilon: 1.0    steps: 205     evaluation reward: 1.5454545454545454\n",
      "episode: 11   score: 1.0   memory length: 2242   epsilon: 1.0    steps: 178     evaluation reward: 1.5\n",
      "episode: 12   score: 2.0   memory length: 2449   epsilon: 1.0    steps: 207     evaluation reward: 1.5384615384615385\n",
      "episode: 13   score: 0.0   memory length: 2589   epsilon: 1.0    steps: 140     evaluation reward: 1.4285714285714286\n",
      "episode: 14   score: 0.0   memory length: 2717   epsilon: 1.0    steps: 128     evaluation reward: 1.3333333333333333\n",
      "episode: 15   score: 0.0   memory length: 2841   epsilon: 1.0    steps: 124     evaluation reward: 1.25\n",
      "episode: 16   score: 2.0   memory length: 3043   epsilon: 1.0    steps: 202     evaluation reward: 1.2941176470588236\n",
      "episode: 17   score: 1.0   memory length: 3222   epsilon: 1.0    steps: 179     evaluation reward: 1.2777777777777777\n",
      "episode: 18   score: 3.0   memory length: 3473   epsilon: 1.0    steps: 251     evaluation reward: 1.368421052631579\n",
      "episode: 19   score: 3.0   memory length: 3709   epsilon: 1.0    steps: 236     evaluation reward: 1.45\n",
      "episode: 20   score: 1.0   memory length: 3882   epsilon: 1.0    steps: 173     evaluation reward: 1.4285714285714286\n",
      "episode: 21   score: 2.0   memory length: 4087   epsilon: 1.0    steps: 205     evaluation reward: 1.4545454545454546\n",
      "episode: 22   score: 0.0   memory length: 4221   epsilon: 1.0    steps: 134     evaluation reward: 1.391304347826087\n",
      "episode: 23   score: 0.0   memory length: 4350   epsilon: 1.0    steps: 129     evaluation reward: 1.3333333333333333\n",
      "episode: 24   score: 0.0   memory length: 4479   epsilon: 1.0    steps: 129     evaluation reward: 1.28\n",
      "episode: 25   score: 0.0   memory length: 4604   epsilon: 1.0    steps: 125     evaluation reward: 1.2307692307692308\n",
      "episode: 26   score: 0.0   memory length: 4733   epsilon: 1.0    steps: 129     evaluation reward: 1.1851851851851851\n",
      "episode: 27   score: 4.0   memory length: 5011   epsilon: 1.0    steps: 278     evaluation reward: 1.2857142857142858\n",
      "episode: 28   score: 3.0   memory length: 5263   epsilon: 1.0    steps: 252     evaluation reward: 1.3448275862068966\n",
      "episode: 29   score: 2.0   memory length: 5466   epsilon: 1.0    steps: 203     evaluation reward: 1.3666666666666667\n",
      "episode: 30   score: 1.0   memory length: 5622   epsilon: 1.0    steps: 156     evaluation reward: 1.3548387096774193\n",
      "episode: 31   score: 1.0   memory length: 5803   epsilon: 1.0    steps: 181     evaluation reward: 1.34375\n",
      "episode: 32   score: 0.0   memory length: 5942   epsilon: 1.0    steps: 139     evaluation reward: 1.303030303030303\n",
      "episode: 33   score: 0.0   memory length: 6070   epsilon: 1.0    steps: 128     evaluation reward: 1.2647058823529411\n",
      "episode: 34   score: 0.0   memory length: 6214   epsilon: 1.0    steps: 144     evaluation reward: 1.2285714285714286\n",
      "episode: 35   score: 3.0   memory length: 6467   epsilon: 1.0    steps: 253     evaluation reward: 1.2777777777777777\n",
      "episode: 36   score: 1.0   memory length: 6640   epsilon: 1.0    steps: 173     evaluation reward: 1.2702702702702702\n",
      "episode: 37   score: 0.0   memory length: 6770   epsilon: 1.0    steps: 130     evaluation reward: 1.236842105263158\n",
      "episode: 38   score: 1.0   memory length: 6955   epsilon: 1.0    steps: 185     evaluation reward: 1.2307692307692308\n",
      "episode: 39   score: 0.0   memory length: 7101   epsilon: 1.0    steps: 146     evaluation reward: 1.2\n",
      "episode: 40   score: 2.0   memory length: 7313   epsilon: 1.0    steps: 212     evaluation reward: 1.2195121951219512\n",
      "episode: 41   score: 1.0   memory length: 7477   epsilon: 1.0    steps: 164     evaluation reward: 1.2142857142857142\n",
      "episode: 42   score: 1.0   memory length: 7656   epsilon: 1.0    steps: 179     evaluation reward: 1.2093023255813953\n",
      "episode: 43   score: 1.0   memory length: 7835   epsilon: 1.0    steps: 179     evaluation reward: 1.2045454545454546\n",
      "episode: 44   score: 0.0   memory length: 7963   epsilon: 1.0    steps: 128     evaluation reward: 1.1777777777777778\n",
      "episode: 45   score: 2.0   memory length: 8183   epsilon: 1.0    steps: 220     evaluation reward: 1.1956521739130435\n",
      "episode: 46   score: 1.0   memory length: 8337   epsilon: 1.0    steps: 154     evaluation reward: 1.1914893617021276\n",
      "episode: 47   score: 0.0   memory length: 8472   epsilon: 1.0    steps: 135     evaluation reward: 1.1666666666666667\n",
      "episode: 48   score: 3.0   memory length: 8702   epsilon: 1.0    steps: 230     evaluation reward: 1.2040816326530612\n",
      "episode: 49   score: 1.0   memory length: 8869   epsilon: 1.0    steps: 167     evaluation reward: 1.2\n",
      "episode: 50   score: 1.0   memory length: 9055   epsilon: 1.0    steps: 186     evaluation reward: 1.196078431372549\n",
      "episode: 51   score: 0.0   memory length: 9180   epsilon: 1.0    steps: 125     evaluation reward: 1.1730769230769231\n",
      "episode: 52   score: 0.0   memory length: 9308   epsilon: 1.0    steps: 128     evaluation reward: 1.150943396226415\n",
      "episode: 53   score: 1.0   memory length: 9476   epsilon: 1.0    steps: 168     evaluation reward: 1.1481481481481481\n",
      "episode: 54   score: 0.0   memory length: 9608   epsilon: 1.0    steps: 132     evaluation reward: 1.1272727272727272\n",
      "episode: 55   score: 2.0   memory length: 9806   epsilon: 1.0    steps: 198     evaluation reward: 1.1428571428571428\n",
      "episode: 56   score: 3.0   memory length: 10082   epsilon: 1.0    steps: 276     evaluation reward: 1.1754385964912282\n",
      "episode: 57   score: 1.0   memory length: 10239   epsilon: 1.0    steps: 157     evaluation reward: 1.1724137931034482\n",
      "episode: 58   score: 0.0   memory length: 10369   epsilon: 1.0    steps: 130     evaluation reward: 1.152542372881356\n",
      "episode: 59   score: 0.0   memory length: 10494   epsilon: 1.0    steps: 125     evaluation reward: 1.1333333333333333\n",
      "episode: 60   score: 0.0   memory length: 10621   epsilon: 1.0    steps: 127     evaluation reward: 1.1147540983606556\n",
      "episode: 61   score: 2.0   memory length: 10829   epsilon: 1.0    steps: 208     evaluation reward: 1.1290322580645162\n",
      "episode: 62   score: 0.0   memory length: 10959   epsilon: 1.0    steps: 130     evaluation reward: 1.1111111111111112\n",
      "episode: 63   score: 3.0   memory length: 11214   epsilon: 1.0    steps: 255     evaluation reward: 1.140625\n",
      "episode: 64   score: 2.0   memory length: 11415   epsilon: 1.0    steps: 201     evaluation reward: 1.1538461538461537\n",
      "episode: 65   score: 4.0   memory length: 11711   epsilon: 1.0    steps: 296     evaluation reward: 1.196969696969697\n",
      "episode: 66   score: 2.0   memory length: 11921   epsilon: 1.0    steps: 210     evaluation reward: 1.208955223880597\n",
      "episode: 67   score: 1.0   memory length: 12097   epsilon: 1.0    steps: 176     evaluation reward: 1.2058823529411764\n",
      "episode: 68   score: 0.0   memory length: 12220   epsilon: 1.0    steps: 123     evaluation reward: 1.1884057971014492\n",
      "episode: 69   score: 1.0   memory length: 12378   epsilon: 1.0    steps: 158     evaluation reward: 1.1857142857142857\n",
      "episode: 70   score: 3.0   memory length: 12662   epsilon: 1.0    steps: 284     evaluation reward: 1.2112676056338028\n",
      "episode: 71   score: 2.0   memory length: 12865   epsilon: 1.0    steps: 203     evaluation reward: 1.2222222222222223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 72   score: 0.0   memory length: 12995   epsilon: 1.0    steps: 130     evaluation reward: 1.2054794520547945\n",
      "episode: 73   score: 2.0   memory length: 13206   epsilon: 1.0    steps: 211     evaluation reward: 1.2162162162162162\n",
      "episode: 74   score: 1.0   memory length: 13378   epsilon: 1.0    steps: 172     evaluation reward: 1.2133333333333334\n",
      "episode: 75   score: 1.0   memory length: 13532   epsilon: 1.0    steps: 154     evaluation reward: 1.2105263157894737\n",
      "episode: 76   score: 1.0   memory length: 13694   epsilon: 1.0    steps: 162     evaluation reward: 1.2077922077922079\n",
      "episode: 77   score: 0.0   memory length: 13826   epsilon: 1.0    steps: 132     evaluation reward: 1.1923076923076923\n",
      "episode: 78   score: 3.0   memory length: 14057   epsilon: 1.0    steps: 231     evaluation reward: 1.2151898734177216\n",
      "episode: 79   score: 3.0   memory length: 14333   epsilon: 1.0    steps: 276     evaluation reward: 1.2375\n",
      "episode: 80   score: 2.0   memory length: 14556   epsilon: 1.0    steps: 223     evaluation reward: 1.2469135802469136\n",
      "episode: 81   score: 0.0   memory length: 14681   epsilon: 1.0    steps: 125     evaluation reward: 1.2317073170731707\n",
      "episode: 82   score: 5.0   memory length: 15024   epsilon: 1.0    steps: 343     evaluation reward: 1.2771084337349397\n",
      "episode: 83   score: 1.0   memory length: 15199   epsilon: 1.0    steps: 175     evaluation reward: 1.2738095238095237\n",
      "episode: 84   score: 0.0   memory length: 15346   epsilon: 1.0    steps: 147     evaluation reward: 1.2588235294117647\n",
      "episode: 85   score: 1.0   memory length: 15519   epsilon: 1.0    steps: 173     evaluation reward: 1.255813953488372\n",
      "episode: 86   score: 0.0   memory length: 15645   epsilon: 1.0    steps: 126     evaluation reward: 1.2413793103448276\n",
      "episode: 87   score: 1.0   memory length: 15802   epsilon: 1.0    steps: 157     evaluation reward: 1.2386363636363635\n",
      "episode: 88   score: 3.0   memory length: 16069   epsilon: 1.0    steps: 267     evaluation reward: 1.2584269662921348\n",
      "episode: 89   score: 2.0   memory length: 16273   epsilon: 1.0    steps: 204     evaluation reward: 1.2666666666666666\n",
      "episode: 90   score: 0.0   memory length: 16407   epsilon: 1.0    steps: 134     evaluation reward: 1.2527472527472527\n",
      "episode: 91   score: 2.0   memory length: 16613   epsilon: 1.0    steps: 206     evaluation reward: 1.2608695652173914\n",
      "episode: 92   score: 2.0   memory length: 16817   epsilon: 1.0    steps: 204     evaluation reward: 1.2688172043010753\n",
      "episode: 93   score: 1.0   memory length: 16993   epsilon: 1.0    steps: 176     evaluation reward: 1.2659574468085106\n",
      "episode: 94   score: 2.0   memory length: 17213   epsilon: 1.0    steps: 220     evaluation reward: 1.2736842105263158\n",
      "episode: 95   score: 0.0   memory length: 17337   epsilon: 1.0    steps: 124     evaluation reward: 1.2604166666666667\n",
      "episode: 96   score: 0.0   memory length: 17472   epsilon: 1.0    steps: 135     evaluation reward: 1.2474226804123711\n",
      "episode: 97   score: 1.0   memory length: 17650   epsilon: 1.0    steps: 178     evaluation reward: 1.2448979591836735\n",
      "episode: 98   score: 2.0   memory length: 17853   epsilon: 1.0    steps: 203     evaluation reward: 1.2525252525252526\n",
      "episode: 99   score: 1.0   memory length: 18014   epsilon: 1.0    steps: 161     evaluation reward: 1.25\n",
      "episode: 100   score: 0.0   memory length: 18145   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 101   score: 2.0   memory length: 18344   epsilon: 1.0    steps: 199     evaluation reward: 1.24\n",
      "episode: 102   score: 2.0   memory length: 18526   epsilon: 1.0    steps: 182     evaluation reward: 1.24\n",
      "episode: 103   score: 2.0   memory length: 18748   epsilon: 1.0    steps: 222     evaluation reward: 1.24\n",
      "episode: 104   score: 1.0   memory length: 18927   epsilon: 1.0    steps: 179     evaluation reward: 1.23\n",
      "episode: 105   score: 2.0   memory length: 19153   epsilon: 1.0    steps: 226     evaluation reward: 1.25\n",
      "episode: 106   score: 2.0   memory length: 19359   epsilon: 1.0    steps: 206     evaluation reward: 1.27\n",
      "episode: 107   score: 0.0   memory length: 19490   epsilon: 1.0    steps: 131     evaluation reward: 1.25\n",
      "episode: 108   score: 0.0   memory length: 19621   epsilon: 1.0    steps: 131     evaluation reward: 1.25\n",
      "episode: 109   score: 1.0   memory length: 19783   epsilon: 1.0    steps: 162     evaluation reward: 1.22\n",
      "episode: 110   score: 1.0   memory length: 19962   epsilon: 1.0    steps: 179     evaluation reward: 1.21\n",
      "episode: 111   score: 2.0   memory length: 20161   epsilon: 1.0    steps: 199     evaluation reward: 1.22\n",
      "episode: 112   score: 0.0   memory length: 20300   epsilon: 1.0    steps: 139     evaluation reward: 1.2\n",
      "episode: 113   score: 0.0   memory length: 20432   epsilon: 1.0    steps: 132     evaluation reward: 1.2\n",
      "episode: 114   score: 5.0   memory length: 20787   epsilon: 1.0    steps: 355     evaluation reward: 1.25\n",
      "episode: 115   score: 1.0   memory length: 20942   epsilon: 1.0    steps: 155     evaluation reward: 1.26\n",
      "episode: 116   score: 0.0   memory length: 21080   epsilon: 1.0    steps: 138     evaluation reward: 1.24\n",
      "episode: 117   score: 2.0   memory length: 21284   epsilon: 1.0    steps: 204     evaluation reward: 1.25\n",
      "episode: 118   score: 0.0   memory length: 21406   epsilon: 1.0    steps: 122     evaluation reward: 1.22\n",
      "episode: 119   score: 1.0   memory length: 21595   epsilon: 1.0    steps: 189     evaluation reward: 1.2\n",
      "episode: 120   score: 1.0   memory length: 21766   epsilon: 1.0    steps: 171     evaluation reward: 1.2\n",
      "episode: 121   score: 4.0   memory length: 22045   epsilon: 1.0    steps: 279     evaluation reward: 1.22\n",
      "episode: 122   score: 1.0   memory length: 22203   epsilon: 1.0    steps: 158     evaluation reward: 1.23\n",
      "episode: 123   score: 1.0   memory length: 22385   epsilon: 1.0    steps: 182     evaluation reward: 1.24\n",
      "episode: 124   score: 0.0   memory length: 22525   epsilon: 1.0    steps: 140     evaluation reward: 1.24\n",
      "episode: 125   score: 0.0   memory length: 22656   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 126   score: 1.0   memory length: 22833   epsilon: 1.0    steps: 177     evaluation reward: 1.25\n",
      "episode: 127   score: 3.0   memory length: 23099   epsilon: 1.0    steps: 266     evaluation reward: 1.24\n",
      "episode: 128   score: 2.0   memory length: 23281   epsilon: 1.0    steps: 182     evaluation reward: 1.23\n",
      "episode: 129   score: 0.0   memory length: 23414   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 130   score: 1.0   memory length: 23568   epsilon: 1.0    steps: 154     evaluation reward: 1.21\n",
      "episode: 131   score: 0.0   memory length: 23692   epsilon: 1.0    steps: 124     evaluation reward: 1.2\n",
      "episode: 132   score: 0.0   memory length: 23823   epsilon: 1.0    steps: 131     evaluation reward: 1.2\n",
      "episode: 133   score: 3.0   memory length: 24052   epsilon: 1.0    steps: 229     evaluation reward: 1.23\n",
      "episode: 134   score: 2.0   memory length: 24238   epsilon: 1.0    steps: 186     evaluation reward: 1.25\n",
      "episode: 135   score: 2.0   memory length: 24450   epsilon: 1.0    steps: 212     evaluation reward: 1.24\n",
      "episode: 136   score: 2.0   memory length: 24670   epsilon: 1.0    steps: 220     evaluation reward: 1.25\n",
      "episode: 137   score: 2.0   memory length: 24895   epsilon: 1.0    steps: 225     evaluation reward: 1.27\n",
      "episode: 138   score: 1.0   memory length: 25074   epsilon: 1.0    steps: 179     evaluation reward: 1.27\n",
      "episode: 139   score: 1.0   memory length: 25264   epsilon: 1.0    steps: 190     evaluation reward: 1.28\n",
      "episode: 140   score: 1.0   memory length: 25422   epsilon: 1.0    steps: 158     evaluation reward: 1.27\n",
      "episode: 141   score: 0.0   memory length: 25556   epsilon: 1.0    steps: 134     evaluation reward: 1.26\n",
      "episode: 142   score: 2.0   memory length: 25745   epsilon: 1.0    steps: 189     evaluation reward: 1.27\n",
      "episode: 143   score: 3.0   memory length: 26028   epsilon: 1.0    steps: 283     evaluation reward: 1.29\n",
      "episode: 144   score: 0.0   memory length: 26157   epsilon: 1.0    steps: 129     evaluation reward: 1.29\n",
      "episode: 145   score: 0.0   memory length: 26292   epsilon: 1.0    steps: 135     evaluation reward: 1.27\n",
      "episode: 146   score: 2.0   memory length: 26514   epsilon: 1.0    steps: 222     evaluation reward: 1.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 147   score: 0.0   memory length: 26653   epsilon: 1.0    steps: 139     evaluation reward: 1.28\n",
      "episode: 148   score: 2.0   memory length: 26869   epsilon: 1.0    steps: 216     evaluation reward: 1.27\n",
      "episode: 149   score: 4.0   memory length: 27147   epsilon: 1.0    steps: 278     evaluation reward: 1.3\n",
      "episode: 150   score: 1.0   memory length: 27331   epsilon: 1.0    steps: 184     evaluation reward: 1.3\n",
      "episode: 151   score: 1.0   memory length: 27503   epsilon: 1.0    steps: 172     evaluation reward: 1.31\n",
      "episode: 152   score: 3.0   memory length: 27733   epsilon: 1.0    steps: 230     evaluation reward: 1.34\n",
      "episode: 153   score: 1.0   memory length: 27904   epsilon: 1.0    steps: 171     evaluation reward: 1.34\n",
      "episode: 154   score: 2.0   memory length: 28125   epsilon: 1.0    steps: 221     evaluation reward: 1.36\n",
      "episode: 155   score: 1.0   memory length: 28287   epsilon: 1.0    steps: 162     evaluation reward: 1.35\n",
      "episode: 156   score: 1.0   memory length: 28443   epsilon: 1.0    steps: 156     evaluation reward: 1.33\n",
      "episode: 157   score: 2.0   memory length: 28655   epsilon: 1.0    steps: 212     evaluation reward: 1.34\n",
      "episode: 158   score: 0.0   memory length: 28781   epsilon: 1.0    steps: 126     evaluation reward: 1.34\n",
      "episode: 159   score: 2.0   memory length: 28991   epsilon: 1.0    steps: 210     evaluation reward: 1.36\n",
      "episode: 160   score: 1.0   memory length: 29149   epsilon: 1.0    steps: 158     evaluation reward: 1.37\n",
      "episode: 161   score: 0.0   memory length: 29281   epsilon: 1.0    steps: 132     evaluation reward: 1.35\n",
      "episode: 162   score: 1.0   memory length: 29451   epsilon: 1.0    steps: 170     evaluation reward: 1.36\n",
      "episode: 163   score: 3.0   memory length: 29734   epsilon: 1.0    steps: 283     evaluation reward: 1.36\n",
      "episode: 164   score: 1.0   memory length: 29887   epsilon: 1.0    steps: 153     evaluation reward: 1.35\n",
      "episode: 165   score: 1.0   memory length: 30055   epsilon: 1.0    steps: 168     evaluation reward: 1.32\n",
      "episode: 166   score: 0.0   memory length: 30186   epsilon: 1.0    steps: 131     evaluation reward: 1.3\n",
      "episode: 167   score: 2.0   memory length: 30388   epsilon: 1.0    steps: 202     evaluation reward: 1.31\n",
      "episode: 168   score: 0.0   memory length: 30521   epsilon: 1.0    steps: 133     evaluation reward: 1.31\n",
      "episode: 169   score: 0.0   memory length: 30647   epsilon: 1.0    steps: 126     evaluation reward: 1.3\n",
      "episode: 170   score: 2.0   memory length: 30844   epsilon: 1.0    steps: 197     evaluation reward: 1.29\n",
      "episode: 171   score: 1.0   memory length: 31038   epsilon: 1.0    steps: 194     evaluation reward: 1.28\n",
      "episode: 172   score: 1.0   memory length: 31216   epsilon: 1.0    steps: 178     evaluation reward: 1.29\n",
      "episode: 173   score: 1.0   memory length: 31371   epsilon: 1.0    steps: 155     evaluation reward: 1.28\n",
      "episode: 174   score: 1.0   memory length: 31546   epsilon: 1.0    steps: 175     evaluation reward: 1.28\n",
      "episode: 175   score: 0.0   memory length: 31673   epsilon: 1.0    steps: 127     evaluation reward: 1.27\n",
      "episode: 176   score: 1.0   memory length: 31860   epsilon: 1.0    steps: 187     evaluation reward: 1.27\n",
      "episode: 177   score: 0.0   memory length: 31988   epsilon: 1.0    steps: 128     evaluation reward: 1.27\n",
      "episode: 178   score: 0.0   memory length: 32116   epsilon: 1.0    steps: 128     evaluation reward: 1.24\n",
      "episode: 179   score: 2.0   memory length: 32320   epsilon: 1.0    steps: 204     evaluation reward: 1.23\n",
      "episode: 180   score: 3.0   memory length: 32575   epsilon: 1.0    steps: 255     evaluation reward: 1.24\n",
      "episode: 181   score: 0.0   memory length: 32708   epsilon: 1.0    steps: 133     evaluation reward: 1.24\n",
      "episode: 182   score: 3.0   memory length: 32944   epsilon: 1.0    steps: 236     evaluation reward: 1.22\n",
      "episode: 183   score: 0.0   memory length: 33076   epsilon: 1.0    steps: 132     evaluation reward: 1.21\n",
      "episode: 184   score: 0.0   memory length: 33209   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 185   score: 0.0   memory length: 33341   epsilon: 1.0    steps: 132     evaluation reward: 1.2\n",
      "episode: 186   score: 1.0   memory length: 33504   epsilon: 1.0    steps: 163     evaluation reward: 1.21\n",
      "episode: 187   score: 0.0   memory length: 33644   epsilon: 1.0    steps: 140     evaluation reward: 1.2\n",
      "episode: 188   score: 2.0   memory length: 33869   epsilon: 1.0    steps: 225     evaluation reward: 1.19\n",
      "episode: 189   score: 0.0   memory length: 34003   epsilon: 1.0    steps: 134     evaluation reward: 1.17\n",
      "episode: 190   score: 0.0   memory length: 34135   epsilon: 1.0    steps: 132     evaluation reward: 1.17\n",
      "episode: 191   score: 5.0   memory length: 34434   epsilon: 1.0    steps: 299     evaluation reward: 1.2\n",
      "episode: 192   score: 2.0   memory length: 34645   epsilon: 1.0    steps: 211     evaluation reward: 1.2\n",
      "episode: 193   score: 0.0   memory length: 34786   epsilon: 1.0    steps: 141     evaluation reward: 1.19\n",
      "episode: 194   score: 1.0   memory length: 34944   epsilon: 1.0    steps: 158     evaluation reward: 1.18\n",
      "episode: 195   score: 3.0   memory length: 35193   epsilon: 1.0    steps: 249     evaluation reward: 1.21\n",
      "episode: 196   score: 2.0   memory length: 35398   epsilon: 1.0    steps: 205     evaluation reward: 1.23\n",
      "episode: 197   score: 1.0   memory length: 35584   epsilon: 1.0    steps: 186     evaluation reward: 1.23\n",
      "episode: 198   score: 0.0   memory length: 35717   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 199   score: 2.0   memory length: 35912   epsilon: 1.0    steps: 195     evaluation reward: 1.22\n",
      "episode: 200   score: 1.0   memory length: 36077   epsilon: 1.0    steps: 165     evaluation reward: 1.23\n",
      "episode: 201   score: 1.0   memory length: 36247   epsilon: 1.0    steps: 170     evaluation reward: 1.22\n",
      "episode: 202   score: 1.0   memory length: 36426   epsilon: 1.0    steps: 179     evaluation reward: 1.21\n",
      "episode: 203   score: 1.0   memory length: 36601   epsilon: 1.0    steps: 175     evaluation reward: 1.2\n",
      "episode: 204   score: 1.0   memory length: 36776   epsilon: 1.0    steps: 175     evaluation reward: 1.2\n",
      "episode: 205   score: 1.0   memory length: 36933   epsilon: 1.0    steps: 157     evaluation reward: 1.19\n",
      "episode: 206   score: 3.0   memory length: 37214   epsilon: 1.0    steps: 281     evaluation reward: 1.2\n",
      "episode: 207   score: 2.0   memory length: 37420   epsilon: 1.0    steps: 206     evaluation reward: 1.22\n",
      "episode: 208   score: 1.0   memory length: 37593   epsilon: 1.0    steps: 173     evaluation reward: 1.23\n",
      "episode: 209   score: 2.0   memory length: 37801   epsilon: 1.0    steps: 208     evaluation reward: 1.24\n",
      "episode: 210   score: 0.0   memory length: 37945   epsilon: 1.0    steps: 144     evaluation reward: 1.23\n",
      "episode: 211   score: 2.0   memory length: 38167   epsilon: 1.0    steps: 222     evaluation reward: 1.23\n",
      "episode: 212   score: 2.0   memory length: 38370   epsilon: 1.0    steps: 203     evaluation reward: 1.25\n",
      "episode: 213   score: 0.0   memory length: 38508   epsilon: 1.0    steps: 138     evaluation reward: 1.25\n",
      "episode: 214   score: 2.0   memory length: 38711   epsilon: 1.0    steps: 203     evaluation reward: 1.22\n",
      "episode: 215   score: 3.0   memory length: 38969   epsilon: 1.0    steps: 258     evaluation reward: 1.24\n",
      "episode: 216   score: 0.0   memory length: 39095   epsilon: 1.0    steps: 126     evaluation reward: 1.24\n",
      "episode: 217   score: 1.0   memory length: 39257   epsilon: 1.0    steps: 162     evaluation reward: 1.23\n",
      "episode: 218   score: 2.0   memory length: 39482   epsilon: 1.0    steps: 225     evaluation reward: 1.25\n",
      "episode: 219   score: 1.0   memory length: 39674   epsilon: 1.0    steps: 192     evaluation reward: 1.25\n",
      "episode: 220   score: 0.0   memory length: 39809   epsilon: 1.0    steps: 135     evaluation reward: 1.24\n",
      "episode: 221   score: 5.0   memory length: 40193   epsilon: 1.0    steps: 384     evaluation reward: 1.25\n",
      "episode: 222   score: 0.0   memory length: 40324   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 223   score: 3.0   memory length: 40569   epsilon: 1.0    steps: 245     evaluation reward: 1.26\n",
      "episode: 224   score: 0.0   memory length: 40695   epsilon: 1.0    steps: 126     evaluation reward: 1.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 225   score: 0.0   memory length: 40833   epsilon: 1.0    steps: 138     evaluation reward: 1.26\n",
      "episode: 226   score: 1.0   memory length: 41006   epsilon: 1.0    steps: 173     evaluation reward: 1.26\n",
      "episode: 227   score: 1.0   memory length: 41185   epsilon: 1.0    steps: 179     evaluation reward: 1.24\n",
      "episode: 228   score: 4.0   memory length: 41454   epsilon: 1.0    steps: 269     evaluation reward: 1.26\n",
      "episode: 229   score: 2.0   memory length: 41652   epsilon: 1.0    steps: 198     evaluation reward: 1.28\n",
      "episode: 230   score: 4.0   memory length: 41956   epsilon: 1.0    steps: 304     evaluation reward: 1.31\n",
      "episode: 231   score: 1.0   memory length: 42131   epsilon: 1.0    steps: 175     evaluation reward: 1.32\n",
      "episode: 232   score: 0.0   memory length: 42260   epsilon: 1.0    steps: 129     evaluation reward: 1.32\n",
      "episode: 233   score: 0.0   memory length: 42386   epsilon: 1.0    steps: 126     evaluation reward: 1.29\n",
      "episode: 234   score: 0.0   memory length: 42517   epsilon: 1.0    steps: 131     evaluation reward: 1.27\n",
      "episode: 235   score: 0.0   memory length: 42644   epsilon: 1.0    steps: 127     evaluation reward: 1.25\n",
      "episode: 236   score: 2.0   memory length: 42859   epsilon: 1.0    steps: 215     evaluation reward: 1.25\n",
      "episode: 237   score: 0.0   memory length: 42990   epsilon: 1.0    steps: 131     evaluation reward: 1.23\n",
      "episode: 238   score: 4.0   memory length: 43290   epsilon: 1.0    steps: 300     evaluation reward: 1.26\n",
      "episode: 239   score: 1.0   memory length: 43465   epsilon: 1.0    steps: 175     evaluation reward: 1.26\n",
      "episode: 240   score: 1.0   memory length: 43625   epsilon: 1.0    steps: 160     evaluation reward: 1.26\n",
      "episode: 241   score: 4.0   memory length: 43902   epsilon: 1.0    steps: 277     evaluation reward: 1.3\n",
      "episode: 242   score: 2.0   memory length: 44119   epsilon: 1.0    steps: 217     evaluation reward: 1.3\n",
      "episode: 243   score: 0.0   memory length: 44253   epsilon: 1.0    steps: 134     evaluation reward: 1.27\n",
      "episode: 244   score: 0.0   memory length: 44389   epsilon: 1.0    steps: 136     evaluation reward: 1.27\n",
      "episode: 245   score: 1.0   memory length: 44560   epsilon: 1.0    steps: 171     evaluation reward: 1.28\n",
      "episode: 246   score: 2.0   memory length: 44753   epsilon: 1.0    steps: 193     evaluation reward: 1.28\n",
      "episode: 247   score: 1.0   memory length: 44916   epsilon: 1.0    steps: 163     evaluation reward: 1.29\n",
      "episode: 248   score: 3.0   memory length: 45152   epsilon: 1.0    steps: 236     evaluation reward: 1.3\n",
      "episode: 249   score: 2.0   memory length: 45394   epsilon: 1.0    steps: 242     evaluation reward: 1.28\n",
      "episode: 250   score: 2.0   memory length: 45617   epsilon: 1.0    steps: 223     evaluation reward: 1.29\n",
      "episode: 251   score: 2.0   memory length: 45851   epsilon: 1.0    steps: 234     evaluation reward: 1.3\n",
      "episode: 252   score: 2.0   memory length: 46088   epsilon: 1.0    steps: 237     evaluation reward: 1.29\n",
      "episode: 253   score: 3.0   memory length: 46336   epsilon: 1.0    steps: 248     evaluation reward: 1.31\n",
      "episode: 254   score: 0.0   memory length: 46471   epsilon: 1.0    steps: 135     evaluation reward: 1.29\n",
      "episode: 255   score: 1.0   memory length: 46651   epsilon: 1.0    steps: 180     evaluation reward: 1.29\n",
      "episode: 256   score: 2.0   memory length: 46853   epsilon: 1.0    steps: 202     evaluation reward: 1.3\n",
      "episode: 257   score: 4.0   memory length: 47139   epsilon: 1.0    steps: 286     evaluation reward: 1.32\n",
      "episode: 258   score: 5.0   memory length: 47488   epsilon: 1.0    steps: 349     evaluation reward: 1.37\n",
      "episode: 259   score: 1.0   memory length: 47666   epsilon: 1.0    steps: 178     evaluation reward: 1.36\n",
      "episode: 260   score: 1.0   memory length: 47842   epsilon: 1.0    steps: 176     evaluation reward: 1.36\n",
      "episode: 261   score: 1.0   memory length: 48009   epsilon: 1.0    steps: 167     evaluation reward: 1.37\n",
      "episode: 262   score: 1.0   memory length: 48186   epsilon: 1.0    steps: 177     evaluation reward: 1.37\n",
      "episode: 263   score: 0.0   memory length: 48320   epsilon: 1.0    steps: 134     evaluation reward: 1.34\n",
      "episode: 264   score: 3.0   memory length: 48567   epsilon: 1.0    steps: 247     evaluation reward: 1.36\n",
      "episode: 265   score: 1.0   memory length: 48743   epsilon: 1.0    steps: 176     evaluation reward: 1.36\n",
      "episode: 266   score: 1.0   memory length: 48908   epsilon: 1.0    steps: 165     evaluation reward: 1.37\n",
      "episode: 267   score: 1.0   memory length: 49088   epsilon: 1.0    steps: 180     evaluation reward: 1.36\n",
      "episode: 268   score: 0.0   memory length: 49223   epsilon: 1.0    steps: 135     evaluation reward: 1.36\n",
      "episode: 269   score: 1.0   memory length: 49393   epsilon: 1.0    steps: 170     evaluation reward: 1.37\n",
      "episode: 270   score: 0.0   memory length: 49525   epsilon: 1.0    steps: 132     evaluation reward: 1.35\n",
      "episode: 271   score: 0.0   memory length: 49655   epsilon: 1.0    steps: 130     evaluation reward: 1.34\n",
      "episode: 272   score: 0.0   memory length: 49794   epsilon: 1.0    steps: 139     evaluation reward: 1.33\n",
      "now time :  2018-12-14 07:43:49.727685\n",
      "episode: 273   score: 4.0   memory length: 50079   epsilon: 1.0    steps: 285     evaluation reward: 1.36\n",
      "episode: 274   score: 0.0   memory length: 50218   epsilon: 1.0    steps: 139     evaluation reward: 1.35\n",
      "episode: 275   score: 1.0   memory length: 50393   epsilon: 1.0    steps: 175     evaluation reward: 1.36\n",
      "episode: 276   score: 1.0   memory length: 50573   epsilon: 1.0    steps: 180     evaluation reward: 1.36\n",
      "episode: 277   score: 0.0   memory length: 50712   epsilon: 1.0    steps: 139     evaluation reward: 1.36\n",
      "episode: 278   score: 1.0   memory length: 50894   epsilon: 1.0    steps: 182     evaluation reward: 1.37\n",
      "episode: 279   score: 0.0   memory length: 51029   epsilon: 1.0    steps: 135     evaluation reward: 1.35\n",
      "episode: 280   score: 2.0   memory length: 51213   epsilon: 1.0    steps: 184     evaluation reward: 1.34\n",
      "episode: 281   score: 1.0   memory length: 51390   epsilon: 1.0    steps: 177     evaluation reward: 1.35\n",
      "episode: 282   score: 1.0   memory length: 51551   epsilon: 1.0    steps: 161     evaluation reward: 1.33\n",
      "episode: 283   score: 2.0   memory length: 51754   epsilon: 1.0    steps: 203     evaluation reward: 1.35\n",
      "episode: 284   score: 1.0   memory length: 51908   epsilon: 1.0    steps: 154     evaluation reward: 1.36\n",
      "episode: 285   score: 2.0   memory length: 52101   epsilon: 1.0    steps: 193     evaluation reward: 1.38\n",
      "episode: 286   score: 0.0   memory length: 52230   epsilon: 1.0    steps: 129     evaluation reward: 1.37\n",
      "episode: 287   score: 1.0   memory length: 52406   epsilon: 1.0    steps: 176     evaluation reward: 1.38\n",
      "episode: 288   score: 0.0   memory length: 52543   epsilon: 1.0    steps: 137     evaluation reward: 1.36\n",
      "episode: 289   score: 1.0   memory length: 52719   epsilon: 1.0    steps: 176     evaluation reward: 1.37\n",
      "episode: 290   score: 1.0   memory length: 52894   epsilon: 1.0    steps: 175     evaluation reward: 1.38\n",
      "episode: 291   score: 0.0   memory length: 53023   epsilon: 1.0    steps: 129     evaluation reward: 1.33\n",
      "episode: 292   score: 0.0   memory length: 53157   epsilon: 1.0    steps: 134     evaluation reward: 1.31\n",
      "episode: 293   score: 0.0   memory length: 53282   epsilon: 1.0    steps: 125     evaluation reward: 1.31\n",
      "episode: 294   score: 0.0   memory length: 53411   epsilon: 1.0    steps: 129     evaluation reward: 1.3\n",
      "episode: 295   score: 0.0   memory length: 53546   epsilon: 1.0    steps: 135     evaluation reward: 1.27\n",
      "episode: 296   score: 0.0   memory length: 53674   epsilon: 1.0    steps: 128     evaluation reward: 1.25\n",
      "episode: 297   score: 0.0   memory length: 53809   epsilon: 1.0    steps: 135     evaluation reward: 1.24\n",
      "episode: 298   score: 2.0   memory length: 53995   epsilon: 1.0    steps: 186     evaluation reward: 1.26\n",
      "episode: 299   score: 1.0   memory length: 54164   epsilon: 1.0    steps: 169     evaluation reward: 1.25\n",
      "episode: 300   score: 6.0   memory length: 54509   epsilon: 1.0    steps: 345     evaluation reward: 1.3\n",
      "episode: 301   score: 4.0   memory length: 54803   epsilon: 1.0    steps: 294     evaluation reward: 1.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 302   score: 2.0   memory length: 55008   epsilon: 1.0    steps: 205     evaluation reward: 1.34\n",
      "episode: 303   score: 4.0   memory length: 55290   epsilon: 1.0    steps: 282     evaluation reward: 1.37\n",
      "episode: 304   score: 0.0   memory length: 55415   epsilon: 1.0    steps: 125     evaluation reward: 1.36\n",
      "episode: 305   score: 2.0   memory length: 55619   epsilon: 1.0    steps: 204     evaluation reward: 1.37\n",
      "episode: 306   score: 1.0   memory length: 55782   epsilon: 1.0    steps: 163     evaluation reward: 1.35\n",
      "episode: 307   score: 1.0   memory length: 55956   epsilon: 1.0    steps: 174     evaluation reward: 1.34\n",
      "episode: 308   score: 0.0   memory length: 56088   epsilon: 1.0    steps: 132     evaluation reward: 1.33\n",
      "episode: 309   score: 2.0   memory length: 56284   epsilon: 1.0    steps: 196     evaluation reward: 1.33\n",
      "episode: 310   score: 4.0   memory length: 56564   epsilon: 1.0    steps: 280     evaluation reward: 1.37\n",
      "episode: 311   score: 5.0   memory length: 56887   epsilon: 1.0    steps: 323     evaluation reward: 1.4\n",
      "episode: 312   score: 2.0   memory length: 57106   epsilon: 1.0    steps: 219     evaluation reward: 1.4\n",
      "episode: 313   score: 0.0   memory length: 57243   epsilon: 1.0    steps: 137     evaluation reward: 1.4\n",
      "episode: 314   score: 0.0   memory length: 57371   epsilon: 1.0    steps: 128     evaluation reward: 1.38\n",
      "episode: 315   score: 1.0   memory length: 57532   epsilon: 1.0    steps: 161     evaluation reward: 1.36\n",
      "episode: 316   score: 0.0   memory length: 57658   epsilon: 1.0    steps: 126     evaluation reward: 1.36\n",
      "episode: 317   score: 2.0   memory length: 57864   epsilon: 1.0    steps: 206     evaluation reward: 1.37\n",
      "episode: 318   score: 2.0   memory length: 58067   epsilon: 1.0    steps: 203     evaluation reward: 1.37\n",
      "episode: 319   score: 0.0   memory length: 58199   epsilon: 1.0    steps: 132     evaluation reward: 1.36\n",
      "episode: 320   score: 2.0   memory length: 58385   epsilon: 1.0    steps: 186     evaluation reward: 1.38\n",
      "episode: 321   score: 1.0   memory length: 58537   epsilon: 1.0    steps: 152     evaluation reward: 1.34\n",
      "episode: 322   score: 0.0   memory length: 58669   epsilon: 1.0    steps: 132     evaluation reward: 1.34\n",
      "episode: 323   score: 2.0   memory length: 58879   epsilon: 1.0    steps: 210     evaluation reward: 1.33\n",
      "episode: 324   score: 0.0   memory length: 59012   epsilon: 1.0    steps: 133     evaluation reward: 1.33\n",
      "episode: 325   score: 1.0   memory length: 59194   epsilon: 1.0    steps: 182     evaluation reward: 1.34\n",
      "episode: 326   score: 1.0   memory length: 59367   epsilon: 1.0    steps: 173     evaluation reward: 1.34\n",
      "episode: 327   score: 2.0   memory length: 59568   epsilon: 1.0    steps: 201     evaluation reward: 1.35\n",
      "episode: 328   score: 2.0   memory length: 59781   epsilon: 1.0    steps: 213     evaluation reward: 1.33\n",
      "episode: 329   score: 1.0   memory length: 59940   epsilon: 1.0    steps: 159     evaluation reward: 1.32\n",
      "episode: 330   score: 0.0   memory length: 60069   epsilon: 1.0    steps: 129     evaluation reward: 1.28\n",
      "episode: 331   score: 2.0   memory length: 60276   epsilon: 1.0    steps: 207     evaluation reward: 1.29\n",
      "episode: 332   score: 0.0   memory length: 60403   epsilon: 1.0    steps: 127     evaluation reward: 1.29\n",
      "episode: 333   score: 3.0   memory length: 60630   epsilon: 1.0    steps: 227     evaluation reward: 1.32\n",
      "episode: 334   score: 2.0   memory length: 60833   epsilon: 1.0    steps: 203     evaluation reward: 1.34\n",
      "episode: 335   score: 1.0   memory length: 60987   epsilon: 1.0    steps: 154     evaluation reward: 1.35\n",
      "episode: 336   score: 1.0   memory length: 61166   epsilon: 1.0    steps: 179     evaluation reward: 1.34\n",
      "episode: 337   score: 0.0   memory length: 61296   epsilon: 1.0    steps: 130     evaluation reward: 1.34\n",
      "episode: 338   score: 0.0   memory length: 61425   epsilon: 1.0    steps: 129     evaluation reward: 1.3\n",
      "episode: 339   score: 2.0   memory length: 61634   epsilon: 1.0    steps: 209     evaluation reward: 1.31\n",
      "episode: 340   score: 1.0   memory length: 61792   epsilon: 1.0    steps: 158     evaluation reward: 1.31\n",
      "episode: 341   score: 2.0   memory length: 62000   epsilon: 1.0    steps: 208     evaluation reward: 1.29\n",
      "episode: 342   score: 2.0   memory length: 62201   epsilon: 1.0    steps: 201     evaluation reward: 1.29\n",
      "episode: 343   score: 1.0   memory length: 62355   epsilon: 1.0    steps: 154     evaluation reward: 1.3\n",
      "episode: 344   score: 1.0   memory length: 62534   epsilon: 1.0    steps: 179     evaluation reward: 1.31\n",
      "episode: 345   score: 1.0   memory length: 62711   epsilon: 1.0    steps: 177     evaluation reward: 1.31\n",
      "episode: 346   score: 1.0   memory length: 62869   epsilon: 1.0    steps: 158     evaluation reward: 1.3\n",
      "episode: 347   score: 0.0   memory length: 62996   epsilon: 1.0    steps: 127     evaluation reward: 1.29\n",
      "episode: 348   score: 0.0   memory length: 63128   epsilon: 1.0    steps: 132     evaluation reward: 1.26\n",
      "episode: 349   score: 0.0   memory length: 63256   epsilon: 1.0    steps: 128     evaluation reward: 1.24\n",
      "episode: 350   score: 1.0   memory length: 63430   epsilon: 1.0    steps: 174     evaluation reward: 1.23\n",
      "episode: 351   score: 1.0   memory length: 63614   epsilon: 1.0    steps: 184     evaluation reward: 1.22\n",
      "episode: 352   score: 1.0   memory length: 63795   epsilon: 1.0    steps: 181     evaluation reward: 1.21\n",
      "episode: 353   score: 1.0   memory length: 63948   epsilon: 1.0    steps: 153     evaluation reward: 1.19\n",
      "episode: 354   score: 1.0   memory length: 64127   epsilon: 1.0    steps: 179     evaluation reward: 1.2\n",
      "episode: 355   score: 1.0   memory length: 64306   epsilon: 1.0    steps: 179     evaluation reward: 1.2\n",
      "episode: 356   score: 1.0   memory length: 64484   epsilon: 1.0    steps: 178     evaluation reward: 1.19\n",
      "episode: 357   score: 0.0   memory length: 64614   epsilon: 1.0    steps: 130     evaluation reward: 1.15\n",
      "episode: 358   score: 0.0   memory length: 64739   epsilon: 1.0    steps: 125     evaluation reward: 1.1\n",
      "episode: 359   score: 2.0   memory length: 64959   epsilon: 1.0    steps: 220     evaluation reward: 1.11\n",
      "episode: 360   score: 1.0   memory length: 65145   epsilon: 1.0    steps: 186     evaluation reward: 1.11\n",
      "episode: 361   score: 1.0   memory length: 65328   epsilon: 1.0    steps: 183     evaluation reward: 1.11\n",
      "episode: 362   score: 1.0   memory length: 65485   epsilon: 1.0    steps: 157     evaluation reward: 1.11\n",
      "episode: 363   score: 1.0   memory length: 65647   epsilon: 1.0    steps: 162     evaluation reward: 1.12\n",
      "episode: 364   score: 1.0   memory length: 65803   epsilon: 1.0    steps: 156     evaluation reward: 1.1\n",
      "episode: 365   score: 1.0   memory length: 65963   epsilon: 1.0    steps: 160     evaluation reward: 1.1\n",
      "episode: 366   score: 2.0   memory length: 66180   epsilon: 1.0    steps: 217     evaluation reward: 1.11\n",
      "episode: 367   score: 0.0   memory length: 66306   epsilon: 1.0    steps: 126     evaluation reward: 1.1\n",
      "episode: 368   score: 0.0   memory length: 66447   epsilon: 1.0    steps: 141     evaluation reward: 1.1\n",
      "episode: 369   score: 1.0   memory length: 66602   epsilon: 1.0    steps: 155     evaluation reward: 1.1\n",
      "episode: 370   score: 4.0   memory length: 66914   epsilon: 1.0    steps: 312     evaluation reward: 1.14\n",
      "episode: 371   score: 2.0   memory length: 67123   epsilon: 1.0    steps: 209     evaluation reward: 1.16\n",
      "episode: 372   score: 1.0   memory length: 67284   epsilon: 1.0    steps: 161     evaluation reward: 1.17\n",
      "episode: 373   score: 5.0   memory length: 67598   epsilon: 1.0    steps: 314     evaluation reward: 1.18\n",
      "episode: 374   score: 0.0   memory length: 67733   epsilon: 1.0    steps: 135     evaluation reward: 1.18\n",
      "episode: 375   score: 1.0   memory length: 67907   epsilon: 1.0    steps: 174     evaluation reward: 1.18\n",
      "episode: 376   score: 1.0   memory length: 68080   epsilon: 1.0    steps: 173     evaluation reward: 1.18\n",
      "episode: 377   score: 0.0   memory length: 68208   epsilon: 1.0    steps: 128     evaluation reward: 1.18\n",
      "episode: 378   score: 1.0   memory length: 68369   epsilon: 1.0    steps: 161     evaluation reward: 1.18\n",
      "episode: 379   score: 4.0   memory length: 68629   epsilon: 1.0    steps: 260     evaluation reward: 1.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 380   score: 2.0   memory length: 68811   epsilon: 1.0    steps: 182     evaluation reward: 1.22\n",
      "episode: 381   score: 1.0   memory length: 68966   epsilon: 1.0    steps: 155     evaluation reward: 1.22\n",
      "episode: 382   score: 0.0   memory length: 69101   epsilon: 1.0    steps: 135     evaluation reward: 1.21\n",
      "episode: 383   score: 1.0   memory length: 69260   epsilon: 1.0    steps: 159     evaluation reward: 1.2\n",
      "episode: 384   score: 3.0   memory length: 69498   epsilon: 1.0    steps: 238     evaluation reward: 1.22\n",
      "episode: 385   score: 2.0   memory length: 69701   epsilon: 1.0    steps: 203     evaluation reward: 1.22\n",
      "episode: 386   score: 0.0   memory length: 69837   epsilon: 1.0    steps: 136     evaluation reward: 1.22\n",
      "episode: 387   score: 3.0   memory length: 70096   epsilon: 1.0    steps: 259     evaluation reward: 1.24\n",
      "episode: 388   score: 0.0   memory length: 70222   epsilon: 1.0    steps: 126     evaluation reward: 1.24\n",
      "episode: 389   score: 3.0   memory length: 70455   epsilon: 1.0    steps: 233     evaluation reward: 1.26\n",
      "episode: 390   score: 0.0   memory length: 70586   epsilon: 1.0    steps: 131     evaluation reward: 1.25\n",
      "episode: 391   score: 0.0   memory length: 70712   epsilon: 1.0    steps: 126     evaluation reward: 1.25\n",
      "episode: 392   score: 1.0   memory length: 70886   epsilon: 1.0    steps: 174     evaluation reward: 1.26\n",
      "episode: 393   score: 0.0   memory length: 71016   epsilon: 1.0    steps: 130     evaluation reward: 1.26\n",
      "episode: 394   score: 1.0   memory length: 71178   epsilon: 1.0    steps: 162     evaluation reward: 1.27\n",
      "episode: 395   score: 1.0   memory length: 71355   epsilon: 1.0    steps: 177     evaluation reward: 1.28\n",
      "episode: 396   score: 1.0   memory length: 71517   epsilon: 1.0    steps: 162     evaluation reward: 1.29\n",
      "episode: 397   score: 2.0   memory length: 71741   epsilon: 1.0    steps: 224     evaluation reward: 1.31\n",
      "episode: 398   score: 1.0   memory length: 71904   epsilon: 1.0    steps: 163     evaluation reward: 1.3\n",
      "episode: 399   score: 4.0   memory length: 72194   epsilon: 1.0    steps: 290     evaluation reward: 1.33\n",
      "episode: 400   score: 0.0   memory length: 72323   epsilon: 1.0    steps: 129     evaluation reward: 1.27\n",
      "episode: 401   score: 2.0   memory length: 72529   epsilon: 1.0    steps: 206     evaluation reward: 1.25\n",
      "episode: 402   score: 4.0   memory length: 72836   epsilon: 1.0    steps: 307     evaluation reward: 1.27\n",
      "episode: 403   score: 1.0   memory length: 72995   epsilon: 1.0    steps: 159     evaluation reward: 1.24\n",
      "episode: 404   score: 2.0   memory length: 73200   epsilon: 1.0    steps: 205     evaluation reward: 1.26\n",
      "episode: 405   score: 3.0   memory length: 73437   epsilon: 1.0    steps: 237     evaluation reward: 1.27\n",
      "episode: 406   score: 2.0   memory length: 73645   epsilon: 1.0    steps: 208     evaluation reward: 1.28\n",
      "episode: 407   score: 0.0   memory length: 73782   epsilon: 1.0    steps: 137     evaluation reward: 1.27\n",
      "episode: 408   score: 2.0   memory length: 73977   epsilon: 1.0    steps: 195     evaluation reward: 1.29\n",
      "episode: 409   score: 3.0   memory length: 74246   epsilon: 1.0    steps: 269     evaluation reward: 1.3\n",
      "episode: 410   score: 0.0   memory length: 74377   epsilon: 1.0    steps: 131     evaluation reward: 1.26\n",
      "episode: 411   score: 1.0   memory length: 74530   epsilon: 1.0    steps: 153     evaluation reward: 1.22\n",
      "episode: 412   score: 2.0   memory length: 74747   epsilon: 1.0    steps: 217     evaluation reward: 1.22\n",
      "episode: 413   score: 2.0   memory length: 74974   epsilon: 1.0    steps: 227     evaluation reward: 1.24\n",
      "episode: 414   score: 0.0   memory length: 75114   epsilon: 1.0    steps: 140     evaluation reward: 1.24\n",
      "episode: 415   score: 0.0   memory length: 75245   epsilon: 1.0    steps: 131     evaluation reward: 1.23\n",
      "episode: 416   score: 0.0   memory length: 75374   epsilon: 1.0    steps: 129     evaluation reward: 1.23\n",
      "episode: 417   score: 2.0   memory length: 75575   epsilon: 1.0    steps: 201     evaluation reward: 1.23\n",
      "episode: 418   score: 0.0   memory length: 75714   epsilon: 1.0    steps: 139     evaluation reward: 1.21\n",
      "episode: 419   score: 1.0   memory length: 75889   epsilon: 1.0    steps: 175     evaluation reward: 1.22\n",
      "episode: 420   score: 1.0   memory length: 76051   epsilon: 1.0    steps: 162     evaluation reward: 1.21\n",
      "episode: 421   score: 3.0   memory length: 76341   epsilon: 1.0    steps: 290     evaluation reward: 1.23\n",
      "episode: 422   score: 1.0   memory length: 76500   epsilon: 1.0    steps: 159     evaluation reward: 1.24\n",
      "episode: 423   score: 1.0   memory length: 76676   epsilon: 1.0    steps: 176     evaluation reward: 1.23\n",
      "episode: 424   score: 1.0   memory length: 76851   epsilon: 1.0    steps: 175     evaluation reward: 1.24\n",
      "episode: 425   score: 0.0   memory length: 76982   epsilon: 1.0    steps: 131     evaluation reward: 1.23\n",
      "episode: 426   score: 2.0   memory length: 77187   epsilon: 1.0    steps: 205     evaluation reward: 1.24\n",
      "episode: 427   score: 0.0   memory length: 77313   epsilon: 1.0    steps: 126     evaluation reward: 1.22\n",
      "episode: 428   score: 2.0   memory length: 77532   epsilon: 1.0    steps: 219     evaluation reward: 1.22\n",
      "episode: 429   score: 0.0   memory length: 77660   epsilon: 1.0    steps: 128     evaluation reward: 1.21\n",
      "episode: 430   score: 1.0   memory length: 77837   epsilon: 1.0    steps: 177     evaluation reward: 1.22\n",
      "episode: 431   score: 2.0   memory length: 78037   epsilon: 1.0    steps: 200     evaluation reward: 1.22\n",
      "episode: 432   score: 3.0   memory length: 78310   epsilon: 1.0    steps: 273     evaluation reward: 1.25\n",
      "episode: 433   score: 0.0   memory length: 78443   epsilon: 1.0    steps: 133     evaluation reward: 1.22\n",
      "episode: 434   score: 1.0   memory length: 78595   epsilon: 1.0    steps: 152     evaluation reward: 1.21\n",
      "episode: 435   score: 0.0   memory length: 78741   epsilon: 1.0    steps: 146     evaluation reward: 1.2\n",
      "episode: 436   score: 0.0   memory length: 78873   epsilon: 1.0    steps: 132     evaluation reward: 1.19\n",
      "episode: 437   score: 3.0   memory length: 79124   epsilon: 1.0    steps: 251     evaluation reward: 1.22\n",
      "episode: 438   score: 1.0   memory length: 79294   epsilon: 1.0    steps: 170     evaluation reward: 1.23\n",
      "episode: 439   score: 0.0   memory length: 79427   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 440   score: 2.0   memory length: 79642   epsilon: 1.0    steps: 215     evaluation reward: 1.22\n",
      "episode: 441   score: 2.0   memory length: 79855   epsilon: 1.0    steps: 213     evaluation reward: 1.22\n",
      "episode: 442   score: 1.0   memory length: 80031   epsilon: 1.0    steps: 176     evaluation reward: 1.21\n",
      "episode: 443   score: 1.0   memory length: 80189   epsilon: 1.0    steps: 158     evaluation reward: 1.21\n",
      "episode: 444   score: 0.0   memory length: 80315   epsilon: 1.0    steps: 126     evaluation reward: 1.2\n",
      "episode: 445   score: 1.0   memory length: 80481   epsilon: 1.0    steps: 166     evaluation reward: 1.2\n",
      "episode: 446   score: 1.0   memory length: 80645   epsilon: 1.0    steps: 164     evaluation reward: 1.2\n",
      "episode: 447   score: 0.0   memory length: 80792   epsilon: 1.0    steps: 147     evaluation reward: 1.2\n",
      "episode: 448   score: 1.0   memory length: 80969   epsilon: 1.0    steps: 177     evaluation reward: 1.21\n",
      "episode: 449   score: 3.0   memory length: 81251   epsilon: 1.0    steps: 282     evaluation reward: 1.24\n",
      "episode: 450   score: 1.0   memory length: 81420   epsilon: 1.0    steps: 169     evaluation reward: 1.24\n",
      "episode: 451   score: 3.0   memory length: 81666   epsilon: 1.0    steps: 246     evaluation reward: 1.26\n",
      "episode: 452   score: 0.0   memory length: 81793   epsilon: 1.0    steps: 127     evaluation reward: 1.25\n",
      "episode: 453   score: 1.0   memory length: 81964   epsilon: 1.0    steps: 171     evaluation reward: 1.25\n",
      "episode: 454   score: 1.0   memory length: 82130   epsilon: 1.0    steps: 166     evaluation reward: 1.25\n",
      "episode: 455   score: 2.0   memory length: 82356   epsilon: 1.0    steps: 226     evaluation reward: 1.26\n",
      "episode: 456   score: 2.0   memory length: 82557   epsilon: 1.0    steps: 201     evaluation reward: 1.27\n",
      "episode: 457   score: 0.0   memory length: 82689   epsilon: 1.0    steps: 132     evaluation reward: 1.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 458   score: 3.0   memory length: 82906   epsilon: 1.0    steps: 217     evaluation reward: 1.3\n",
      "episode: 459   score: 1.0   memory length: 83072   epsilon: 1.0    steps: 166     evaluation reward: 1.29\n",
      "episode: 460   score: 2.0   memory length: 83258   epsilon: 1.0    steps: 186     evaluation reward: 1.3\n",
      "episode: 461   score: 1.0   memory length: 83416   epsilon: 1.0    steps: 158     evaluation reward: 1.3\n",
      "episode: 462   score: 2.0   memory length: 83619   epsilon: 1.0    steps: 203     evaluation reward: 1.31\n",
      "episode: 463   score: 3.0   memory length: 83849   epsilon: 1.0    steps: 230     evaluation reward: 1.33\n",
      "episode: 464   score: 2.0   memory length: 84055   epsilon: 1.0    steps: 206     evaluation reward: 1.34\n",
      "episode: 465   score: 1.0   memory length: 84224   epsilon: 1.0    steps: 169     evaluation reward: 1.34\n",
      "episode: 466   score: 0.0   memory length: 84350   epsilon: 1.0    steps: 126     evaluation reward: 1.32\n",
      "episode: 467   score: 2.0   memory length: 84571   epsilon: 1.0    steps: 221     evaluation reward: 1.34\n",
      "episode: 468   score: 0.0   memory length: 84697   epsilon: 1.0    steps: 126     evaluation reward: 1.34\n",
      "episode: 469   score: 1.0   memory length: 84871   epsilon: 1.0    steps: 174     evaluation reward: 1.34\n",
      "episode: 470   score: 0.0   memory length: 85001   epsilon: 1.0    steps: 130     evaluation reward: 1.3\n",
      "episode: 471   score: 0.0   memory length: 85136   epsilon: 1.0    steps: 135     evaluation reward: 1.28\n",
      "episode: 472   score: 0.0   memory length: 85266   epsilon: 1.0    steps: 130     evaluation reward: 1.27\n",
      "episode: 473   score: 0.0   memory length: 85398   epsilon: 1.0    steps: 132     evaluation reward: 1.22\n",
      "episode: 474   score: 1.0   memory length: 85571   epsilon: 1.0    steps: 173     evaluation reward: 1.23\n",
      "episode: 475   score: 0.0   memory length: 85697   epsilon: 1.0    steps: 126     evaluation reward: 1.22\n",
      "episode: 476   score: 1.0   memory length: 85874   epsilon: 1.0    steps: 177     evaluation reward: 1.22\n",
      "episode: 477   score: 2.0   memory length: 86078   epsilon: 1.0    steps: 204     evaluation reward: 1.24\n",
      "episode: 478   score: 3.0   memory length: 86336   epsilon: 1.0    steps: 258     evaluation reward: 1.26\n",
      "episode: 479   score: 0.0   memory length: 86462   epsilon: 1.0    steps: 126     evaluation reward: 1.22\n",
      "episode: 480   score: 1.0   memory length: 86641   epsilon: 1.0    steps: 179     evaluation reward: 1.21\n",
      "episode: 481   score: 2.0   memory length: 86838   epsilon: 1.0    steps: 197     evaluation reward: 1.22\n",
      "episode: 482   score: 0.0   memory length: 86978   epsilon: 1.0    steps: 140     evaluation reward: 1.22\n",
      "episode: 483   score: 2.0   memory length: 87200   epsilon: 1.0    steps: 222     evaluation reward: 1.23\n",
      "episode: 484   score: 0.0   memory length: 87323   epsilon: 1.0    steps: 123     evaluation reward: 1.2\n",
      "episode: 485   score: 0.0   memory length: 87452   epsilon: 1.0    steps: 129     evaluation reward: 1.18\n",
      "episode: 486   score: 2.0   memory length: 87633   epsilon: 1.0    steps: 181     evaluation reward: 1.2\n",
      "episode: 487   score: 1.0   memory length: 87797   epsilon: 1.0    steps: 164     evaluation reward: 1.18\n",
      "episode: 488   score: 0.0   memory length: 87922   epsilon: 1.0    steps: 125     evaluation reward: 1.18\n",
      "episode: 489   score: 3.0   memory length: 88159   epsilon: 1.0    steps: 237     evaluation reward: 1.18\n",
      "episode: 490   score: 2.0   memory length: 88386   epsilon: 1.0    steps: 227     evaluation reward: 1.2\n",
      "episode: 491   score: 1.0   memory length: 88587   epsilon: 1.0    steps: 201     evaluation reward: 1.21\n",
      "episode: 492   score: 0.0   memory length: 88715   epsilon: 1.0    steps: 128     evaluation reward: 1.2\n",
      "episode: 493   score: 2.0   memory length: 88906   epsilon: 1.0    steps: 191     evaluation reward: 1.22\n",
      "episode: 494   score: 2.0   memory length: 89109   epsilon: 1.0    steps: 203     evaluation reward: 1.23\n",
      "episode: 495   score: 0.0   memory length: 89243   epsilon: 1.0    steps: 134     evaluation reward: 1.22\n",
      "episode: 496   score: 0.0   memory length: 89386   epsilon: 1.0    steps: 143     evaluation reward: 1.21\n",
      "episode: 497   score: 5.0   memory length: 89691   epsilon: 1.0    steps: 305     evaluation reward: 1.24\n",
      "episode: 498   score: 1.0   memory length: 89842   epsilon: 1.0    steps: 151     evaluation reward: 1.24\n",
      "episode: 499   score: 1.0   memory length: 90010   epsilon: 1.0    steps: 168     evaluation reward: 1.21\n",
      "episode: 500   score: 0.0   memory length: 90142   epsilon: 1.0    steps: 132     evaluation reward: 1.21\n",
      "episode: 501   score: 0.0   memory length: 90272   epsilon: 1.0    steps: 130     evaluation reward: 1.19\n",
      "episode: 502   score: 2.0   memory length: 90472   epsilon: 1.0    steps: 200     evaluation reward: 1.17\n",
      "episode: 503   score: 2.0   memory length: 90671   epsilon: 1.0    steps: 199     evaluation reward: 1.18\n",
      "episode: 504   score: 1.0   memory length: 90852   epsilon: 1.0    steps: 181     evaluation reward: 1.17\n",
      "episode: 505   score: 2.0   memory length: 91033   epsilon: 1.0    steps: 181     evaluation reward: 1.16\n",
      "episode: 506   score: 3.0   memory length: 91280   epsilon: 1.0    steps: 247     evaluation reward: 1.17\n",
      "episode: 507   score: 1.0   memory length: 91446   epsilon: 1.0    steps: 166     evaluation reward: 1.18\n",
      "episode: 508   score: 1.0   memory length: 91640   epsilon: 1.0    steps: 194     evaluation reward: 1.17\n",
      "episode: 509   score: 0.0   memory length: 91771   epsilon: 1.0    steps: 131     evaluation reward: 1.14\n",
      "episode: 510   score: 4.0   memory length: 92068   epsilon: 1.0    steps: 297     evaluation reward: 1.18\n",
      "episode: 511   score: 0.0   memory length: 92199   epsilon: 1.0    steps: 131     evaluation reward: 1.17\n",
      "episode: 512   score: 0.0   memory length: 92324   epsilon: 1.0    steps: 125     evaluation reward: 1.15\n",
      "episode: 513   score: 0.0   memory length: 92465   epsilon: 1.0    steps: 141     evaluation reward: 1.13\n",
      "episode: 514   score: 0.0   memory length: 92603   epsilon: 1.0    steps: 138     evaluation reward: 1.13\n",
      "episode: 515   score: 1.0   memory length: 92785   epsilon: 1.0    steps: 182     evaluation reward: 1.14\n",
      "episode: 516   score: 1.0   memory length: 92939   epsilon: 1.0    steps: 154     evaluation reward: 1.15\n",
      "episode: 517   score: 1.0   memory length: 93115   epsilon: 1.0    steps: 176     evaluation reward: 1.14\n",
      "episode: 518   score: 1.0   memory length: 93290   epsilon: 1.0    steps: 175     evaluation reward: 1.15\n",
      "episode: 519   score: 1.0   memory length: 93455   epsilon: 1.0    steps: 165     evaluation reward: 1.15\n",
      "episode: 520   score: 1.0   memory length: 93632   epsilon: 1.0    steps: 177     evaluation reward: 1.15\n",
      "episode: 521   score: 0.0   memory length: 93771   epsilon: 1.0    steps: 139     evaluation reward: 1.12\n",
      "episode: 522   score: 1.0   memory length: 93949   epsilon: 1.0    steps: 178     evaluation reward: 1.12\n",
      "episode: 523   score: 0.0   memory length: 94092   epsilon: 1.0    steps: 143     evaluation reward: 1.11\n",
      "episode: 524   score: 4.0   memory length: 94416   epsilon: 1.0    steps: 324     evaluation reward: 1.14\n",
      "episode: 525   score: 2.0   memory length: 94638   epsilon: 1.0    steps: 222     evaluation reward: 1.16\n",
      "episode: 526   score: 0.0   memory length: 94769   epsilon: 1.0    steps: 131     evaluation reward: 1.14\n",
      "episode: 527   score: 1.0   memory length: 94944   epsilon: 1.0    steps: 175     evaluation reward: 1.15\n",
      "episode: 528   score: 0.0   memory length: 95074   epsilon: 1.0    steps: 130     evaluation reward: 1.13\n",
      "episode: 529   score: 1.0   memory length: 95260   epsilon: 1.0    steps: 186     evaluation reward: 1.14\n",
      "episode: 530   score: 1.0   memory length: 95444   epsilon: 1.0    steps: 184     evaluation reward: 1.14\n",
      "episode: 531   score: 1.0   memory length: 95604   epsilon: 1.0    steps: 160     evaluation reward: 1.13\n",
      "episode: 532   score: 1.0   memory length: 95783   epsilon: 1.0    steps: 179     evaluation reward: 1.11\n",
      "episode: 533   score: 0.0   memory length: 95910   epsilon: 1.0    steps: 127     evaluation reward: 1.11\n",
      "episode: 534   score: 1.0   memory length: 96071   epsilon: 1.0    steps: 161     evaluation reward: 1.11\n",
      "episode: 535   score: 1.0   memory length: 96245   epsilon: 1.0    steps: 174     evaluation reward: 1.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 536   score: 2.0   memory length: 96450   epsilon: 1.0    steps: 205     evaluation reward: 1.14\n",
      "episode: 537   score: 0.0   memory length: 96577   epsilon: 1.0    steps: 127     evaluation reward: 1.11\n",
      "episode: 538   score: 1.0   memory length: 96732   epsilon: 1.0    steps: 155     evaluation reward: 1.11\n",
      "episode: 539   score: 2.0   memory length: 96935   epsilon: 1.0    steps: 203     evaluation reward: 1.13\n",
      "episode: 540   score: 0.0   memory length: 97061   epsilon: 1.0    steps: 126     evaluation reward: 1.11\n",
      "episode: 541   score: 0.0   memory length: 97187   epsilon: 1.0    steps: 126     evaluation reward: 1.09\n",
      "episode: 542   score: 4.0   memory length: 97469   epsilon: 1.0    steps: 282     evaluation reward: 1.12\n",
      "episode: 543   score: 2.0   memory length: 97672   epsilon: 1.0    steps: 203     evaluation reward: 1.13\n",
      "episode: 544   score: 1.0   memory length: 97841   epsilon: 1.0    steps: 169     evaluation reward: 1.14\n",
      "episode: 545   score: 0.0   memory length: 97975   epsilon: 1.0    steps: 134     evaluation reward: 1.13\n",
      "episode: 546   score: 4.0   memory length: 98252   epsilon: 1.0    steps: 277     evaluation reward: 1.16\n",
      "episode: 547   score: 1.0   memory length: 98428   epsilon: 1.0    steps: 176     evaluation reward: 1.17\n",
      "episode: 548   score: 3.0   memory length: 98659   epsilon: 1.0    steps: 231     evaluation reward: 1.19\n",
      "episode: 549   score: 0.0   memory length: 98796   epsilon: 1.0    steps: 137     evaluation reward: 1.16\n",
      "episode: 550   score: 1.0   memory length: 98951   epsilon: 1.0    steps: 155     evaluation reward: 1.16\n",
      "episode: 551   score: 1.0   memory length: 99113   epsilon: 1.0    steps: 162     evaluation reward: 1.14\n",
      "episode: 552   score: 2.0   memory length: 99300   epsilon: 1.0    steps: 187     evaluation reward: 1.16\n",
      "episode: 553   score: 0.0   memory length: 99434   epsilon: 1.0    steps: 134     evaluation reward: 1.15\n",
      "episode: 554   score: 1.0   memory length: 99604   epsilon: 1.0    steps: 170     evaluation reward: 1.15\n",
      "episode: 555   score: 2.0   memory length: 99829   epsilon: 1.0    steps: 225     evaluation reward: 1.15\n",
      "episode: 556   score: 0.0   memory length: 99960   epsilon: 1.0    steps: 131     evaluation reward: 1.13\n",
      "now time :  2018-12-14 07:46:20.788383\n",
      "episode: 557   score: 2.0   memory length: 100163   epsilon: 0.9998442000000001    steps: 203     evaluation reward: 1.15\n",
      "episode: 558   score: 1.0   memory length: 100329   epsilon: 0.9996865000000001    steps: 166     evaluation reward: 1.13\n",
      "episode: 559   score: 0.0   memory length: 100454   epsilon: 0.9995677500000002    steps: 125     evaluation reward: 1.12\n",
      "episode: 560   score: 1.0   memory length: 100615   epsilon: 0.9994148000000003    steps: 161     evaluation reward: 1.11\n",
      "episode: 561   score: 0.0   memory length: 100754   epsilon: 0.9992827500000003    steps: 139     evaluation reward: 1.1\n",
      "episode: 562   score: 0.0   memory length: 100895   epsilon: 0.9991488000000004    steps: 141     evaluation reward: 1.08\n",
      "episode: 563   score: 1.0   memory length: 101075   epsilon: 0.9989778000000005    steps: 180     evaluation reward: 1.06\n",
      "episode: 564   score: 0.0   memory length: 101208   epsilon: 0.9988514500000005    steps: 133     evaluation reward: 1.04\n",
      "episode: 565   score: 6.0   memory length: 101615   epsilon: 0.9984648000000007    steps: 407     evaluation reward: 1.09\n",
      "episode: 566   score: 1.0   memory length: 101793   epsilon: 0.9982957000000008    steps: 178     evaluation reward: 1.1\n",
      "episode: 567   score: 1.0   memory length: 101950   epsilon: 0.9981465500000009    steps: 157     evaluation reward: 1.09\n",
      "episode: 568   score: 0.0   memory length: 102082   epsilon: 0.9980211500000009    steps: 132     evaluation reward: 1.09\n",
      "episode: 569   score: 3.0   memory length: 102347   epsilon: 0.997769400000001    steps: 265     evaluation reward: 1.11\n",
      "episode: 570   score: 1.0   memory length: 102520   epsilon: 0.9976050500000011    steps: 173     evaluation reward: 1.12\n",
      "episode: 571   score: 0.0   memory length: 102650   epsilon: 0.9974815500000012    steps: 130     evaluation reward: 1.12\n",
      "episode: 572   score: 2.0   memory length: 102845   epsilon: 0.9972963000000012    steps: 195     evaluation reward: 1.14\n",
      "episode: 573   score: 0.0   memory length: 102974   epsilon: 0.9971737500000013    steps: 129     evaluation reward: 1.14\n",
      "episode: 574   score: 0.0   memory length: 103105   epsilon: 0.9970493000000014    steps: 131     evaluation reward: 1.13\n",
      "episode: 575   score: 2.0   memory length: 103313   epsilon: 0.9968517000000015    steps: 208     evaluation reward: 1.15\n",
      "episode: 576   score: 1.0   memory length: 103467   epsilon: 0.9967054000000015    steps: 154     evaluation reward: 1.15\n",
      "episode: 577   score: 1.0   memory length: 103665   epsilon: 0.9965173000000016    steps: 198     evaluation reward: 1.14\n",
      "episode: 578   score: 1.0   memory length: 103824   epsilon: 0.9963662500000017    steps: 159     evaluation reward: 1.12\n",
      "episode: 579   score: 1.0   memory length: 103984   epsilon: 0.9962142500000017    steps: 160     evaluation reward: 1.13\n",
      "episode: 580   score: 2.0   memory length: 104193   epsilon: 0.9960157000000018    steps: 209     evaluation reward: 1.14\n",
      "episode: 581   score: 0.0   memory length: 104325   epsilon: 0.9958903000000019    steps: 132     evaluation reward: 1.12\n",
      "episode: 582   score: 0.0   memory length: 104470   epsilon: 0.995752550000002    steps: 145     evaluation reward: 1.12\n",
      "episode: 583   score: 0.0   memory length: 104602   epsilon: 0.995627150000002    steps: 132     evaluation reward: 1.1\n",
      "episode: 584   score: 2.0   memory length: 104806   epsilon: 0.9954333500000021    steps: 204     evaluation reward: 1.12\n",
      "episode: 585   score: 2.0   memory length: 105003   epsilon: 0.9952462000000022    steps: 197     evaluation reward: 1.14\n",
      "episode: 586   score: 2.0   memory length: 105207   epsilon: 0.9950524000000023    steps: 204     evaluation reward: 1.14\n",
      "episode: 587   score: 3.0   memory length: 105461   epsilon: 0.9948111000000024    steps: 254     evaluation reward: 1.16\n",
      "episode: 588   score: 1.0   memory length: 105635   epsilon: 0.9946458000000025    steps: 174     evaluation reward: 1.17\n",
      "episode: 589   score: 0.0   memory length: 105763   epsilon: 0.9945242000000025    steps: 128     evaluation reward: 1.14\n",
      "episode: 590   score: 2.0   memory length: 105964   epsilon: 0.9943332500000026    steps: 201     evaluation reward: 1.14\n",
      "episode: 591   score: 0.0   memory length: 106102   epsilon: 0.9942021500000027    steps: 138     evaluation reward: 1.13\n",
      "episode: 592   score: 2.0   memory length: 106303   epsilon: 0.9940112000000028    steps: 201     evaluation reward: 1.15\n",
      "episode: 593   score: 1.0   memory length: 106464   epsilon: 0.9938582500000028    steps: 161     evaluation reward: 1.14\n",
      "episode: 594   score: 0.0   memory length: 106595   epsilon: 0.9937338000000029    steps: 131     evaluation reward: 1.12\n",
      "episode: 595   score: 2.0   memory length: 106808   epsilon: 0.993531450000003    steps: 213     evaluation reward: 1.14\n",
      "episode: 596   score: 1.0   memory length: 106972   epsilon: 0.993375650000003    steps: 164     evaluation reward: 1.15\n",
      "episode: 597   score: 2.0   memory length: 107178   epsilon: 0.9931799500000031    steps: 206     evaluation reward: 1.12\n",
      "episode: 598   score: 2.0   memory length: 107393   epsilon: 0.9929757000000032    steps: 215     evaluation reward: 1.13\n",
      "episode: 599   score: 3.0   memory length: 107642   epsilon: 0.9927391500000033    steps: 249     evaluation reward: 1.15\n",
      "episode: 600   score: 2.0   memory length: 107849   epsilon: 0.9925425000000034    steps: 207     evaluation reward: 1.17\n",
      "episode: 601   score: 1.0   memory length: 108038   epsilon: 0.9923629500000035    steps: 189     evaluation reward: 1.18\n",
      "episode: 602   score: 2.0   memory length: 108263   epsilon: 0.9921492000000036    steps: 225     evaluation reward: 1.18\n",
      "episode: 603   score: 2.0   memory length: 108465   epsilon: 0.9919573000000037    steps: 202     evaluation reward: 1.18\n",
      "episode: 604   score: 1.0   memory length: 108627   epsilon: 0.9918034000000038    steps: 162     evaluation reward: 1.18\n",
      "episode: 605   score: 1.0   memory length: 108785   epsilon: 0.9916533000000038    steps: 158     evaluation reward: 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 606   score: 3.0   memory length: 109005   epsilon: 0.9914443000000039    steps: 220     evaluation reward: 1.17\n",
      "episode: 607   score: 1.0   memory length: 109172   epsilon: 0.991285650000004    steps: 167     evaluation reward: 1.17\n",
      "episode: 608   score: 1.0   memory length: 109345   epsilon: 0.9911213000000041    steps: 173     evaluation reward: 1.17\n",
      "episode: 609   score: 0.0   memory length: 109472   epsilon: 0.9910006500000041    steps: 127     evaluation reward: 1.17\n",
      "episode: 610   score: 1.0   memory length: 109644   epsilon: 0.9908372500000042    steps: 172     evaluation reward: 1.14\n",
      "episode: 611   score: 0.0   memory length: 109780   epsilon: 0.9907080500000043    steps: 136     evaluation reward: 1.14\n",
      "episode: 612   score: 1.0   memory length: 109935   epsilon: 0.9905608000000043    steps: 155     evaluation reward: 1.15\n",
      "episode: 613   score: 2.0   memory length: 110149   epsilon: 0.9903575000000044    steps: 214     evaluation reward: 1.17\n",
      "episode: 614   score: 1.0   memory length: 110321   epsilon: 0.9901941000000045    steps: 172     evaluation reward: 1.18\n",
      "episode: 615   score: 0.0   memory length: 110463   epsilon: 0.9900592000000046    steps: 142     evaluation reward: 1.17\n",
      "episode: 616   score: 2.0   memory length: 110661   epsilon: 0.9898711000000047    steps: 198     evaluation reward: 1.18\n",
      "episode: 617   score: 1.0   memory length: 110834   epsilon: 0.9897067500000047    steps: 173     evaluation reward: 1.18\n",
      "episode: 618   score: 4.0   memory length: 111111   epsilon: 0.9894436000000049    steps: 277     evaluation reward: 1.21\n",
      "episode: 619   score: 3.0   memory length: 111352   epsilon: 0.989214650000005    steps: 241     evaluation reward: 1.23\n",
      "episode: 620   score: 1.0   memory length: 111527   epsilon: 0.989048400000005    steps: 175     evaluation reward: 1.23\n",
      "episode: 621   score: 1.0   memory length: 111710   epsilon: 0.9888745500000051    steps: 183     evaluation reward: 1.24\n",
      "episode: 622   score: 3.0   memory length: 111963   epsilon: 0.9886342000000052    steps: 253     evaluation reward: 1.26\n",
      "episode: 623   score: 2.0   memory length: 112184   epsilon: 0.9884242500000053    steps: 221     evaluation reward: 1.28\n",
      "episode: 624   score: 2.0   memory length: 112385   epsilon: 0.9882333000000054    steps: 201     evaluation reward: 1.26\n",
      "episode: 625   score: 1.0   memory length: 112563   epsilon: 0.9880642000000055    steps: 178     evaluation reward: 1.25\n",
      "episode: 626   score: 0.0   memory length: 112699   epsilon: 0.9879350000000056    steps: 136     evaluation reward: 1.25\n",
      "episode: 627   score: 0.0   memory length: 112833   epsilon: 0.9878077000000056    steps: 134     evaluation reward: 1.24\n",
      "episode: 628   score: 3.0   memory length: 113101   epsilon: 0.9875531000000057    steps: 268     evaluation reward: 1.27\n",
      "episode: 629   score: 0.0   memory length: 113229   epsilon: 0.9874315000000058    steps: 128     evaluation reward: 1.26\n",
      "episode: 630   score: 1.0   memory length: 113403   epsilon: 0.9872662000000059    steps: 174     evaluation reward: 1.26\n",
      "episode: 631   score: 1.0   memory length: 113564   epsilon: 0.9871132500000059    steps: 161     evaluation reward: 1.26\n",
      "episode: 632   score: 2.0   memory length: 113755   epsilon: 0.986931800000006    steps: 191     evaluation reward: 1.27\n",
      "episode: 633   score: 3.0   memory length: 113992   epsilon: 0.9867066500000061    steps: 237     evaluation reward: 1.3\n",
      "episode: 634   score: 2.0   memory length: 114210   epsilon: 0.9864995500000062    steps: 218     evaluation reward: 1.31\n",
      "episode: 635   score: 0.0   memory length: 114342   epsilon: 0.9863741500000063    steps: 132     evaluation reward: 1.3\n",
      "episode: 636   score: 2.0   memory length: 114528   epsilon: 0.9861974500000064    steps: 186     evaluation reward: 1.3\n",
      "episode: 637   score: 0.0   memory length: 114660   epsilon: 0.9860720500000064    steps: 132     evaluation reward: 1.3\n",
      "episode: 638   score: 2.0   memory length: 114864   epsilon: 0.9858782500000065    steps: 204     evaluation reward: 1.31\n",
      "episode: 639   score: 3.0   memory length: 115111   epsilon: 0.9856436000000066    steps: 247     evaluation reward: 1.32\n",
      "episode: 640   score: 1.0   memory length: 115286   epsilon: 0.9854773500000067    steps: 175     evaluation reward: 1.33\n",
      "episode: 641   score: 3.0   memory length: 115565   epsilon: 0.9852123000000068    steps: 279     evaluation reward: 1.36\n",
      "episode: 642   score: 0.0   memory length: 115709   epsilon: 0.9850755000000069    steps: 144     evaluation reward: 1.32\n",
      "episode: 643   score: 1.0   memory length: 115872   epsilon: 0.984920650000007    steps: 163     evaluation reward: 1.31\n",
      "episode: 644   score: 2.0   memory length: 116065   epsilon: 0.984737300000007    steps: 193     evaluation reward: 1.32\n",
      "episode: 645   score: 3.0   memory length: 116305   epsilon: 0.9845093000000071    steps: 240     evaluation reward: 1.35\n",
      "episode: 646   score: 0.0   memory length: 116443   epsilon: 0.9843782000000072    steps: 138     evaluation reward: 1.31\n",
      "episode: 647   score: 0.0   memory length: 116571   epsilon: 0.9842566000000073    steps: 128     evaluation reward: 1.3\n",
      "episode: 648   score: 0.0   memory length: 116705   epsilon: 0.9841293000000073    steps: 134     evaluation reward: 1.27\n",
      "episode: 649   score: 2.0   memory length: 116920   epsilon: 0.9839250500000074    steps: 215     evaluation reward: 1.29\n",
      "episode: 650   score: 1.0   memory length: 117074   epsilon: 0.9837787500000075    steps: 154     evaluation reward: 1.29\n",
      "episode: 651   score: 1.0   memory length: 117229   epsilon: 0.9836315000000075    steps: 155     evaluation reward: 1.29\n",
      "episode: 652   score: 3.0   memory length: 117483   epsilon: 0.9833902000000077    steps: 254     evaluation reward: 1.3\n",
      "episode: 653   score: 1.0   memory length: 117666   epsilon: 0.9832163500000077    steps: 183     evaluation reward: 1.31\n",
      "episode: 654   score: 3.0   memory length: 117922   epsilon: 0.9829731500000078    steps: 256     evaluation reward: 1.33\n",
      "episode: 655   score: 1.0   memory length: 118103   epsilon: 0.9828012000000079    steps: 181     evaluation reward: 1.32\n",
      "episode: 656   score: 0.0   memory length: 118236   epsilon: 0.982674850000008    steps: 133     evaluation reward: 1.32\n",
      "episode: 657   score: 3.0   memory length: 118457   epsilon: 0.9824649000000081    steps: 221     evaluation reward: 1.33\n",
      "episode: 658   score: 1.0   memory length: 118620   epsilon: 0.9823100500000082    steps: 163     evaluation reward: 1.33\n",
      "episode: 659   score: 1.0   memory length: 118776   epsilon: 0.9821618500000082    steps: 156     evaluation reward: 1.34\n",
      "episode: 660   score: 0.0   memory length: 118910   epsilon: 0.9820345500000083    steps: 134     evaluation reward: 1.33\n",
      "episode: 661   score: 1.0   memory length: 119063   epsilon: 0.9818892000000083    steps: 153     evaluation reward: 1.34\n",
      "episode: 662   score: 1.0   memory length: 119217   epsilon: 0.9817429000000084    steps: 154     evaluation reward: 1.35\n",
      "episode: 663   score: 1.0   memory length: 119383   epsilon: 0.9815852000000085    steps: 166     evaluation reward: 1.35\n",
      "episode: 664   score: 0.0   memory length: 119519   epsilon: 0.9814560000000085    steps: 136     evaluation reward: 1.35\n",
      "episode: 665   score: 1.0   memory length: 119700   epsilon: 0.9812840500000086    steps: 181     evaluation reward: 1.3\n",
      "episode: 666   score: 3.0   memory length: 119933   epsilon: 0.9810627000000087    steps: 233     evaluation reward: 1.32\n",
      "episode: 667   score: 2.0   memory length: 120137   epsilon: 0.9808689000000088    steps: 204     evaluation reward: 1.33\n",
      "episode: 668   score: 0.0   memory length: 120271   epsilon: 0.9807416000000089    steps: 134     evaluation reward: 1.33\n",
      "episode: 669   score: 0.0   memory length: 120395   epsilon: 0.9806238000000089    steps: 124     evaluation reward: 1.3\n",
      "episode: 670   score: 3.0   memory length: 120666   epsilon: 0.980366350000009    steps: 271     evaluation reward: 1.32\n",
      "episode: 671   score: 0.0   memory length: 120792   epsilon: 0.9802466500000091    steps: 126     evaluation reward: 1.32\n",
      "episode: 672   score: 0.0   memory length: 120943   epsilon: 0.9801032000000092    steps: 151     evaluation reward: 1.3\n",
      "episode: 673   score: 0.0   memory length: 121082   epsilon: 0.9799711500000092    steps: 139     evaluation reward: 1.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 674   score: 1.0   memory length: 121267   epsilon: 0.9797954000000093    steps: 185     evaluation reward: 1.31\n",
      "episode: 675   score: 1.0   memory length: 121426   epsilon: 0.9796443500000094    steps: 159     evaluation reward: 1.3\n",
      "episode: 676   score: 0.0   memory length: 121562   epsilon: 0.9795151500000094    steps: 136     evaluation reward: 1.29\n",
      "episode: 677   score: 2.0   memory length: 121750   epsilon: 0.9793365500000095    steps: 188     evaluation reward: 1.3\n",
      "episode: 678   score: 0.0   memory length: 121876   epsilon: 0.9792168500000096    steps: 126     evaluation reward: 1.29\n",
      "episode: 679   score: 5.0   memory length: 122200   epsilon: 0.9789090500000097    steps: 324     evaluation reward: 1.33\n",
      "episode: 680   score: 0.0   memory length: 122330   epsilon: 0.9787855500000098    steps: 130     evaluation reward: 1.31\n",
      "episode: 681   score: 2.0   memory length: 122544   epsilon: 0.9785822500000099    steps: 214     evaluation reward: 1.33\n",
      "episode: 682   score: 0.0   memory length: 122671   epsilon: 0.9784616000000099    steps: 127     evaluation reward: 1.33\n",
      "episode: 683   score: 0.0   memory length: 122803   epsilon: 0.97833620000001    steps: 132     evaluation reward: 1.33\n",
      "episode: 684   score: 1.0   memory length: 122975   epsilon: 0.9781728000000101    steps: 172     evaluation reward: 1.32\n",
      "episode: 685   score: 0.0   memory length: 123103   epsilon: 0.9780512000000101    steps: 128     evaluation reward: 1.3\n",
      "episode: 686   score: 1.0   memory length: 123291   epsilon: 0.9778726000000102    steps: 188     evaluation reward: 1.29\n",
      "episode: 687   score: 2.0   memory length: 123495   epsilon: 0.9776788000000103    steps: 204     evaluation reward: 1.28\n",
      "episode: 688   score: 3.0   memory length: 123718   epsilon: 0.9774669500000104    steps: 223     evaluation reward: 1.3\n",
      "episode: 689   score: 3.0   memory length: 123966   epsilon: 0.9772313500000105    steps: 248     evaluation reward: 1.33\n",
      "episode: 690   score: 0.0   memory length: 124100   epsilon: 0.9771040500000105    steps: 134     evaluation reward: 1.31\n",
      "episode: 691   score: 1.0   memory length: 124273   epsilon: 0.9769397000000106    steps: 173     evaluation reward: 1.32\n",
      "episode: 692   score: 1.0   memory length: 124429   epsilon: 0.9767915000000107    steps: 156     evaluation reward: 1.31\n",
      "episode: 693   score: 0.0   memory length: 124554   epsilon: 0.9766727500000107    steps: 125     evaluation reward: 1.3\n",
      "episode: 694   score: 3.0   memory length: 124806   epsilon: 0.9764333500000109    steps: 252     evaluation reward: 1.33\n",
      "episode: 695   score: 1.0   memory length: 124988   epsilon: 0.9762604500000109    steps: 182     evaluation reward: 1.32\n",
      "episode: 696   score: 2.0   memory length: 125187   epsilon: 0.976071400000011    steps: 199     evaluation reward: 1.33\n",
      "episode: 697   score: 0.0   memory length: 125324   epsilon: 0.9759412500000111    steps: 137     evaluation reward: 1.31\n",
      "episode: 698   score: 0.0   memory length: 125458   epsilon: 0.9758139500000111    steps: 134     evaluation reward: 1.29\n",
      "episode: 699   score: 0.0   memory length: 125592   epsilon: 0.9756866500000112    steps: 134     evaluation reward: 1.26\n",
      "episode: 700   score: 0.0   memory length: 125721   epsilon: 0.9755641000000113    steps: 129     evaluation reward: 1.24\n",
      "episode: 701   score: 0.0   memory length: 125854   epsilon: 0.9754377500000113    steps: 133     evaluation reward: 1.23\n",
      "episode: 702   score: 1.0   memory length: 126011   epsilon: 0.9752886000000114    steps: 157     evaluation reward: 1.22\n",
      "episode: 703   score: 0.0   memory length: 126150   epsilon: 0.9751565500000114    steps: 139     evaluation reward: 1.2\n",
      "episode: 704   score: 1.0   memory length: 126338   epsilon: 0.9749779500000115    steps: 188     evaluation reward: 1.2\n",
      "episode: 705   score: 1.0   memory length: 126516   epsilon: 0.9748088500000116    steps: 178     evaluation reward: 1.2\n",
      "episode: 706   score: 0.0   memory length: 126655   epsilon: 0.9746768000000117    steps: 139     evaluation reward: 1.17\n",
      "episode: 707   score: 0.0   memory length: 126806   epsilon: 0.9745333500000117    steps: 151     evaluation reward: 1.16\n",
      "episode: 708   score: 0.0   memory length: 126932   epsilon: 0.9744136500000118    steps: 126     evaluation reward: 1.15\n",
      "episode: 709   score: 0.0   memory length: 127061   epsilon: 0.9742911000000118    steps: 129     evaluation reward: 1.15\n",
      "episode: 710   score: 0.0   memory length: 127193   epsilon: 0.9741657000000119    steps: 132     evaluation reward: 1.14\n",
      "episode: 711   score: 2.0   memory length: 127384   epsilon: 0.973984250000012    steps: 191     evaluation reward: 1.16\n",
      "episode: 712   score: 1.0   memory length: 127567   epsilon: 0.9738104000000121    steps: 183     evaluation reward: 1.16\n",
      "episode: 713   score: 1.0   memory length: 127750   epsilon: 0.9736365500000121    steps: 183     evaluation reward: 1.15\n",
      "episode: 714   score: 3.0   memory length: 127986   epsilon: 0.9734123500000122    steps: 236     evaluation reward: 1.17\n",
      "episode: 715   score: 0.0   memory length: 128116   epsilon: 0.9732888500000123    steps: 130     evaluation reward: 1.17\n",
      "episode: 716   score: 0.0   memory length: 128247   epsilon: 0.9731644000000124    steps: 131     evaluation reward: 1.15\n",
      "episode: 717   score: 1.0   memory length: 128436   epsilon: 0.9729848500000124    steps: 189     evaluation reward: 1.15\n",
      "episode: 718   score: 1.0   memory length: 128595   epsilon: 0.9728338000000125    steps: 159     evaluation reward: 1.12\n",
      "episode: 719   score: 0.0   memory length: 128721   epsilon: 0.9727141000000126    steps: 126     evaluation reward: 1.09\n",
      "episode: 720   score: 2.0   memory length: 128930   epsilon: 0.9725155500000127    steps: 209     evaluation reward: 1.1\n",
      "episode: 721   score: 1.0   memory length: 129117   epsilon: 0.9723379000000127    steps: 187     evaluation reward: 1.1\n",
      "episode: 722   score: 0.0   memory length: 129257   epsilon: 0.9722049000000128    steps: 140     evaluation reward: 1.07\n",
      "episode: 723   score: 1.0   memory length: 129420   epsilon: 0.9720500500000129    steps: 163     evaluation reward: 1.06\n",
      "episode: 724   score: 2.0   memory length: 129627   epsilon: 0.971853400000013    steps: 207     evaluation reward: 1.06\n",
      "episode: 725   score: 3.0   memory length: 129855   epsilon: 0.9716368000000131    steps: 228     evaluation reward: 1.08\n",
      "episode: 726   score: 0.0   memory length: 129994   epsilon: 0.9715047500000131    steps: 139     evaluation reward: 1.08\n",
      "episode: 727   score: 0.0   memory length: 130132   epsilon: 0.9713736500000132    steps: 138     evaluation reward: 1.08\n",
      "episode: 728   score: 0.0   memory length: 130263   epsilon: 0.9712492000000132    steps: 131     evaluation reward: 1.05\n",
      "episode: 729   score: 1.0   memory length: 130423   epsilon: 0.9710972000000133    steps: 160     evaluation reward: 1.06\n",
      "episode: 730   score: 0.0   memory length: 130561   epsilon: 0.9709661000000134    steps: 138     evaluation reward: 1.05\n",
      "episode: 731   score: 3.0   memory length: 130816   epsilon: 0.9707238500000135    steps: 255     evaluation reward: 1.07\n",
      "episode: 732   score: 1.0   memory length: 130980   epsilon: 0.9705680500000136    steps: 164     evaluation reward: 1.06\n",
      "episode: 733   score: 0.0   memory length: 131108   epsilon: 0.9704464500000136    steps: 128     evaluation reward: 1.03\n",
      "episode: 734   score: 1.0   memory length: 131306   epsilon: 0.9702583500000137    steps: 198     evaluation reward: 1.02\n",
      "episode: 735   score: 2.0   memory length: 131496   epsilon: 0.9700778500000138    steps: 190     evaluation reward: 1.04\n",
      "episode: 736   score: 1.0   memory length: 131683   epsilon: 0.9699002000000139    steps: 187     evaluation reward: 1.03\n",
      "episode: 737   score: 2.0   memory length: 131866   epsilon: 0.969726350000014    steps: 183     evaluation reward: 1.05\n",
      "episode: 738   score: 2.0   memory length: 132072   epsilon: 0.969530650000014    steps: 206     evaluation reward: 1.05\n",
      "episode: 739   score: 1.0   memory length: 132239   epsilon: 0.9693720000000141    steps: 167     evaluation reward: 1.03\n",
      "episode: 740   score: 4.0   memory length: 132526   epsilon: 0.9690993500000142    steps: 287     evaluation reward: 1.06\n",
      "episode: 741   score: 0.0   memory length: 132660   epsilon: 0.9689720500000143    steps: 134     evaluation reward: 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 742   score: 0.0   memory length: 132812   epsilon: 0.9688276500000144    steps: 152     evaluation reward: 1.03\n",
      "episode: 743   score: 0.0   memory length: 132939   epsilon: 0.9687070000000144    steps: 127     evaluation reward: 1.02\n",
      "episode: 744   score: 2.0   memory length: 133163   epsilon: 0.9684942000000145    steps: 224     evaluation reward: 1.02\n",
      "episode: 745   score: 2.0   memory length: 133368   epsilon: 0.9682994500000146    steps: 205     evaluation reward: 1.01\n",
      "episode: 746   score: 3.0   memory length: 133608   epsilon: 0.9680714500000147    steps: 240     evaluation reward: 1.04\n",
      "episode: 747   score: 2.0   memory length: 133820   epsilon: 0.9678700500000148    steps: 212     evaluation reward: 1.06\n",
      "episode: 748   score: 2.0   memory length: 134013   epsilon: 0.9676867000000149    steps: 193     evaluation reward: 1.08\n",
      "episode: 749   score: 0.0   memory length: 134142   epsilon: 0.9675641500000149    steps: 129     evaluation reward: 1.06\n",
      "episode: 750   score: 2.0   memory length: 134346   epsilon: 0.967370350000015    steps: 204     evaluation reward: 1.07\n",
      "episode: 751   score: 0.0   memory length: 134473   epsilon: 0.9672497000000151    steps: 127     evaluation reward: 1.06\n",
      "episode: 752   score: 0.0   memory length: 134607   epsilon: 0.9671224000000151    steps: 134     evaluation reward: 1.03\n",
      "episode: 753   score: 1.0   memory length: 134775   epsilon: 0.9669628000000152    steps: 168     evaluation reward: 1.03\n",
      "episode: 754   score: 2.0   memory length: 135001   epsilon: 0.9667481000000153    steps: 226     evaluation reward: 1.02\n",
      "episode: 755   score: 0.0   memory length: 135136   epsilon: 0.9666198500000154    steps: 135     evaluation reward: 1.01\n",
      "episode: 756   score: 2.0   memory length: 135340   epsilon: 0.9664260500000155    steps: 204     evaluation reward: 1.03\n",
      "episode: 757   score: 2.0   memory length: 135572   epsilon: 0.9662056500000156    steps: 232     evaluation reward: 1.02\n",
      "episode: 758   score: 2.0   memory length: 135779   epsilon: 0.9660090000000157    steps: 207     evaluation reward: 1.03\n",
      "episode: 759   score: 0.0   memory length: 135916   epsilon: 0.9658788500000157    steps: 137     evaluation reward: 1.02\n",
      "episode: 760   score: 1.0   memory length: 136078   epsilon: 0.9657249500000158    steps: 162     evaluation reward: 1.03\n",
      "episode: 761   score: 1.0   memory length: 136238   epsilon: 0.9655729500000159    steps: 160     evaluation reward: 1.03\n",
      "episode: 762   score: 2.0   memory length: 136437   epsilon: 0.965383900000016    steps: 199     evaluation reward: 1.04\n",
      "episode: 763   score: 0.0   memory length: 136569   epsilon: 0.965258500000016    steps: 132     evaluation reward: 1.03\n",
      "episode: 764   score: 3.0   memory length: 136785   epsilon: 0.9650533000000161    steps: 216     evaluation reward: 1.06\n",
      "episode: 765   score: 0.0   memory length: 136911   epsilon: 0.9649336000000162    steps: 126     evaluation reward: 1.05\n",
      "episode: 766   score: 0.0   memory length: 137041   epsilon: 0.9648101000000162    steps: 130     evaluation reward: 1.02\n",
      "episode: 767   score: 0.0   memory length: 137168   epsilon: 0.9646894500000163    steps: 127     evaluation reward: 1.0\n",
      "episode: 768   score: 0.0   memory length: 137304   epsilon: 0.9645602500000163    steps: 136     evaluation reward: 1.0\n",
      "episode: 769   score: 3.0   memory length: 137541   epsilon: 0.9643351000000164    steps: 237     evaluation reward: 1.03\n",
      "episode: 770   score: 1.0   memory length: 137712   epsilon: 0.9641726500000165    steps: 171     evaluation reward: 1.01\n",
      "episode: 771   score: 1.0   memory length: 137872   epsilon: 0.9640206500000166    steps: 160     evaluation reward: 1.02\n",
      "episode: 772   score: 1.0   memory length: 138053   epsilon: 0.9638487000000167    steps: 181     evaluation reward: 1.03\n",
      "episode: 773   score: 3.0   memory length: 138301   epsilon: 0.9636131000000168    steps: 248     evaluation reward: 1.06\n",
      "episode: 774   score: 0.0   memory length: 138439   epsilon: 0.9634820000000168    steps: 138     evaluation reward: 1.05\n",
      "episode: 775   score: 0.0   memory length: 138566   epsilon: 0.9633613500000169    steps: 127     evaluation reward: 1.04\n",
      "episode: 776   score: 2.0   memory length: 138764   epsilon: 0.963173250000017    steps: 198     evaluation reward: 1.06\n",
      "episode: 777   score: 3.0   memory length: 138996   epsilon: 0.9629528500000171    steps: 232     evaluation reward: 1.07\n",
      "episode: 778   score: 1.0   memory length: 139157   epsilon: 0.9627999000000171    steps: 161     evaluation reward: 1.08\n",
      "episode: 779   score: 2.0   memory length: 139362   epsilon: 0.9626051500000172    steps: 205     evaluation reward: 1.05\n",
      "episode: 780   score: 2.0   memory length: 139553   epsilon: 0.9624237000000173    steps: 191     evaluation reward: 1.07\n",
      "episode: 781   score: 2.0   memory length: 139760   epsilon: 0.9622270500000174    steps: 207     evaluation reward: 1.07\n",
      "episode: 782   score: 0.0   memory length: 139885   epsilon: 0.9621083000000175    steps: 125     evaluation reward: 1.07\n",
      "episode: 783   score: 1.0   memory length: 140038   epsilon: 0.9619629500000175    steps: 153     evaluation reward: 1.08\n",
      "episode: 784   score: 0.0   memory length: 140169   epsilon: 0.9618385000000176    steps: 131     evaluation reward: 1.07\n",
      "episode: 785   score: 1.0   memory length: 140325   epsilon: 0.9616903000000177    steps: 156     evaluation reward: 1.08\n",
      "episode: 786   score: 0.0   memory length: 140456   epsilon: 0.9615658500000177    steps: 131     evaluation reward: 1.07\n",
      "episode: 787   score: 0.0   memory length: 140587   epsilon: 0.9614414000000178    steps: 131     evaluation reward: 1.05\n",
      "episode: 788   score: 1.0   memory length: 140739   epsilon: 0.9612970000000178    steps: 152     evaluation reward: 1.03\n",
      "episode: 789   score: 0.0   memory length: 140872   epsilon: 0.9611706500000179    steps: 133     evaluation reward: 1.0\n",
      "episode: 790   score: 1.0   memory length: 141026   epsilon: 0.961024350000018    steps: 154     evaluation reward: 1.01\n",
      "episode: 791   score: 0.0   memory length: 141163   epsilon: 0.960894200000018    steps: 137     evaluation reward: 1.0\n",
      "episode: 792   score: 2.0   memory length: 141350   epsilon: 0.9607165500000181    steps: 187     evaluation reward: 1.01\n",
      "episode: 793   score: 3.0   memory length: 141584   epsilon: 0.9604942500000182    steps: 234     evaluation reward: 1.04\n",
      "episode: 794   score: 2.0   memory length: 141765   epsilon: 0.9603223000000183    steps: 181     evaluation reward: 1.03\n",
      "episode: 795   score: 3.0   memory length: 142020   epsilon: 0.9600800500000184    steps: 255     evaluation reward: 1.05\n",
      "episode: 796   score: 3.0   memory length: 142269   epsilon: 0.9598435000000185    steps: 249     evaluation reward: 1.06\n",
      "episode: 797   score: 3.0   memory length: 142499   epsilon: 0.9596250000000186    steps: 230     evaluation reward: 1.09\n",
      "episode: 798   score: 1.0   memory length: 142690   epsilon: 0.9594435500000187    steps: 191     evaluation reward: 1.1\n",
      "episode: 799   score: 1.0   memory length: 142850   epsilon: 0.9592915500000188    steps: 160     evaluation reward: 1.11\n",
      "episode: 800   score: 0.0   memory length: 142983   epsilon: 0.9591652000000188    steps: 133     evaluation reward: 1.11\n",
      "episode: 801   score: 2.0   memory length: 143191   epsilon: 0.9589676000000189    steps: 208     evaluation reward: 1.13\n",
      "episode: 802   score: 3.0   memory length: 143427   epsilon: 0.958743400000019    steps: 236     evaluation reward: 1.15\n",
      "episode: 803   score: 2.0   memory length: 143640   epsilon: 0.9585410500000191    steps: 213     evaluation reward: 1.17\n",
      "episode: 804   score: 0.0   memory length: 143779   epsilon: 0.9584090000000192    steps: 139     evaluation reward: 1.16\n",
      "episode: 805   score: 1.0   memory length: 143933   epsilon: 0.9582627000000192    steps: 154     evaluation reward: 1.16\n",
      "episode: 806   score: 0.0   memory length: 144066   epsilon: 0.9581363500000193    steps: 133     evaluation reward: 1.16\n",
      "episode: 807   score: 1.0   memory length: 144243   epsilon: 0.9579682000000194    steps: 177     evaluation reward: 1.17\n",
      "episode: 808   score: 3.0   memory length: 144506   epsilon: 0.9577183500000195    steps: 263     evaluation reward: 1.2\n",
      "episode: 809   score: 0.0   memory length: 144646   epsilon: 0.9575853500000195    steps: 140     evaluation reward: 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 810   score: 3.0   memory length: 144874   epsilon: 0.9573687500000196    steps: 228     evaluation reward: 1.23\n",
      "episode: 811   score: 1.0   memory length: 145031   epsilon: 0.9572196000000197    steps: 157     evaluation reward: 1.22\n",
      "episode: 812   score: 0.0   memory length: 145166   epsilon: 0.9570913500000198    steps: 135     evaluation reward: 1.21\n",
      "episode: 813   score: 3.0   memory length: 145382   epsilon: 0.9568861500000199    steps: 216     evaluation reward: 1.23\n",
      "episode: 814   score: 2.0   memory length: 145571   epsilon: 0.95670660000002    steps: 189     evaluation reward: 1.22\n",
      "episode: 815   score: 2.0   memory length: 145785   epsilon: 0.95650330000002    steps: 214     evaluation reward: 1.24\n",
      "episode: 816   score: 4.0   memory length: 146082   epsilon: 0.9562211500000202    steps: 297     evaluation reward: 1.28\n",
      "episode: 817   score: 1.0   memory length: 146234   epsilon: 0.9560767500000202    steps: 152     evaluation reward: 1.28\n",
      "episode: 818   score: 1.0   memory length: 146424   epsilon: 0.9558962500000203    steps: 190     evaluation reward: 1.28\n",
      "episode: 819   score: 3.0   memory length: 146656   epsilon: 0.9556758500000204    steps: 232     evaluation reward: 1.31\n",
      "episode: 820   score: 1.0   memory length: 146827   epsilon: 0.9555134000000205    steps: 171     evaluation reward: 1.3\n",
      "episode: 821   score: 0.0   memory length: 146965   epsilon: 0.9553823000000206    steps: 138     evaluation reward: 1.29\n",
      "episode: 822   score: 2.0   memory length: 147171   epsilon: 0.9551866000000206    steps: 206     evaluation reward: 1.31\n",
      "episode: 823   score: 2.0   memory length: 147400   epsilon: 0.9549690500000207    steps: 229     evaluation reward: 1.32\n",
      "episode: 824   score: 2.0   memory length: 147613   epsilon: 0.9547667000000208    steps: 213     evaluation reward: 1.32\n",
      "episode: 825   score: 0.0   memory length: 147746   epsilon: 0.9546403500000209    steps: 133     evaluation reward: 1.29\n",
      "episode: 826   score: 5.0   memory length: 148064   epsilon: 0.954338250000021    steps: 318     evaluation reward: 1.34\n",
      "episode: 827   score: 2.0   memory length: 148283   epsilon: 0.9541302000000211    steps: 219     evaluation reward: 1.36\n",
      "episode: 828   score: 1.0   memory length: 148445   epsilon: 0.9539763000000212    steps: 162     evaluation reward: 1.37\n",
      "episode: 829   score: 1.0   memory length: 148609   epsilon: 0.9538205000000213    steps: 164     evaluation reward: 1.37\n",
      "episode: 830   score: 1.0   memory length: 148801   epsilon: 0.9536381000000214    steps: 192     evaluation reward: 1.38\n",
      "episode: 831   score: 1.0   memory length: 148978   epsilon: 0.9534699500000214    steps: 177     evaluation reward: 1.36\n",
      "episode: 832   score: 2.0   memory length: 149177   epsilon: 0.9532809000000215    steps: 199     evaluation reward: 1.37\n",
      "episode: 833   score: 0.0   memory length: 149303   epsilon: 0.9531612000000216    steps: 126     evaluation reward: 1.37\n",
      "episode: 834   score: 1.0   memory length: 149482   epsilon: 0.9529911500000217    steps: 179     evaluation reward: 1.37\n",
      "episode: 835   score: 1.0   memory length: 149648   epsilon: 0.9528334500000217    steps: 166     evaluation reward: 1.36\n",
      "episode: 836   score: 2.0   memory length: 149836   epsilon: 0.9526548500000218    steps: 188     evaluation reward: 1.37\n",
      "now time :  2018-12-14 07:59:10.080632\n",
      "episode: 837   score: 1.0   memory length: 150006   epsilon: 0.9524933500000219    steps: 170     evaluation reward: 1.36\n",
      "episode: 838   score: 3.0   memory length: 150271   epsilon: 0.952241600000022    steps: 265     evaluation reward: 1.37\n",
      "episode: 839   score: 1.0   memory length: 150453   epsilon: 0.9520687000000221    steps: 182     evaluation reward: 1.37\n",
      "episode: 840   score: 1.0   memory length: 150611   epsilon: 0.9519186000000222    steps: 158     evaluation reward: 1.34\n",
      "episode: 841   score: 4.0   memory length: 150860   epsilon: 0.9516820500000223    steps: 249     evaluation reward: 1.38\n",
      "episode: 842   score: 2.0   memory length: 151084   epsilon: 0.9514692500000224    steps: 224     evaluation reward: 1.4\n",
      "episode: 843   score: 0.0   memory length: 151210   epsilon: 0.9513495500000224    steps: 126     evaluation reward: 1.4\n",
      "episode: 844   score: 3.0   memory length: 151456   epsilon: 0.9511158500000225    steps: 246     evaluation reward: 1.41\n",
      "episode: 845   score: 3.0   memory length: 151709   epsilon: 0.9508755000000226    steps: 253     evaluation reward: 1.42\n",
      "episode: 846   score: 2.0   memory length: 151913   epsilon: 0.9506817000000227    steps: 204     evaluation reward: 1.41\n",
      "episode: 847   score: 2.0   memory length: 152096   epsilon: 0.9505078500000228    steps: 183     evaluation reward: 1.41\n",
      "episode: 848   score: 0.0   memory length: 152239   epsilon: 0.9503720000000229    steps: 143     evaluation reward: 1.39\n",
      "episode: 849   score: 4.0   memory length: 152517   epsilon: 0.950107900000023    steps: 278     evaluation reward: 1.43\n",
      "episode: 850   score: 4.0   memory length: 152807   epsilon: 0.9498324000000231    steps: 290     evaluation reward: 1.45\n",
      "episode: 851   score: 0.0   memory length: 152937   epsilon: 0.9497089000000232    steps: 130     evaluation reward: 1.45\n",
      "episode: 852   score: 2.0   memory length: 153123   epsilon: 0.9495322000000233    steps: 186     evaluation reward: 1.47\n",
      "episode: 853   score: 2.0   memory length: 153308   epsilon: 0.9493564500000233    steps: 185     evaluation reward: 1.48\n",
      "episode: 854   score: 1.0   memory length: 153481   epsilon: 0.9491921000000234    steps: 173     evaluation reward: 1.47\n",
      "episode: 855   score: 4.0   memory length: 153762   epsilon: 0.9489251500000235    steps: 281     evaluation reward: 1.51\n",
      "episode: 856   score: 1.0   memory length: 153915   epsilon: 0.9487798000000236    steps: 153     evaluation reward: 1.5\n",
      "episode: 857   score: 1.0   memory length: 154081   epsilon: 0.9486221000000237    steps: 166     evaluation reward: 1.49\n",
      "episode: 858   score: 3.0   memory length: 154331   epsilon: 0.9483846000000238    steps: 250     evaluation reward: 1.5\n",
      "episode: 859   score: 0.0   memory length: 154457   epsilon: 0.9482649000000238    steps: 126     evaluation reward: 1.5\n",
      "episode: 860   score: 0.0   memory length: 154583   epsilon: 0.9481452000000239    steps: 126     evaluation reward: 1.49\n",
      "episode: 861   score: 0.0   memory length: 154720   epsilon: 0.948015050000024    steps: 137     evaluation reward: 1.48\n",
      "episode: 862   score: 3.0   memory length: 154944   epsilon: 0.947802250000024    steps: 224     evaluation reward: 1.49\n",
      "episode: 863   score: 0.0   memory length: 155072   epsilon: 0.9476806500000241    steps: 128     evaluation reward: 1.49\n",
      "episode: 864   score: 8.0   memory length: 155366   epsilon: 0.9474013500000242    steps: 294     evaluation reward: 1.54\n",
      "episode: 865   score: 4.0   memory length: 155668   epsilon: 0.9471144500000244    steps: 302     evaluation reward: 1.58\n",
      "episode: 866   score: 1.0   memory length: 155858   epsilon: 0.9469339500000244    steps: 190     evaluation reward: 1.59\n",
      "episode: 867   score: 0.0   memory length: 155984   epsilon: 0.9468142500000245    steps: 126     evaluation reward: 1.59\n",
      "episode: 868   score: 1.0   memory length: 156151   epsilon: 0.9466556000000246    steps: 167     evaluation reward: 1.6\n",
      "episode: 869   score: 4.0   memory length: 156437   epsilon: 0.9463839000000247    steps: 286     evaluation reward: 1.61\n",
      "episode: 870   score: 0.0   memory length: 156573   epsilon: 0.9462547000000248    steps: 136     evaluation reward: 1.6\n",
      "episode: 871   score: 2.0   memory length: 156788   epsilon: 0.9460504500000249    steps: 215     evaluation reward: 1.61\n",
      "episode: 872   score: 0.0   memory length: 156923   epsilon: 0.9459222000000249    steps: 135     evaluation reward: 1.6\n",
      "episode: 873   score: 2.0   memory length: 157112   epsilon: 0.945742650000025    steps: 189     evaluation reward: 1.59\n",
      "episode: 874   score: 0.0   memory length: 157251   epsilon: 0.9456106000000251    steps: 139     evaluation reward: 1.59\n",
      "episode: 875   score: 0.0   memory length: 157378   epsilon: 0.9454899500000251    steps: 127     evaluation reward: 1.59\n",
      "episode: 876   score: 1.0   memory length: 157553   epsilon: 0.9453237000000252    steps: 175     evaluation reward: 1.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 877   score: 0.0   memory length: 157679   epsilon: 0.9452040000000252    steps: 126     evaluation reward: 1.55\n",
      "episode: 878   score: 1.0   memory length: 157846   epsilon: 0.9450453500000253    steps: 167     evaluation reward: 1.55\n",
      "episode: 879   score: 1.0   memory length: 158027   epsilon: 0.9448734000000254    steps: 181     evaluation reward: 1.54\n",
      "episode: 880   score: 1.0   memory length: 158188   epsilon: 0.9447204500000255    steps: 161     evaluation reward: 1.53\n",
      "episode: 881   score: 4.0   memory length: 158490   epsilon: 0.9444335500000256    steps: 302     evaluation reward: 1.55\n",
      "episode: 882   score: 3.0   memory length: 158739   epsilon: 0.9441970000000257    steps: 249     evaluation reward: 1.58\n",
      "episode: 883   score: 1.0   memory length: 158910   epsilon: 0.9440345500000258    steps: 171     evaluation reward: 1.58\n",
      "episode: 884   score: 1.0   memory length: 159069   epsilon: 0.9438835000000259    steps: 159     evaluation reward: 1.59\n",
      "episode: 885   score: 1.0   memory length: 159241   epsilon: 0.9437201000000259    steps: 172     evaluation reward: 1.59\n",
      "episode: 886   score: 1.0   memory length: 159426   epsilon: 0.943544350000026    steps: 185     evaluation reward: 1.6\n",
      "episode: 887   score: 1.0   memory length: 159606   epsilon: 0.9433733500000261    steps: 180     evaluation reward: 1.61\n",
      "episode: 888   score: 4.0   memory length: 159893   epsilon: 0.9431007000000262    steps: 287     evaluation reward: 1.64\n",
      "episode: 889   score: 2.0   memory length: 160094   epsilon: 0.9429097500000263    steps: 201     evaluation reward: 1.66\n",
      "episode: 890   score: 5.0   memory length: 160440   epsilon: 0.9425810500000265    steps: 346     evaluation reward: 1.7\n",
      "episode: 891   score: 3.0   memory length: 160684   epsilon: 0.9423492500000266    steps: 244     evaluation reward: 1.73\n",
      "episode: 892   score: 3.0   memory length: 160969   epsilon: 0.9420785000000267    steps: 285     evaluation reward: 1.74\n",
      "episode: 893   score: 0.0   memory length: 161102   epsilon: 0.9419521500000267    steps: 133     evaluation reward: 1.71\n",
      "episode: 894   score: 3.0   memory length: 161324   epsilon: 0.9417412500000268    steps: 222     evaluation reward: 1.72\n",
      "episode: 895   score: 2.0   memory length: 161509   epsilon: 0.9415655000000269    steps: 185     evaluation reward: 1.71\n",
      "episode: 896   score: 1.0   memory length: 161687   epsilon: 0.941396400000027    steps: 178     evaluation reward: 1.69\n",
      "episode: 897   score: 4.0   memory length: 161952   epsilon: 0.9411446500000271    steps: 265     evaluation reward: 1.7\n",
      "episode: 898   score: 1.0   memory length: 162126   epsilon: 0.9409793500000272    steps: 174     evaluation reward: 1.7\n",
      "episode: 899   score: 0.0   memory length: 162261   epsilon: 0.9408511000000273    steps: 135     evaluation reward: 1.69\n",
      "episode: 900   score: 1.0   memory length: 162441   epsilon: 0.9406801000000273    steps: 180     evaluation reward: 1.7\n",
      "episode: 901   score: 0.0   memory length: 162574   epsilon: 0.9405537500000274    steps: 133     evaluation reward: 1.68\n",
      "episode: 902   score: 0.0   memory length: 162704   epsilon: 0.9404302500000274    steps: 130     evaluation reward: 1.65\n",
      "episode: 903   score: 1.0   memory length: 162858   epsilon: 0.9402839500000275    steps: 154     evaluation reward: 1.64\n",
      "episode: 904   score: 4.0   memory length: 163163   epsilon: 0.9399942000000276    steps: 305     evaluation reward: 1.68\n",
      "episode: 905   score: 3.0   memory length: 163420   epsilon: 0.9397500500000278    steps: 257     evaluation reward: 1.7\n",
      "episode: 906   score: 3.0   memory length: 163664   epsilon: 0.9395182500000279    steps: 244     evaluation reward: 1.73\n",
      "episode: 907   score: 3.0   memory length: 163882   epsilon: 0.939311150000028    steps: 218     evaluation reward: 1.75\n",
      "episode: 908   score: 1.0   memory length: 164051   epsilon: 0.939150600000028    steps: 169     evaluation reward: 1.73\n",
      "episode: 909   score: 1.0   memory length: 164204   epsilon: 0.9390052500000281    steps: 153     evaluation reward: 1.74\n",
      "episode: 910   score: 1.0   memory length: 164378   epsilon: 0.9388399500000282    steps: 174     evaluation reward: 1.72\n",
      "episode: 911   score: 1.0   memory length: 164541   epsilon: 0.9386851000000282    steps: 163     evaluation reward: 1.72\n",
      "episode: 912   score: 0.0   memory length: 164676   epsilon: 0.9385568500000283    steps: 135     evaluation reward: 1.72\n",
      "episode: 913   score: 2.0   memory length: 164880   epsilon: 0.9383630500000284    steps: 204     evaluation reward: 1.71\n",
      "episode: 914   score: 0.0   memory length: 165015   epsilon: 0.9382348000000285    steps: 135     evaluation reward: 1.69\n",
      "episode: 915   score: 1.0   memory length: 165169   epsilon: 0.9380885000000285    steps: 154     evaluation reward: 1.68\n",
      "episode: 916   score: 5.0   memory length: 165514   epsilon: 0.9377607500000287    steps: 345     evaluation reward: 1.69\n",
      "episode: 917   score: 3.0   memory length: 165729   epsilon: 0.9375565000000288    steps: 215     evaluation reward: 1.71\n",
      "episode: 918   score: 2.0   memory length: 165917   epsilon: 0.9373779000000289    steps: 188     evaluation reward: 1.72\n",
      "episode: 919   score: 3.0   memory length: 166179   epsilon: 0.937129000000029    steps: 262     evaluation reward: 1.72\n",
      "episode: 920   score: 0.0   memory length: 166307   epsilon: 0.937007400000029    steps: 128     evaluation reward: 1.71\n",
      "episode: 921   score: 2.0   memory length: 166508   epsilon: 0.9368164500000291    steps: 201     evaluation reward: 1.73\n",
      "episode: 922   score: 3.0   memory length: 166783   epsilon: 0.9365552000000292    steps: 275     evaluation reward: 1.74\n",
      "episode: 923   score: 0.0   memory length: 166916   epsilon: 0.9364288500000293    steps: 133     evaluation reward: 1.72\n",
      "episode: 924   score: 1.0   memory length: 167076   epsilon: 0.9362768500000294    steps: 160     evaluation reward: 1.71\n",
      "episode: 925   score: 0.0   memory length: 167204   epsilon: 0.9361552500000294    steps: 128     evaluation reward: 1.71\n",
      "episode: 926   score: 2.0   memory length: 167431   epsilon: 0.9359396000000295    steps: 227     evaluation reward: 1.68\n",
      "episode: 927   score: 4.0   memory length: 167737   epsilon: 0.9356489000000296    steps: 306     evaluation reward: 1.7\n",
      "episode: 928   score: 3.0   memory length: 167992   epsilon: 0.9354066500000298    steps: 255     evaluation reward: 1.72\n",
      "episode: 929   score: 2.0   memory length: 168196   epsilon: 0.9352128500000298    steps: 204     evaluation reward: 1.73\n",
      "episode: 930   score: 2.0   memory length: 168426   epsilon: 0.93499435000003    steps: 230     evaluation reward: 1.74\n",
      "episode: 931   score: 1.0   memory length: 168594   epsilon: 0.93483475000003    steps: 168     evaluation reward: 1.74\n",
      "episode: 932   score: 1.0   memory length: 168777   epsilon: 0.9346609000000301    steps: 183     evaluation reward: 1.73\n",
      "episode: 933   score: 2.0   memory length: 168964   epsilon: 0.9344832500000302    steps: 187     evaluation reward: 1.75\n",
      "episode: 934   score: 1.0   memory length: 169141   epsilon: 0.9343151000000303    steps: 177     evaluation reward: 1.75\n",
      "episode: 935   score: 0.0   memory length: 169271   epsilon: 0.9341916000000303    steps: 130     evaluation reward: 1.74\n",
      "episode: 936   score: 3.0   memory length: 169525   epsilon: 0.9339503000000304    steps: 254     evaluation reward: 1.75\n",
      "episode: 937   score: 3.0   memory length: 169780   epsilon: 0.9337080500000305    steps: 255     evaluation reward: 1.77\n",
      "episode: 938   score: 3.0   memory length: 170007   epsilon: 0.9334924000000306    steps: 227     evaluation reward: 1.77\n",
      "episode: 939   score: 3.0   memory length: 170266   epsilon: 0.9332463500000308    steps: 259     evaluation reward: 1.79\n",
      "episode: 940   score: 2.0   memory length: 170464   epsilon: 0.9330582500000308    steps: 198     evaluation reward: 1.8\n",
      "episode: 941   score: 3.0   memory length: 170736   epsilon: 0.932799850000031    steps: 272     evaluation reward: 1.79\n",
      "episode: 942   score: 1.0   memory length: 170900   epsilon: 0.932644050000031    steps: 164     evaluation reward: 1.78\n",
      "episode: 943   score: 2.0   memory length: 171126   epsilon: 0.9324293500000311    steps: 226     evaluation reward: 1.8\n",
      "episode: 944   score: 2.0   memory length: 171330   epsilon: 0.9322355500000312    steps: 204     evaluation reward: 1.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 945   score: 1.0   memory length: 171488   epsilon: 0.9320854500000313    steps: 158     evaluation reward: 1.77\n",
      "episode: 946   score: 0.0   memory length: 171619   epsilon: 0.9319610000000313    steps: 131     evaluation reward: 1.75\n",
      "episode: 947   score: 2.0   memory length: 171819   epsilon: 0.9317710000000314    steps: 200     evaluation reward: 1.75\n",
      "episode: 948   score: 0.0   memory length: 171954   epsilon: 0.9316427500000315    steps: 135     evaluation reward: 1.75\n",
      "episode: 949   score: 0.0   memory length: 172094   epsilon: 0.9315097500000316    steps: 140     evaluation reward: 1.71\n",
      "episode: 950   score: 1.0   memory length: 172246   epsilon: 0.9313653500000316    steps: 152     evaluation reward: 1.68\n",
      "episode: 951   score: 1.0   memory length: 172405   epsilon: 0.9312143000000317    steps: 159     evaluation reward: 1.69\n",
      "episode: 952   score: 1.0   memory length: 172559   epsilon: 0.9310680000000318    steps: 154     evaluation reward: 1.68\n",
      "episode: 953   score: 3.0   memory length: 172795   epsilon: 0.9308438000000319    steps: 236     evaluation reward: 1.69\n",
      "episode: 954   score: 1.0   memory length: 172969   epsilon: 0.9306785000000319    steps: 174     evaluation reward: 1.69\n",
      "episode: 955   score: 1.0   memory length: 173152   epsilon: 0.930504650000032    steps: 183     evaluation reward: 1.66\n",
      "episode: 956   score: 2.0   memory length: 173345   epsilon: 0.9303213000000321    steps: 193     evaluation reward: 1.67\n",
      "episode: 957   score: 1.0   memory length: 173509   epsilon: 0.9301655000000322    steps: 164     evaluation reward: 1.67\n",
      "episode: 958   score: 2.0   memory length: 173710   epsilon: 0.9299745500000323    steps: 201     evaluation reward: 1.66\n",
      "episode: 959   score: 2.0   memory length: 173928   epsilon: 0.9297674500000324    steps: 218     evaluation reward: 1.68\n",
      "episode: 960   score: 5.0   memory length: 174297   epsilon: 0.9294169000000325    steps: 369     evaluation reward: 1.73\n",
      "episode: 961   score: 1.0   memory length: 174452   epsilon: 0.9292696500000326    steps: 155     evaluation reward: 1.74\n",
      "episode: 962   score: 0.0   memory length: 174586   epsilon: 0.9291423500000326    steps: 134     evaluation reward: 1.71\n",
      "episode: 963   score: 3.0   memory length: 174840   epsilon: 0.9289010500000328    steps: 254     evaluation reward: 1.74\n",
      "episode: 964   score: 1.0   memory length: 175000   epsilon: 0.9287490500000328    steps: 160     evaluation reward: 1.67\n",
      "episode: 965   score: 0.0   memory length: 175127   epsilon: 0.9286284000000329    steps: 127     evaluation reward: 1.63\n",
      "episode: 966   score: 2.0   memory length: 175340   epsilon: 0.928426050000033    steps: 213     evaluation reward: 1.64\n",
      "episode: 967   score: 3.0   memory length: 175593   epsilon: 0.9281857000000331    steps: 253     evaluation reward: 1.67\n",
      "episode: 968   score: 2.0   memory length: 175835   epsilon: 0.9279558000000332    steps: 242     evaluation reward: 1.68\n",
      "episode: 969   score: 2.0   memory length: 176043   epsilon: 0.9277582000000333    steps: 208     evaluation reward: 1.66\n",
      "episode: 970   score: 1.0   memory length: 176225   epsilon: 0.9275853000000334    steps: 182     evaluation reward: 1.67\n",
      "episode: 971   score: 3.0   memory length: 176464   epsilon: 0.9273582500000335    steps: 239     evaluation reward: 1.68\n",
      "episode: 972   score: 1.0   memory length: 176646   epsilon: 0.9271853500000335    steps: 182     evaluation reward: 1.69\n",
      "episode: 973   score: 0.0   memory length: 176772   epsilon: 0.9270656500000336    steps: 126     evaluation reward: 1.67\n",
      "episode: 974   score: 0.0   memory length: 176905   epsilon: 0.9269393000000337    steps: 133     evaluation reward: 1.67\n",
      "episode: 975   score: 1.0   memory length: 177079   epsilon: 0.9267740000000337    steps: 174     evaluation reward: 1.68\n",
      "episode: 976   score: 1.0   memory length: 177237   epsilon: 0.9266239000000338    steps: 158     evaluation reward: 1.68\n",
      "episode: 977   score: 1.0   memory length: 177416   epsilon: 0.9264538500000339    steps: 179     evaluation reward: 1.69\n",
      "episode: 978   score: 0.0   memory length: 177542   epsilon: 0.9263341500000339    steps: 126     evaluation reward: 1.68\n",
      "episode: 979   score: 2.0   memory length: 177752   epsilon: 0.926134650000034    steps: 210     evaluation reward: 1.69\n",
      "episode: 980   score: 0.0   memory length: 177887   epsilon: 0.9260064000000341    steps: 135     evaluation reward: 1.68\n",
      "episode: 981   score: 2.0   memory length: 178112   epsilon: 0.9257926500000342    steps: 225     evaluation reward: 1.66\n",
      "episode: 982   score: 0.0   memory length: 178249   epsilon: 0.9256625000000342    steps: 137     evaluation reward: 1.63\n",
      "episode: 983   score: 0.0   memory length: 178384   epsilon: 0.9255342500000343    steps: 135     evaluation reward: 1.62\n",
      "episode: 984   score: 0.0   memory length: 178518   epsilon: 0.9254069500000344    steps: 134     evaluation reward: 1.61\n",
      "episode: 985   score: 1.0   memory length: 178692   epsilon: 0.9252416500000344    steps: 174     evaluation reward: 1.61\n",
      "episode: 986   score: 0.0   memory length: 178825   epsilon: 0.9251153000000345    steps: 133     evaluation reward: 1.6\n",
      "episode: 987   score: 3.0   memory length: 179061   epsilon: 0.9248911000000346    steps: 236     evaluation reward: 1.62\n",
      "episode: 988   score: 2.0   memory length: 179262   epsilon: 0.9247001500000347    steps: 201     evaluation reward: 1.6\n",
      "episode: 989   score: 0.0   memory length: 179387   epsilon: 0.9245814000000347    steps: 125     evaluation reward: 1.58\n",
      "episode: 990   score: 0.0   memory length: 179519   epsilon: 0.9244560000000348    steps: 132     evaluation reward: 1.53\n",
      "episode: 991   score: 2.0   memory length: 179733   epsilon: 0.9242527000000349    steps: 214     evaluation reward: 1.52\n",
      "episode: 992   score: 1.0   memory length: 179890   epsilon: 0.924103550000035    steps: 157     evaluation reward: 1.5\n",
      "episode: 993   score: 3.0   memory length: 180127   epsilon: 0.9238784000000351    steps: 237     evaluation reward: 1.53\n",
      "episode: 994   score: 1.0   memory length: 180308   epsilon: 0.9237064500000352    steps: 181     evaluation reward: 1.51\n",
      "episode: 995   score: 1.0   memory length: 180472   epsilon: 0.9235506500000352    steps: 164     evaluation reward: 1.5\n",
      "episode: 996   score: 4.0   memory length: 180761   epsilon: 0.9232761000000353    steps: 289     evaluation reward: 1.53\n",
      "episode: 997   score: 2.0   memory length: 180977   epsilon: 0.9230709000000354    steps: 216     evaluation reward: 1.51\n",
      "episode: 998   score: 2.0   memory length: 181189   epsilon: 0.9228695000000355    steps: 212     evaluation reward: 1.52\n",
      "episode: 999   score: 3.0   memory length: 181439   epsilon: 0.9226320000000356    steps: 250     evaluation reward: 1.55\n",
      "episode: 1000   score: 0.0   memory length: 181566   epsilon: 0.9225113500000357    steps: 127     evaluation reward: 1.54\n",
      "episode: 1001   score: 1.0   memory length: 181752   epsilon: 0.9223346500000358    steps: 186     evaluation reward: 1.55\n",
      "episode: 1002   score: 3.0   memory length: 181966   epsilon: 0.9221313500000359    steps: 214     evaluation reward: 1.58\n",
      "episode: 1003   score: 4.0   memory length: 182243   epsilon: 0.921868200000036    steps: 277     evaluation reward: 1.61\n",
      "episode: 1004   score: 2.0   memory length: 182446   epsilon: 0.9216753500000361    steps: 203     evaluation reward: 1.59\n",
      "episode: 1005   score: 1.0   memory length: 182634   epsilon: 0.9214967500000362    steps: 188     evaluation reward: 1.57\n",
      "episode: 1006   score: 2.0   memory length: 182836   epsilon: 0.9213048500000363    steps: 202     evaluation reward: 1.56\n",
      "episode: 1007   score: 0.0   memory length: 182973   epsilon: 0.9211747000000363    steps: 137     evaluation reward: 1.53\n",
      "episode: 1008   score: 5.0   memory length: 183311   epsilon: 0.9208536000000365    steps: 338     evaluation reward: 1.57\n",
      "episode: 1009   score: 3.0   memory length: 183566   epsilon: 0.9206113500000366    steps: 255     evaluation reward: 1.59\n",
      "episode: 1010   score: 4.0   memory length: 183850   epsilon: 0.9203415500000367    steps: 284     evaluation reward: 1.62\n",
      "episode: 1011   score: 2.0   memory length: 184055   epsilon: 0.9201468000000368    steps: 205     evaluation reward: 1.63\n",
      "episode: 1012   score: 1.0   memory length: 184230   epsilon: 0.9199805500000369    steps: 175     evaluation reward: 1.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1013   score: 0.0   memory length: 184357   epsilon: 0.9198599000000369    steps: 127     evaluation reward: 1.62\n",
      "episode: 1014   score: 5.0   memory length: 184662   epsilon: 0.9195701500000371    steps: 305     evaluation reward: 1.67\n",
      "episode: 1015   score: 2.0   memory length: 184876   epsilon: 0.9193668500000372    steps: 214     evaluation reward: 1.68\n",
      "episode: 1016   score: 6.0   memory length: 185224   epsilon: 0.9190362500000373    steps: 348     evaluation reward: 1.69\n",
      "episode: 1017   score: 1.0   memory length: 185384   epsilon: 0.9188842500000374    steps: 160     evaluation reward: 1.67\n",
      "episode: 1018   score: 2.0   memory length: 185587   epsilon: 0.9186914000000375    steps: 203     evaluation reward: 1.67\n",
      "episode: 1019   score: 0.0   memory length: 185714   epsilon: 0.9185707500000375    steps: 127     evaluation reward: 1.64\n",
      "episode: 1020   score: 1.0   memory length: 185890   epsilon: 0.9184035500000376    steps: 176     evaluation reward: 1.65\n",
      "episode: 1021   score: 1.0   memory length: 186048   epsilon: 0.9182534500000377    steps: 158     evaluation reward: 1.64\n",
      "episode: 1022   score: 4.0   memory length: 186342   epsilon: 0.9179741500000378    steps: 294     evaluation reward: 1.65\n",
      "episode: 1023   score: 5.0   memory length: 186679   epsilon: 0.9176540000000379    steps: 337     evaluation reward: 1.7\n",
      "episode: 1024   score: 1.0   memory length: 186847   epsilon: 0.917494400000038    steps: 168     evaluation reward: 1.7\n",
      "episode: 1025   score: 0.0   memory length: 186978   epsilon: 0.9173699500000381    steps: 131     evaluation reward: 1.7\n",
      "episode: 1026   score: 1.0   memory length: 187139   epsilon: 0.9172170000000381    steps: 161     evaluation reward: 1.69\n",
      "episode: 1027   score: 4.0   memory length: 187439   epsilon: 0.9169320000000383    steps: 300     evaluation reward: 1.69\n",
      "episode: 1028   score: 5.0   memory length: 187752   epsilon: 0.9166346500000384    steps: 313     evaluation reward: 1.71\n",
      "episode: 1029   score: 1.0   memory length: 187930   epsilon: 0.9164655500000385    steps: 178     evaluation reward: 1.7\n",
      "episode: 1030   score: 3.0   memory length: 188185   epsilon: 0.9162233000000386    steps: 255     evaluation reward: 1.71\n",
      "episode: 1031   score: 0.0   memory length: 188329   epsilon: 0.9160865000000387    steps: 144     evaluation reward: 1.7\n",
      "episode: 1032   score: 0.0   memory length: 188462   epsilon: 0.9159601500000387    steps: 133     evaluation reward: 1.69\n",
      "episode: 1033   score: 1.0   memory length: 188623   epsilon: 0.9158072000000388    steps: 161     evaluation reward: 1.68\n",
      "episode: 1034   score: 0.0   memory length: 188748   epsilon: 0.9156884500000388    steps: 125     evaluation reward: 1.67\n",
      "episode: 1035   score: 0.0   memory length: 188875   epsilon: 0.9155678000000389    steps: 127     evaluation reward: 1.67\n",
      "episode: 1036   score: 0.0   memory length: 189009   epsilon: 0.915440500000039    steps: 134     evaluation reward: 1.64\n",
      "episode: 1037   score: 0.0   memory length: 189134   epsilon: 0.915321750000039    steps: 125     evaluation reward: 1.61\n",
      "episode: 1038   score: 0.0   memory length: 189267   epsilon: 0.9151954000000391    steps: 133     evaluation reward: 1.58\n",
      "episode: 1039   score: 0.0   memory length: 189397   epsilon: 0.9150719000000391    steps: 130     evaluation reward: 1.55\n",
      "episode: 1040   score: 3.0   memory length: 189647   epsilon: 0.9148344000000392    steps: 250     evaluation reward: 1.56\n",
      "episode: 1041   score: 2.0   memory length: 189841   epsilon: 0.9146501000000393    steps: 194     evaluation reward: 1.55\n",
      "episode: 1042   score: 2.0   memory length: 190024   epsilon: 0.9144762500000394    steps: 183     evaluation reward: 1.56\n",
      "episode: 1043   score: 7.0   memory length: 190436   epsilon: 0.9140848500000396    steps: 412     evaluation reward: 1.61\n",
      "episode: 1044   score: 0.0   memory length: 190588   epsilon: 0.9139404500000397    steps: 152     evaluation reward: 1.59\n",
      "episode: 1045   score: 2.0   memory length: 190787   epsilon: 0.9137514000000397    steps: 199     evaluation reward: 1.6\n",
      "episode: 1046   score: 0.0   memory length: 190916   epsilon: 0.9136288500000398    steps: 129     evaluation reward: 1.6\n",
      "episode: 1047   score: 1.0   memory length: 191091   epsilon: 0.9134626000000399    steps: 175     evaluation reward: 1.59\n",
      "episode: 1048   score: 2.0   memory length: 191276   epsilon: 0.91328685000004    steps: 185     evaluation reward: 1.61\n",
      "episode: 1049   score: 1.0   memory length: 191432   epsilon: 0.91313865000004    steps: 156     evaluation reward: 1.62\n",
      "episode: 1050   score: 0.0   memory length: 191558   epsilon: 0.9130189500000401    steps: 126     evaluation reward: 1.61\n",
      "episode: 1051   score: 2.0   memory length: 191761   epsilon: 0.9128261000000402    steps: 203     evaluation reward: 1.62\n",
      "episode: 1052   score: 1.0   memory length: 191937   epsilon: 0.9126589000000402    steps: 176     evaluation reward: 1.62\n",
      "episode: 1053   score: 0.0   memory length: 192070   epsilon: 0.9125325500000403    steps: 133     evaluation reward: 1.59\n",
      "episode: 1054   score: 3.0   memory length: 192303   epsilon: 0.9123112000000404    steps: 233     evaluation reward: 1.61\n",
      "episode: 1055   score: 5.0   memory length: 192635   epsilon: 0.9119958000000405    steps: 332     evaluation reward: 1.65\n",
      "episode: 1056   score: 0.0   memory length: 192759   epsilon: 0.9118780000000406    steps: 124     evaluation reward: 1.63\n",
      "episode: 1057   score: 3.0   memory length: 192999   epsilon: 0.9116500000000407    steps: 240     evaluation reward: 1.65\n",
      "episode: 1058   score: 2.0   memory length: 193214   epsilon: 0.9114457500000408    steps: 215     evaluation reward: 1.65\n",
      "episode: 1059   score: 0.0   memory length: 193354   epsilon: 0.9113127500000409    steps: 140     evaluation reward: 1.63\n",
      "episode: 1060   score: 3.0   memory length: 193580   epsilon: 0.911098050000041    steps: 226     evaluation reward: 1.61\n",
      "episode: 1061   score: 3.0   memory length: 193792   epsilon: 0.910896650000041    steps: 212     evaluation reward: 1.63\n",
      "episode: 1062   score: 2.0   memory length: 193986   epsilon: 0.9107123500000411    steps: 194     evaluation reward: 1.65\n",
      "episode: 1063   score: 2.0   memory length: 194167   epsilon: 0.9105404000000412    steps: 181     evaluation reward: 1.64\n",
      "episode: 1064   score: 1.0   memory length: 194338   epsilon: 0.9103779500000413    steps: 171     evaluation reward: 1.64\n",
      "episode: 1065   score: 0.0   memory length: 194475   epsilon: 0.9102478000000414    steps: 137     evaluation reward: 1.64\n",
      "episode: 1066   score: 2.0   memory length: 194694   epsilon: 0.9100397500000414    steps: 219     evaluation reward: 1.64\n",
      "episode: 1067   score: 2.0   memory length: 194924   epsilon: 0.9098212500000415    steps: 230     evaluation reward: 1.63\n",
      "episode: 1068   score: 2.0   memory length: 195144   epsilon: 0.9096122500000416    steps: 220     evaluation reward: 1.63\n",
      "episode: 1069   score: 1.0   memory length: 195310   epsilon: 0.9094545500000417    steps: 166     evaluation reward: 1.62\n",
      "episode: 1070   score: 1.0   memory length: 195486   epsilon: 0.9092873500000418    steps: 176     evaluation reward: 1.62\n",
      "episode: 1071   score: 4.0   memory length: 195772   epsilon: 0.9090156500000419    steps: 286     evaluation reward: 1.63\n",
      "episode: 1072   score: 2.0   memory length: 195974   epsilon: 0.908823750000042    steps: 202     evaluation reward: 1.64\n",
      "episode: 1073   score: 1.0   memory length: 196137   epsilon: 0.9086689000000421    steps: 163     evaluation reward: 1.65\n",
      "episode: 1074   score: 4.0   memory length: 196405   epsilon: 0.9084143000000422    steps: 268     evaluation reward: 1.69\n",
      "episode: 1075   score: 2.0   memory length: 196609   epsilon: 0.9082205000000423    steps: 204     evaluation reward: 1.7\n",
      "episode: 1076   score: 0.0   memory length: 196743   epsilon: 0.9080932000000423    steps: 134     evaluation reward: 1.69\n",
      "episode: 1077   score: 2.0   memory length: 196952   epsilon: 0.9078946500000424    steps: 209     evaluation reward: 1.7\n",
      "episode: 1078   score: 4.0   memory length: 197249   epsilon: 0.9076125000000426    steps: 297     evaluation reward: 1.74\n",
      "episode: 1079   score: 2.0   memory length: 197443   epsilon: 0.9074282000000427    steps: 194     evaluation reward: 1.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1080   score: 1.0   memory length: 197614   epsilon: 0.9072657500000427    steps: 171     evaluation reward: 1.75\n",
      "episode: 1081   score: 3.0   memory length: 197866   epsilon: 0.9070263500000428    steps: 252     evaluation reward: 1.76\n",
      "episode: 1082   score: 2.0   memory length: 198087   epsilon: 0.9068164000000429    steps: 221     evaluation reward: 1.78\n",
      "episode: 1083   score: 0.0   memory length: 198222   epsilon: 0.906688150000043    steps: 135     evaluation reward: 1.78\n",
      "episode: 1084   score: 1.0   memory length: 198373   epsilon: 0.9065447000000431    steps: 151     evaluation reward: 1.79\n",
      "episode: 1085   score: 3.0   memory length: 198630   epsilon: 0.9063005500000432    steps: 257     evaluation reward: 1.81\n",
      "episode: 1086   score: 4.0   memory length: 198908   epsilon: 0.9060364500000433    steps: 278     evaluation reward: 1.85\n",
      "episode: 1087   score: 2.0   memory length: 199094   epsilon: 0.9058597500000434    steps: 186     evaluation reward: 1.84\n",
      "episode: 1088   score: 2.0   memory length: 199306   epsilon: 0.9056583500000435    steps: 212     evaluation reward: 1.84\n",
      "episode: 1089   score: 2.0   memory length: 199507   epsilon: 0.9054674000000436    steps: 201     evaluation reward: 1.86\n",
      "episode: 1090   score: 1.0   memory length: 199662   epsilon: 0.9053201500000436    steps: 155     evaluation reward: 1.87\n",
      "episode: 1091   score: 2.0   memory length: 199853   epsilon: 0.9051387000000437    steps: 191     evaluation reward: 1.87\n",
      "now time :  2018-12-14 08:12:46.068919\n",
      "episode: 1092   score: 1.0   memory length: 200035   epsilon: 0.9049658000000438    steps: 182     evaluation reward: 1.87\n",
      "episode: 1093   score: 1.0   memory length: 200217   epsilon: 0.9047929000000439    steps: 182     evaluation reward: 1.85\n",
      "episode: 1094   score: 1.0   memory length: 200384   epsilon: 0.9046342500000439    steps: 167     evaluation reward: 1.85\n",
      "episode: 1095   score: 1.0   memory length: 200571   epsilon: 0.904456600000044    steps: 187     evaluation reward: 1.85\n",
      "episode: 1096   score: 2.0   memory length: 200761   epsilon: 0.9042761000000441    steps: 190     evaluation reward: 1.83\n",
      "episode: 1097   score: 3.0   memory length: 201008   epsilon: 0.9040414500000442    steps: 247     evaluation reward: 1.84\n",
      "episode: 1098   score: 3.0   memory length: 201271   epsilon: 0.9037916000000443    steps: 263     evaluation reward: 1.85\n",
      "episode: 1099   score: 2.0   memory length: 201469   epsilon: 0.9036035000000444    steps: 198     evaluation reward: 1.84\n",
      "episode: 1100   score: 1.0   memory length: 201622   epsilon: 0.9034581500000445    steps: 153     evaluation reward: 1.85\n",
      "episode: 1101   score: 1.0   memory length: 201778   epsilon: 0.9033099500000445    steps: 156     evaluation reward: 1.85\n",
      "episode: 1102   score: 2.0   memory length: 201981   epsilon: 0.9031171000000446    steps: 203     evaluation reward: 1.84\n",
      "episode: 1103   score: 3.0   memory length: 202229   epsilon: 0.9028815000000447    steps: 248     evaluation reward: 1.83\n",
      "episode: 1104   score: 0.0   memory length: 202357   epsilon: 0.9027599000000448    steps: 128     evaluation reward: 1.81\n",
      "episode: 1105   score: 2.0   memory length: 202559   epsilon: 0.9025680000000449    steps: 202     evaluation reward: 1.82\n",
      "episode: 1106   score: 1.0   memory length: 202717   epsilon: 0.902417900000045    steps: 158     evaluation reward: 1.81\n",
      "episode: 1107   score: 5.0   memory length: 203014   epsilon: 0.9021357500000451    steps: 297     evaluation reward: 1.86\n",
      "episode: 1108   score: 3.0   memory length: 203236   epsilon: 0.9019248500000452    steps: 222     evaluation reward: 1.84\n",
      "episode: 1109   score: 2.0   memory length: 203435   epsilon: 0.9017358000000453    steps: 199     evaluation reward: 1.83\n",
      "episode: 1110   score: 3.0   memory length: 203677   epsilon: 0.9015059000000454    steps: 242     evaluation reward: 1.82\n",
      "episode: 1111   score: 6.0   memory length: 204027   epsilon: 0.9011734000000455    steps: 350     evaluation reward: 1.86\n",
      "episode: 1112   score: 4.0   memory length: 204298   epsilon: 0.9009159500000457    steps: 271     evaluation reward: 1.89\n",
      "episode: 1113   score: 1.0   memory length: 204464   epsilon: 0.9007582500000457    steps: 166     evaluation reward: 1.9\n",
      "episode: 1114   score: 4.0   memory length: 204760   epsilon: 0.9004770500000459    steps: 296     evaluation reward: 1.89\n",
      "episode: 1115   score: 2.0   memory length: 204970   epsilon: 0.900277550000046    steps: 210     evaluation reward: 1.89\n",
      "episode: 1116   score: 1.0   memory length: 205150   epsilon: 0.900106550000046    steps: 180     evaluation reward: 1.84\n",
      "episode: 1117   score: 4.0   memory length: 205424   epsilon: 0.8998462500000461    steps: 274     evaluation reward: 1.87\n",
      "episode: 1118   score: 1.0   memory length: 205577   epsilon: 0.8997009000000462    steps: 153     evaluation reward: 1.86\n",
      "episode: 1119   score: 2.0   memory length: 205765   epsilon: 0.8995223000000463    steps: 188     evaluation reward: 1.88\n",
      "episode: 1120   score: 4.0   memory length: 206064   epsilon: 0.8992382500000464    steps: 299     evaluation reward: 1.91\n",
      "episode: 1121   score: 4.0   memory length: 206314   epsilon: 0.8990007500000465    steps: 250     evaluation reward: 1.94\n",
      "episode: 1122   score: 1.0   memory length: 206472   epsilon: 0.8988506500000466    steps: 158     evaluation reward: 1.91\n",
      "episode: 1123   score: 0.0   memory length: 206599   epsilon: 0.8987300000000467    steps: 127     evaluation reward: 1.86\n",
      "episode: 1124   score: 3.0   memory length: 206856   epsilon: 0.8984858500000468    steps: 257     evaluation reward: 1.88\n",
      "episode: 1125   score: 2.0   memory length: 207084   epsilon: 0.8982692500000469    steps: 228     evaluation reward: 1.9\n",
      "episode: 1126   score: 2.0   memory length: 207289   epsilon: 0.898074500000047    steps: 205     evaluation reward: 1.91\n",
      "episode: 1127   score: 2.0   memory length: 207492   epsilon: 0.897881650000047    steps: 203     evaluation reward: 1.89\n",
      "episode: 1128   score: 3.0   memory length: 207746   epsilon: 0.8976403500000472    steps: 254     evaluation reward: 1.87\n",
      "episode: 1129   score: 1.0   memory length: 207917   epsilon: 0.8974779000000472    steps: 171     evaluation reward: 1.87\n",
      "episode: 1130   score: 2.0   memory length: 208125   epsilon: 0.8972803000000473    steps: 208     evaluation reward: 1.86\n",
      "episode: 1131   score: 0.0   memory length: 208259   epsilon: 0.8971530000000474    steps: 134     evaluation reward: 1.86\n",
      "episode: 1132   score: 0.0   memory length: 208385   epsilon: 0.8970333000000474    steps: 126     evaluation reward: 1.86\n",
      "episode: 1133   score: 5.0   memory length: 208707   epsilon: 0.8967274000000476    steps: 322     evaluation reward: 1.9\n",
      "episode: 1134   score: 4.0   memory length: 208971   epsilon: 0.8964766000000477    steps: 264     evaluation reward: 1.94\n",
      "episode: 1135   score: 1.0   memory length: 209129   epsilon: 0.8963265000000478    steps: 158     evaluation reward: 1.95\n",
      "episode: 1136   score: 2.0   memory length: 209352   epsilon: 0.8961146500000479    steps: 223     evaluation reward: 1.97\n",
      "episode: 1137   score: 1.0   memory length: 209510   epsilon: 0.8959645500000479    steps: 158     evaluation reward: 1.98\n",
      "episode: 1138   score: 1.0   memory length: 209662   epsilon: 0.895820150000048    steps: 152     evaluation reward: 1.99\n",
      "episode: 1139   score: 1.0   memory length: 209827   epsilon: 0.8956634000000481    steps: 165     evaluation reward: 2.0\n",
      "episode: 1140   score: 0.0   memory length: 209949   epsilon: 0.8955475000000481    steps: 122     evaluation reward: 1.97\n",
      "episode: 1141   score: 2.0   memory length: 210164   epsilon: 0.8953432500000482    steps: 215     evaluation reward: 1.97\n",
      "episode: 1142   score: 1.0   memory length: 210332   epsilon: 0.8951836500000483    steps: 168     evaluation reward: 1.96\n",
      "episode: 1143   score: 2.0   memory length: 210543   epsilon: 0.8949832000000484    steps: 211     evaluation reward: 1.91\n",
      "episode: 1144   score: 0.0   memory length: 210670   epsilon: 0.8948625500000484    steps: 127     evaluation reward: 1.91\n",
      "episode: 1145   score: 2.0   memory length: 210878   epsilon: 0.8946649500000485    steps: 208     evaluation reward: 1.91\n",
      "episode: 1146   score: 2.0   memory length: 211064   epsilon: 0.8944882500000486    steps: 186     evaluation reward: 1.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1147   score: 0.0   memory length: 211198   epsilon: 0.8943609500000487    steps: 134     evaluation reward: 1.92\n",
      "episode: 1148   score: 3.0   memory length: 211430   epsilon: 0.8941405500000488    steps: 232     evaluation reward: 1.93\n",
      "episode: 1149   score: 2.0   memory length: 211623   epsilon: 0.8939572000000489    steps: 193     evaluation reward: 1.94\n",
      "episode: 1150   score: 0.0   memory length: 211750   epsilon: 0.8938365500000489    steps: 127     evaluation reward: 1.94\n",
      "episode: 1151   score: 5.0   memory length: 212065   epsilon: 0.893537300000049    steps: 315     evaluation reward: 1.97\n",
      "episode: 1152   score: 4.0   memory length: 212323   epsilon: 0.8932922000000492    steps: 258     evaluation reward: 2.0\n",
      "episode: 1153   score: 3.0   memory length: 212544   epsilon: 0.8930822500000493    steps: 221     evaluation reward: 2.03\n",
      "episode: 1154   score: 3.0   memory length: 212761   epsilon: 0.8928761000000494    steps: 217     evaluation reward: 2.03\n",
      "episode: 1155   score: 4.0   memory length: 213069   epsilon: 0.8925835000000495    steps: 308     evaluation reward: 2.02\n",
      "episode: 1156   score: 1.0   memory length: 213249   epsilon: 0.8924125000000496    steps: 180     evaluation reward: 2.03\n",
      "episode: 1157   score: 1.0   memory length: 213435   epsilon: 0.8922358000000497    steps: 186     evaluation reward: 2.01\n",
      "episode: 1158   score: 0.0   memory length: 213564   epsilon: 0.8921132500000497    steps: 129     evaluation reward: 1.99\n",
      "episode: 1159   score: 2.0   memory length: 213769   epsilon: 0.8919185000000498    steps: 205     evaluation reward: 2.01\n",
      "episode: 1160   score: 2.0   memory length: 213969   epsilon: 0.8917285000000499    steps: 200     evaluation reward: 2.0\n",
      "episode: 1161   score: 0.0   memory length: 214100   epsilon: 0.8916040500000499    steps: 131     evaluation reward: 1.97\n",
      "episode: 1162   score: 0.0   memory length: 214229   epsilon: 0.89148150000005    steps: 129     evaluation reward: 1.95\n",
      "episode: 1163   score: 3.0   memory length: 214477   epsilon: 0.8912459000000501    steps: 248     evaluation reward: 1.96\n",
      "episode: 1164   score: 1.0   memory length: 214642   epsilon: 0.8910891500000502    steps: 165     evaluation reward: 1.96\n",
      "episode: 1165   score: 1.0   memory length: 214805   epsilon: 0.8909343000000502    steps: 163     evaluation reward: 1.97\n",
      "episode: 1166   score: 1.0   memory length: 214977   epsilon: 0.8907709000000503    steps: 172     evaluation reward: 1.96\n",
      "episode: 1167   score: 3.0   memory length: 215247   epsilon: 0.8905144000000504    steps: 270     evaluation reward: 1.97\n",
      "episode: 1168   score: 1.0   memory length: 215431   epsilon: 0.8903396000000505    steps: 184     evaluation reward: 1.96\n",
      "episode: 1169   score: 3.0   memory length: 215668   epsilon: 0.8901144500000506    steps: 237     evaluation reward: 1.98\n",
      "episode: 1170   score: 0.0   memory length: 215808   epsilon: 0.8899814500000507    steps: 140     evaluation reward: 1.97\n",
      "episode: 1171   score: 2.0   memory length: 216030   epsilon: 0.8897705500000508    steps: 222     evaluation reward: 1.95\n",
      "episode: 1172   score: 1.0   memory length: 216191   epsilon: 0.8896176000000509    steps: 161     evaluation reward: 1.94\n",
      "episode: 1173   score: 1.0   memory length: 216348   epsilon: 0.8894684500000509    steps: 157     evaluation reward: 1.94\n",
      "episode: 1174   score: 4.0   memory length: 216631   epsilon: 0.889199600000051    steps: 283     evaluation reward: 1.94\n",
      "episode: 1175   score: 2.0   memory length: 216832   epsilon: 0.8890086500000511    steps: 201     evaluation reward: 1.94\n",
      "episode: 1176   score: 3.0   memory length: 217110   epsilon: 0.8887445500000513    steps: 278     evaluation reward: 1.97\n",
      "episode: 1177   score: 4.0   memory length: 217387   epsilon: 0.8884814000000514    steps: 277     evaluation reward: 1.99\n",
      "episode: 1178   score: 1.0   memory length: 217572   epsilon: 0.8883056500000515    steps: 185     evaluation reward: 1.96\n",
      "episode: 1179   score: 1.0   memory length: 217733   epsilon: 0.8881527000000515    steps: 161     evaluation reward: 1.95\n",
      "episode: 1180   score: 1.0   memory length: 217892   epsilon: 0.8880016500000516    steps: 159     evaluation reward: 1.95\n",
      "episode: 1181   score: 3.0   memory length: 218134   epsilon: 0.8877717500000517    steps: 242     evaluation reward: 1.95\n",
      "episode: 1182   score: 2.0   memory length: 218317   epsilon: 0.8875979000000518    steps: 183     evaluation reward: 1.95\n",
      "episode: 1183   score: 0.0   memory length: 218461   epsilon: 0.8874611000000519    steps: 144     evaluation reward: 1.95\n",
      "episode: 1184   score: 3.0   memory length: 218675   epsilon: 0.8872578000000519    steps: 214     evaluation reward: 1.97\n",
      "episode: 1185   score: 1.0   memory length: 218856   epsilon: 0.887085850000052    steps: 181     evaluation reward: 1.95\n",
      "episode: 1186   score: 1.0   memory length: 219016   epsilon: 0.8869338500000521    steps: 160     evaluation reward: 1.92\n",
      "episode: 1187   score: 3.0   memory length: 219292   epsilon: 0.8866716500000522    steps: 276     evaluation reward: 1.93\n",
      "episode: 1188   score: 4.0   memory length: 219583   epsilon: 0.8863952000000523    steps: 291     evaluation reward: 1.95\n",
      "episode: 1189   score: 2.0   memory length: 219772   epsilon: 0.8862156500000524    steps: 189     evaluation reward: 1.95\n",
      "episode: 1190   score: 3.0   memory length: 220045   epsilon: 0.8859563000000525    steps: 273     evaluation reward: 1.97\n",
      "episode: 1191   score: 4.0   memory length: 220330   epsilon: 0.8856855500000527    steps: 285     evaluation reward: 1.99\n",
      "episode: 1192   score: 1.0   memory length: 220486   epsilon: 0.8855373500000527    steps: 156     evaluation reward: 1.99\n",
      "episode: 1193   score: 0.0   memory length: 220611   epsilon: 0.8854186000000528    steps: 125     evaluation reward: 1.98\n",
      "episode: 1194   score: 3.0   memory length: 220875   epsilon: 0.8851678000000529    steps: 264     evaluation reward: 2.0\n",
      "episode: 1195   score: 5.0   memory length: 221203   epsilon: 0.884856200000053    steps: 328     evaluation reward: 2.04\n",
      "episode: 1196   score: 4.0   memory length: 221468   epsilon: 0.8846044500000532    steps: 265     evaluation reward: 2.06\n",
      "episode: 1197   score: 2.0   memory length: 221677   epsilon: 0.8844059000000533    steps: 209     evaluation reward: 2.05\n",
      "episode: 1198   score: 4.0   memory length: 221978   epsilon: 0.8841199500000534    steps: 301     evaluation reward: 2.06\n",
      "episode: 1199   score: 2.0   memory length: 222184   epsilon: 0.8839242500000535    steps: 206     evaluation reward: 2.06\n",
      "episode: 1200   score: 1.0   memory length: 222346   epsilon: 0.8837703500000536    steps: 162     evaluation reward: 2.06\n",
      "episode: 1201   score: 1.0   memory length: 222526   epsilon: 0.8835993500000536    steps: 180     evaluation reward: 2.06\n",
      "episode: 1202   score: 2.0   memory length: 222739   epsilon: 0.8833970000000537    steps: 213     evaluation reward: 2.06\n",
      "episode: 1203   score: 3.0   memory length: 222978   epsilon: 0.8831699500000538    steps: 239     evaluation reward: 2.06\n",
      "episode: 1204   score: 4.0   memory length: 223278   epsilon: 0.882884950000054    steps: 300     evaluation reward: 2.1\n",
      "episode: 1205   score: 4.0   memory length: 223586   epsilon: 0.8825923500000541    steps: 308     evaluation reward: 2.12\n",
      "episode: 1206   score: 3.0   memory length: 223829   epsilon: 0.8823615000000542    steps: 243     evaluation reward: 2.14\n",
      "episode: 1207   score: 3.0   memory length: 224066   epsilon: 0.8821363500000543    steps: 237     evaluation reward: 2.12\n",
      "episode: 1208   score: 2.0   memory length: 224281   epsilon: 0.8819321000000544    steps: 215     evaluation reward: 2.11\n",
      "episode: 1209   score: 1.0   memory length: 224442   epsilon: 0.8817791500000545    steps: 161     evaluation reward: 2.1\n",
      "episode: 1210   score: 2.0   memory length: 224655   epsilon: 0.8815768000000546    steps: 213     evaluation reward: 2.09\n",
      "episode: 1211   score: 2.0   memory length: 224867   epsilon: 0.8813754000000547    steps: 212     evaluation reward: 2.05\n",
      "episode: 1212   score: 3.0   memory length: 225093   epsilon: 0.8811607000000548    steps: 226     evaluation reward: 2.04\n",
      "episode: 1213   score: 1.0   memory length: 225269   epsilon: 0.8809935000000548    steps: 176     evaluation reward: 2.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1214   score: 0.0   memory length: 225401   epsilon: 0.8808681000000549    steps: 132     evaluation reward: 2.0\n",
      "episode: 1215   score: 4.0   memory length: 225652   epsilon: 0.880629650000055    steps: 251     evaluation reward: 2.02\n",
      "episode: 1216   score: 2.0   memory length: 225862   epsilon: 0.8804301500000551    steps: 210     evaluation reward: 2.03\n",
      "episode: 1217   score: 0.0   memory length: 226006   epsilon: 0.8802933500000552    steps: 144     evaluation reward: 1.99\n",
      "episode: 1218   score: 1.0   memory length: 226164   epsilon: 0.8801432500000552    steps: 158     evaluation reward: 1.99\n",
      "episode: 1219   score: 5.0   memory length: 226497   epsilon: 0.8798269000000554    steps: 333     evaluation reward: 2.02\n",
      "episode: 1220   score: 4.0   memory length: 226790   epsilon: 0.8795485500000555    steps: 293     evaluation reward: 2.02\n",
      "episode: 1221   score: 4.0   memory length: 227093   epsilon: 0.8792607000000556    steps: 303     evaluation reward: 2.02\n",
      "episode: 1222   score: 1.0   memory length: 227249   epsilon: 0.8791125000000557    steps: 156     evaluation reward: 2.02\n",
      "episode: 1223   score: 2.0   memory length: 227444   epsilon: 0.8789272500000558    steps: 195     evaluation reward: 2.04\n",
      "episode: 1224   score: 2.0   memory length: 227647   epsilon: 0.8787344000000559    steps: 203     evaluation reward: 2.03\n",
      "episode: 1225   score: 3.0   memory length: 227883   epsilon: 0.878510200000056    steps: 236     evaluation reward: 2.04\n",
      "episode: 1226   score: 1.0   memory length: 228045   epsilon: 0.878356300000056    steps: 162     evaluation reward: 2.03\n",
      "episode: 1227   score: 3.0   memory length: 228282   epsilon: 0.8781311500000561    steps: 237     evaluation reward: 2.04\n",
      "episode: 1228   score: 2.0   memory length: 228470   epsilon: 0.8779525500000562    steps: 188     evaluation reward: 2.03\n",
      "episode: 1229   score: 3.0   memory length: 228687   epsilon: 0.8777464000000563    steps: 217     evaluation reward: 2.05\n",
      "episode: 1230   score: 3.0   memory length: 228926   epsilon: 0.8775193500000564    steps: 239     evaluation reward: 2.06\n",
      "episode: 1231   score: 4.0   memory length: 229207   epsilon: 0.8772524000000566    steps: 281     evaluation reward: 2.1\n",
      "episode: 1232   score: 5.0   memory length: 229556   epsilon: 0.8769208500000567    steps: 349     evaluation reward: 2.15\n",
      "episode: 1233   score: 5.0   memory length: 229870   epsilon: 0.8766225500000568    steps: 314     evaluation reward: 2.15\n",
      "episode: 1234   score: 0.0   memory length: 230003   epsilon: 0.8764962000000569    steps: 133     evaluation reward: 2.11\n",
      "episode: 1235   score: 2.0   memory length: 230201   epsilon: 0.876308100000057    steps: 198     evaluation reward: 2.12\n",
      "episode: 1236   score: 3.0   memory length: 230440   epsilon: 0.8760810500000571    steps: 239     evaluation reward: 2.13\n",
      "episode: 1237   score: 4.0   memory length: 230761   epsilon: 0.8757761000000572    steps: 321     evaluation reward: 2.16\n",
      "episode: 1238   score: 1.0   memory length: 230928   epsilon: 0.8756174500000573    steps: 167     evaluation reward: 2.16\n",
      "episode: 1239   score: 0.0   memory length: 231066   epsilon: 0.8754863500000574    steps: 138     evaluation reward: 2.15\n",
      "episode: 1240   score: 4.0   memory length: 231337   epsilon: 0.8752289000000575    steps: 271     evaluation reward: 2.19\n",
      "episode: 1241   score: 5.0   memory length: 231696   epsilon: 0.8748878500000576    steps: 359     evaluation reward: 2.22\n",
      "episode: 1242   score: 2.0   memory length: 231897   epsilon: 0.8746969000000577    steps: 201     evaluation reward: 2.23\n",
      "episode: 1243   score: 0.0   memory length: 232043   epsilon: 0.8745582000000578    steps: 146     evaluation reward: 2.21\n",
      "episode: 1244   score: 0.0   memory length: 232174   epsilon: 0.8744337500000579    steps: 131     evaluation reward: 2.21\n",
      "episode: 1245   score: 1.0   memory length: 232333   epsilon: 0.8742827000000579    steps: 159     evaluation reward: 2.2\n",
      "episode: 1246   score: 5.0   memory length: 232658   epsilon: 0.8739739500000581    steps: 325     evaluation reward: 2.23\n",
      "episode: 1247   score: 1.0   memory length: 232812   epsilon: 0.8738276500000581    steps: 154     evaluation reward: 2.24\n",
      "episode: 1248   score: 3.0   memory length: 233041   epsilon: 0.8736101000000582    steps: 229     evaluation reward: 2.24\n",
      "episode: 1249   score: 3.0   memory length: 233288   epsilon: 0.8733754500000583    steps: 247     evaluation reward: 2.25\n",
      "episode: 1250   score: 2.0   memory length: 233499   epsilon: 0.8731750000000584    steps: 211     evaluation reward: 2.27\n",
      "episode: 1251   score: 3.0   memory length: 233746   epsilon: 0.8729403500000585    steps: 247     evaluation reward: 2.25\n",
      "episode: 1252   score: 1.0   memory length: 233915   epsilon: 0.8727798000000586    steps: 169     evaluation reward: 2.22\n",
      "episode: 1253   score: 1.0   memory length: 234075   epsilon: 0.8726278000000587    steps: 160     evaluation reward: 2.2\n",
      "episode: 1254   score: 4.0   memory length: 234384   epsilon: 0.8723342500000588    steps: 309     evaluation reward: 2.21\n",
      "episode: 1255   score: 3.0   memory length: 234623   epsilon: 0.8721072000000589    steps: 239     evaluation reward: 2.2\n",
      "episode: 1256   score: 2.0   memory length: 234836   epsilon: 0.871904850000059    steps: 213     evaluation reward: 2.21\n",
      "episode: 1257   score: 2.0   memory length: 235085   epsilon: 0.8716683000000591    steps: 249     evaluation reward: 2.22\n",
      "episode: 1258   score: 1.0   memory length: 235254   epsilon: 0.8715077500000592    steps: 169     evaluation reward: 2.23\n",
      "episode: 1259   score: 2.0   memory length: 235456   epsilon: 0.8713158500000593    steps: 202     evaluation reward: 2.23\n",
      "episode: 1260   score: 4.0   memory length: 235725   epsilon: 0.8710603000000594    steps: 269     evaluation reward: 2.25\n",
      "episode: 1261   score: 1.0   memory length: 235886   epsilon: 0.8709073500000595    steps: 161     evaluation reward: 2.26\n",
      "episode: 1262   score: 1.0   memory length: 236060   epsilon: 0.8707420500000596    steps: 174     evaluation reward: 2.27\n",
      "episode: 1263   score: 1.0   memory length: 236234   epsilon: 0.8705767500000596    steps: 174     evaluation reward: 2.25\n",
      "episode: 1264   score: 2.0   memory length: 236432   epsilon: 0.8703886500000597    steps: 198     evaluation reward: 2.26\n",
      "episode: 1265   score: 4.0   memory length: 236716   epsilon: 0.8701188500000598    steps: 284     evaluation reward: 2.29\n",
      "episode: 1266   score: 2.0   memory length: 236903   epsilon: 0.8699412000000599    steps: 187     evaluation reward: 2.3\n",
      "episode: 1267   score: 3.0   memory length: 237138   epsilon: 0.86971795000006    steps: 235     evaluation reward: 2.3\n",
      "episode: 1268   score: 3.0   memory length: 237400   epsilon: 0.8694690500000601    steps: 262     evaluation reward: 2.32\n",
      "episode: 1269   score: 3.0   memory length: 237644   epsilon: 0.8692372500000602    steps: 244     evaluation reward: 2.32\n",
      "episode: 1270   score: 4.0   memory length: 237927   epsilon: 0.8689684000000604    steps: 283     evaluation reward: 2.36\n",
      "episode: 1271   score: 2.0   memory length: 238114   epsilon: 0.8687907500000605    steps: 187     evaluation reward: 2.36\n",
      "episode: 1272   score: 3.0   memory length: 238363   epsilon: 0.8685542000000606    steps: 249     evaluation reward: 2.38\n",
      "episode: 1273   score: 1.0   memory length: 238539   epsilon: 0.8683870000000606    steps: 176     evaluation reward: 2.38\n",
      "episode: 1274   score: 2.0   memory length: 238740   epsilon: 0.8681960500000607    steps: 201     evaluation reward: 2.36\n",
      "episode: 1275   score: 2.0   memory length: 238957   epsilon: 0.8679899000000608    steps: 217     evaluation reward: 2.36\n",
      "episode: 1276   score: 3.0   memory length: 239231   epsilon: 0.8677296000000609    steps: 274     evaluation reward: 2.36\n",
      "episode: 1277   score: 4.0   memory length: 239529   epsilon: 0.8674465000000611    steps: 298     evaluation reward: 2.36\n",
      "episode: 1278   score: 6.0   memory length: 239888   epsilon: 0.8671054500000612    steps: 359     evaluation reward: 2.41\n",
      "episode: 1279   score: 2.0   memory length: 240103   epsilon: 0.8669012000000613    steps: 215     evaluation reward: 2.42\n",
      "episode: 1280   score: 2.0   memory length: 240315   epsilon: 0.8666998000000614    steps: 212     evaluation reward: 2.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1281   score: 0.0   memory length: 240444   epsilon: 0.8665772500000615    steps: 129     evaluation reward: 2.4\n",
      "episode: 1282   score: 3.0   memory length: 240708   epsilon: 0.8663264500000616    steps: 264     evaluation reward: 2.41\n",
      "episode: 1283   score: 7.0   memory length: 240995   epsilon: 0.8660538000000617    steps: 287     evaluation reward: 2.48\n",
      "episode: 1284   score: 0.0   memory length: 241125   epsilon: 0.8659303000000618    steps: 130     evaluation reward: 2.45\n",
      "episode: 1285   score: 4.0   memory length: 241385   epsilon: 0.8656833000000619    steps: 260     evaluation reward: 2.48\n",
      "episode: 1286   score: 2.0   memory length: 241606   epsilon: 0.865473350000062    steps: 221     evaluation reward: 2.49\n",
      "episode: 1287   score: 3.0   memory length: 241863   epsilon: 0.8652292000000621    steps: 257     evaluation reward: 2.49\n",
      "episode: 1288   score: 1.0   memory length: 242047   epsilon: 0.8650544000000622    steps: 184     evaluation reward: 2.46\n",
      "episode: 1289   score: 2.0   memory length: 242237   epsilon: 0.8648739000000623    steps: 190     evaluation reward: 2.46\n",
      "episode: 1290   score: 4.0   memory length: 242519   epsilon: 0.8646060000000624    steps: 282     evaluation reward: 2.47\n",
      "episode: 1291   score: 2.0   memory length: 242714   epsilon: 0.8644207500000625    steps: 195     evaluation reward: 2.45\n",
      "episode: 1292   score: 1.0   memory length: 242886   epsilon: 0.8642573500000625    steps: 172     evaluation reward: 2.45\n",
      "episode: 1293   score: 5.0   memory length: 243239   epsilon: 0.8639220000000627    steps: 353     evaluation reward: 2.5\n",
      "episode: 1294   score: 1.0   memory length: 243417   epsilon: 0.8637529000000628    steps: 178     evaluation reward: 2.48\n",
      "episode: 1295   score: 0.0   memory length: 243539   epsilon: 0.8636370000000628    steps: 122     evaluation reward: 2.43\n",
      "episode: 1296   score: 3.0   memory length: 243791   epsilon: 0.8633976000000629    steps: 252     evaluation reward: 2.42\n",
      "episode: 1297   score: 1.0   memory length: 243966   epsilon: 0.863231350000063    steps: 175     evaluation reward: 2.41\n",
      "episode: 1298   score: 7.0   memory length: 244394   epsilon: 0.8628247500000632    steps: 428     evaluation reward: 2.44\n",
      "episode: 1299   score: 2.0   memory length: 244606   epsilon: 0.8626233500000633    steps: 212     evaluation reward: 2.44\n",
      "episode: 1300   score: 2.0   memory length: 244792   epsilon: 0.8624466500000634    steps: 186     evaluation reward: 2.45\n",
      "episode: 1301   score: 2.0   memory length: 244973   epsilon: 0.8622747000000635    steps: 181     evaluation reward: 2.46\n",
      "episode: 1302   score: 2.0   memory length: 245175   epsilon: 0.8620828000000635    steps: 202     evaluation reward: 2.46\n",
      "episode: 1303   score: 3.0   memory length: 245409   epsilon: 0.8618605000000636    steps: 234     evaluation reward: 2.46\n",
      "episode: 1304   score: 3.0   memory length: 245701   epsilon: 0.8615831000000638    steps: 292     evaluation reward: 2.45\n",
      "episode: 1305   score: 2.0   memory length: 245904   epsilon: 0.8613902500000639    steps: 203     evaluation reward: 2.43\n",
      "episode: 1306   score: 3.0   memory length: 246135   epsilon: 0.861170800000064    steps: 231     evaluation reward: 2.43\n",
      "episode: 1307   score: 1.0   memory length: 246292   epsilon: 0.861021650000064    steps: 157     evaluation reward: 2.41\n",
      "episode: 1308   score: 0.0   memory length: 246431   epsilon: 0.8608896000000641    steps: 139     evaluation reward: 2.39\n",
      "episode: 1309   score: 8.0   memory length: 246891   epsilon: 0.8604526000000643    steps: 460     evaluation reward: 2.46\n",
      "episode: 1310   score: 3.0   memory length: 247150   epsilon: 0.8602065500000644    steps: 259     evaluation reward: 2.47\n",
      "episode: 1311   score: 5.0   memory length: 247432   epsilon: 0.8599386500000645    steps: 282     evaluation reward: 2.5\n",
      "episode: 1312   score: 0.0   memory length: 247558   epsilon: 0.8598189500000646    steps: 126     evaluation reward: 2.47\n",
      "episode: 1313   score: 0.0   memory length: 247683   epsilon: 0.8597002000000646    steps: 125     evaluation reward: 2.46\n",
      "episode: 1314   score: 0.0   memory length: 247806   epsilon: 0.8595833500000647    steps: 123     evaluation reward: 2.46\n",
      "episode: 1315   score: 1.0   memory length: 247963   epsilon: 0.8594342000000648    steps: 157     evaluation reward: 2.43\n",
      "episode: 1316   score: 5.0   memory length: 248304   epsilon: 0.8591102500000649    steps: 341     evaluation reward: 2.46\n",
      "episode: 1317   score: 3.0   memory length: 248555   epsilon: 0.858871800000065    steps: 251     evaluation reward: 2.49\n",
      "episode: 1318   score: 0.0   memory length: 248682   epsilon: 0.8587511500000651    steps: 127     evaluation reward: 2.48\n",
      "episode: 1319   score: 0.0   memory length: 248811   epsilon: 0.8586286000000651    steps: 129     evaluation reward: 2.43\n",
      "episode: 1320   score: 4.0   memory length: 249090   epsilon: 0.8583635500000653    steps: 279     evaluation reward: 2.43\n",
      "episode: 1321   score: 1.0   memory length: 249255   epsilon: 0.8582068000000653    steps: 165     evaluation reward: 2.4\n",
      "episode: 1322   score: 1.0   memory length: 249429   epsilon: 0.8580415000000654    steps: 174     evaluation reward: 2.4\n",
      "episode: 1323   score: 4.0   memory length: 249715   epsilon: 0.8577698000000655    steps: 286     evaluation reward: 2.42\n",
      "episode: 1324   score: 3.0   memory length: 249943   epsilon: 0.8575532000000656    steps: 228     evaluation reward: 2.43\n",
      "now time :  2018-12-14 08:27:16.700217\n",
      "episode: 1325   score: 3.0   memory length: 250182   epsilon: 0.8573261500000657    steps: 239     evaluation reward: 2.43\n",
      "episode: 1326   score: 1.0   memory length: 250360   epsilon: 0.8571570500000658    steps: 178     evaluation reward: 2.43\n",
      "episode: 1327   score: 2.0   memory length: 250587   epsilon: 0.8569414000000659    steps: 227     evaluation reward: 2.42\n",
      "episode: 1328   score: 1.0   memory length: 250743   epsilon: 0.856793200000066    steps: 156     evaluation reward: 2.41\n",
      "episode: 1329   score: 4.0   memory length: 251046   epsilon: 0.8565053500000661    steps: 303     evaluation reward: 2.42\n",
      "episode: 1330   score: 1.0   memory length: 251221   epsilon: 0.8563391000000662    steps: 175     evaluation reward: 2.4\n",
      "episode: 1331   score: 1.0   memory length: 251397   epsilon: 0.8561719000000663    steps: 176     evaluation reward: 2.37\n",
      "episode: 1332   score: 0.0   memory length: 251542   epsilon: 0.8560341500000663    steps: 145     evaluation reward: 2.32\n",
      "episode: 1333   score: 3.0   memory length: 251781   epsilon: 0.8558071000000664    steps: 239     evaluation reward: 2.3\n",
      "episode: 1334   score: 2.0   memory length: 252011   epsilon: 0.8555886000000665    steps: 230     evaluation reward: 2.32\n",
      "episode: 1335   score: 1.0   memory length: 252202   epsilon: 0.8554071500000666    steps: 191     evaluation reward: 2.31\n",
      "episode: 1336   score: 2.0   memory length: 252405   epsilon: 0.8552143000000667    steps: 203     evaluation reward: 2.3\n",
      "episode: 1337   score: 2.0   memory length: 252605   epsilon: 0.8550243000000668    steps: 200     evaluation reward: 2.28\n",
      "episode: 1338   score: 2.0   memory length: 252812   epsilon: 0.8548276500000669    steps: 207     evaluation reward: 2.29\n",
      "episode: 1339   score: 4.0   memory length: 253101   epsilon: 0.854553100000067    steps: 289     evaluation reward: 2.33\n",
      "episode: 1340   score: 1.0   memory length: 253282   epsilon: 0.8543811500000671    steps: 181     evaluation reward: 2.3\n",
      "episode: 1341   score: 4.0   memory length: 253557   epsilon: 0.8541199000000672    steps: 275     evaluation reward: 2.29\n",
      "episode: 1342   score: 4.0   memory length: 253816   epsilon: 0.8538738500000673    steps: 259     evaluation reward: 2.31\n",
      "episode: 1343   score: 2.0   memory length: 254017   epsilon: 0.8536829000000674    steps: 201     evaluation reward: 2.33\n",
      "episode: 1344   score: 2.0   memory length: 254243   epsilon: 0.8534682000000675    steps: 226     evaluation reward: 2.35\n",
      "episode: 1345   score: 2.0   memory length: 254456   epsilon: 0.8532658500000676    steps: 213     evaluation reward: 2.36\n",
      "episode: 1346   score: 2.0   memory length: 254644   epsilon: 0.8530872500000677    steps: 188     evaluation reward: 2.33\n",
      "episode: 1347   score: 1.0   memory length: 254797   epsilon: 0.8529419000000678    steps: 153     evaluation reward: 2.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1348   score: 1.0   memory length: 254978   epsilon: 0.8527699500000678    steps: 181     evaluation reward: 2.31\n",
      "episode: 1349   score: 2.0   memory length: 255167   epsilon: 0.8525904000000679    steps: 189     evaluation reward: 2.3\n",
      "episode: 1350   score: 2.0   memory length: 255351   epsilon: 0.852415600000068    steps: 184     evaluation reward: 2.3\n",
      "episode: 1351   score: 3.0   memory length: 255621   epsilon: 0.8521591000000681    steps: 270     evaluation reward: 2.3\n",
      "episode: 1352   score: 6.0   memory length: 255981   epsilon: 0.8518171000000683    steps: 360     evaluation reward: 2.35\n",
      "episode: 1353   score: 1.0   memory length: 256148   epsilon: 0.8516584500000683    steps: 167     evaluation reward: 2.35\n",
      "episode: 1354   score: 4.0   memory length: 256412   epsilon: 0.8514076500000685    steps: 264     evaluation reward: 2.35\n",
      "episode: 1355   score: 2.0   memory length: 256619   epsilon: 0.8512110000000686    steps: 207     evaluation reward: 2.34\n",
      "episode: 1356   score: 5.0   memory length: 256934   epsilon: 0.8509117500000687    steps: 315     evaluation reward: 2.37\n",
      "episode: 1357   score: 8.0   memory length: 257241   epsilon: 0.8506201000000688    steps: 307     evaluation reward: 2.43\n",
      "episode: 1358   score: 2.0   memory length: 257461   epsilon: 0.8504111000000689    steps: 220     evaluation reward: 2.44\n",
      "episode: 1359   score: 1.0   memory length: 257632   epsilon: 0.850248650000069    steps: 171     evaluation reward: 2.43\n",
      "episode: 1360   score: 2.0   memory length: 257855   epsilon: 0.8500368000000691    steps: 223     evaluation reward: 2.41\n",
      "episode: 1361   score: 3.0   memory length: 258092   epsilon: 0.8498116500000692    steps: 237     evaluation reward: 2.43\n",
      "episode: 1362   score: 5.0   memory length: 258444   epsilon: 0.8494772500000694    steps: 352     evaluation reward: 2.47\n",
      "episode: 1363   score: 3.0   memory length: 258720   epsilon: 0.8492150500000695    steps: 276     evaluation reward: 2.49\n",
      "episode: 1364   score: 2.0   memory length: 258909   epsilon: 0.8490355000000696    steps: 189     evaluation reward: 2.49\n",
      "episode: 1365   score: 4.0   memory length: 259196   epsilon: 0.8487628500000697    steps: 287     evaluation reward: 2.49\n",
      "episode: 1366   score: 1.0   memory length: 259351   epsilon: 0.8486156000000697    steps: 155     evaluation reward: 2.48\n",
      "episode: 1367   score: 0.0   memory length: 259484   epsilon: 0.8484892500000698    steps: 133     evaluation reward: 2.45\n",
      "episode: 1368   score: 0.0   memory length: 259623   epsilon: 0.8483572000000699    steps: 139     evaluation reward: 2.42\n",
      "episode: 1369   score: 3.0   memory length: 259861   epsilon: 0.84813110000007    steps: 238     evaluation reward: 2.42\n",
      "episode: 1370   score: 1.0   memory length: 260025   epsilon: 0.84797530000007    steps: 164     evaluation reward: 2.39\n",
      "episode: 1371   score: 0.0   memory length: 260159   epsilon: 0.8478480000000701    steps: 134     evaluation reward: 2.37\n",
      "episode: 1372   score: 5.0   memory length: 260474   epsilon: 0.8475487500000702    steps: 315     evaluation reward: 2.39\n",
      "episode: 1373   score: 1.0   memory length: 260637   epsilon: 0.8473939000000703    steps: 163     evaluation reward: 2.39\n",
      "episode: 1374   score: 3.0   memory length: 260861   epsilon: 0.8471811000000704    steps: 224     evaluation reward: 2.4\n",
      "episode: 1375   score: 1.0   memory length: 261029   epsilon: 0.8470215000000705    steps: 168     evaluation reward: 2.39\n",
      "episode: 1376   score: 1.0   memory length: 261204   epsilon: 0.8468552500000706    steps: 175     evaluation reward: 2.37\n",
      "episode: 1377   score: 4.0   memory length: 261507   epsilon: 0.8465674000000707    steps: 303     evaluation reward: 2.37\n",
      "episode: 1378   score: 3.0   memory length: 261771   epsilon: 0.8463166000000708    steps: 264     evaluation reward: 2.34\n",
      "episode: 1379   score: 0.0   memory length: 261907   epsilon: 0.8461874000000709    steps: 136     evaluation reward: 2.32\n",
      "episode: 1380   score: 1.0   memory length: 262082   epsilon: 0.8460211500000709    steps: 175     evaluation reward: 2.31\n",
      "episode: 1381   score: 0.0   memory length: 262212   epsilon: 0.845897650000071    steps: 130     evaluation reward: 2.31\n",
      "episode: 1382   score: 4.0   memory length: 262493   epsilon: 0.8456307000000711    steps: 281     evaluation reward: 2.32\n",
      "episode: 1383   score: 1.0   memory length: 262659   epsilon: 0.8454730000000712    steps: 166     evaluation reward: 2.26\n",
      "episode: 1384   score: 1.0   memory length: 262813   epsilon: 0.8453267000000713    steps: 154     evaluation reward: 2.27\n",
      "episode: 1385   score: 1.0   memory length: 262966   epsilon: 0.8451813500000713    steps: 153     evaluation reward: 2.24\n",
      "episode: 1386   score: 4.0   memory length: 263266   epsilon: 0.8448963500000715    steps: 300     evaluation reward: 2.26\n",
      "episode: 1387   score: 2.0   memory length: 263450   epsilon: 0.8447215500000715    steps: 184     evaluation reward: 2.25\n",
      "episode: 1388   score: 3.0   memory length: 263696   epsilon: 0.8444878500000716    steps: 246     evaluation reward: 2.27\n",
      "episode: 1389   score: 2.0   memory length: 263885   epsilon: 0.8443083000000717    steps: 189     evaluation reward: 2.27\n",
      "episode: 1390   score: 3.0   memory length: 264135   epsilon: 0.8440708000000718    steps: 250     evaluation reward: 2.26\n",
      "episode: 1391   score: 4.0   memory length: 264410   epsilon: 0.843809550000072    steps: 275     evaluation reward: 2.28\n",
      "episode: 1392   score: 0.0   memory length: 264536   epsilon: 0.843689850000072    steps: 126     evaluation reward: 2.27\n",
      "episode: 1393   score: 1.0   memory length: 264689   epsilon: 0.8435445000000721    steps: 153     evaluation reward: 2.23\n",
      "episode: 1394   score: 0.0   memory length: 264816   epsilon: 0.8434238500000721    steps: 127     evaluation reward: 2.22\n",
      "episode: 1395   score: 2.0   memory length: 265020   epsilon: 0.8432300500000722    steps: 204     evaluation reward: 2.24\n",
      "episode: 1396   score: 2.0   memory length: 265228   epsilon: 0.8430324500000723    steps: 208     evaluation reward: 2.23\n",
      "episode: 1397   score: 2.0   memory length: 265447   epsilon: 0.8428244000000724    steps: 219     evaluation reward: 2.24\n",
      "episode: 1398   score: 2.0   memory length: 265660   epsilon: 0.8426220500000725    steps: 213     evaluation reward: 2.19\n",
      "episode: 1399   score: 4.0   memory length: 265959   epsilon: 0.8423380000000726    steps: 299     evaluation reward: 2.21\n",
      "episode: 1400   score: 4.0   memory length: 266221   epsilon: 0.8420891000000728    steps: 262     evaluation reward: 2.23\n",
      "episode: 1401   score: 2.0   memory length: 266419   epsilon: 0.8419010000000728    steps: 198     evaluation reward: 2.23\n",
      "episode: 1402   score: 2.0   memory length: 266629   epsilon: 0.8417015000000729    steps: 210     evaluation reward: 2.23\n",
      "episode: 1403   score: 6.0   memory length: 267010   epsilon: 0.8413395500000731    steps: 381     evaluation reward: 2.26\n",
      "episode: 1404   score: 5.0   memory length: 267332   epsilon: 0.8410336500000732    steps: 322     evaluation reward: 2.28\n",
      "episode: 1405   score: 2.0   memory length: 267529   epsilon: 0.8408465000000733    steps: 197     evaluation reward: 2.28\n",
      "episode: 1406   score: 2.0   memory length: 267737   epsilon: 0.8406489000000734    steps: 208     evaluation reward: 2.27\n",
      "episode: 1407   score: 5.0   memory length: 268036   epsilon: 0.8403648500000735    steps: 299     evaluation reward: 2.31\n",
      "episode: 1408   score: 7.0   memory length: 268425   epsilon: 0.8399953000000737    steps: 389     evaluation reward: 2.38\n",
      "episode: 1409   score: 3.0   memory length: 268684   epsilon: 0.8397492500000738    steps: 259     evaluation reward: 2.33\n",
      "episode: 1410   score: 4.0   memory length: 268944   epsilon: 0.839502250000074    steps: 260     evaluation reward: 2.34\n",
      "episode: 1411   score: 3.0   memory length: 269205   epsilon: 0.8392543000000741    steps: 261     evaluation reward: 2.32\n",
      "episode: 1412   score: 2.0   memory length: 269408   epsilon: 0.8390614500000741    steps: 203     evaluation reward: 2.34\n",
      "episode: 1413   score: 2.0   memory length: 269612   epsilon: 0.8388676500000742    steps: 204     evaluation reward: 2.36\n",
      "episode: 1414   score: 1.0   memory length: 269775   epsilon: 0.8387128000000743    steps: 163     evaluation reward: 2.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1415   score: 4.0   memory length: 270052   epsilon: 0.8384496500000744    steps: 277     evaluation reward: 2.4\n",
      "episode: 1416   score: 0.0   memory length: 270182   epsilon: 0.8383261500000745    steps: 130     evaluation reward: 2.35\n",
      "episode: 1417   score: 0.0   memory length: 270310   epsilon: 0.8382045500000745    steps: 128     evaluation reward: 2.32\n",
      "episode: 1418   score: 0.0   memory length: 270441   epsilon: 0.8380801000000746    steps: 131     evaluation reward: 2.32\n",
      "episode: 1419   score: 3.0   memory length: 270693   epsilon: 0.8378407000000747    steps: 252     evaluation reward: 2.35\n",
      "episode: 1420   score: 3.0   memory length: 270967   epsilon: 0.8375804000000748    steps: 274     evaluation reward: 2.34\n",
      "episode: 1421   score: 3.0   memory length: 271223   epsilon: 0.8373372000000749    steps: 256     evaluation reward: 2.36\n",
      "episode: 1422   score: 8.0   memory length: 271523   epsilon: 0.8370522000000751    steps: 300     evaluation reward: 2.43\n",
      "episode: 1423   score: 6.0   memory length: 271899   epsilon: 0.8366950000000752    steps: 376     evaluation reward: 2.45\n",
      "episode: 1424   score: 4.0   memory length: 272184   epsilon: 0.8364242500000754    steps: 285     evaluation reward: 2.46\n",
      "episode: 1425   score: 5.0   memory length: 272509   epsilon: 0.8361155000000755    steps: 325     evaluation reward: 2.48\n",
      "episode: 1426   score: 0.0   memory length: 272635   epsilon: 0.8359958000000756    steps: 126     evaluation reward: 2.47\n",
      "episode: 1427   score: 1.0   memory length: 272811   epsilon: 0.8358286000000756    steps: 176     evaluation reward: 2.46\n",
      "episode: 1428   score: 2.0   memory length: 273006   epsilon: 0.8356433500000757    steps: 195     evaluation reward: 2.47\n",
      "episode: 1429   score: 1.0   memory length: 273159   epsilon: 0.8354980000000758    steps: 153     evaluation reward: 2.44\n",
      "episode: 1430   score: 3.0   memory length: 273388   epsilon: 0.8352804500000759    steps: 229     evaluation reward: 2.46\n",
      "episode: 1431   score: 1.0   memory length: 273560   epsilon: 0.835117050000076    steps: 172     evaluation reward: 2.46\n",
      "episode: 1432   score: 3.0   memory length: 273805   epsilon: 0.8348843000000761    steps: 245     evaluation reward: 2.49\n",
      "episode: 1433   score: 3.0   memory length: 274040   epsilon: 0.8346610500000762    steps: 235     evaluation reward: 2.49\n",
      "episode: 1434   score: 3.0   memory length: 274306   epsilon: 0.8344083500000763    steps: 266     evaluation reward: 2.5\n",
      "episode: 1435   score: 3.0   memory length: 274532   epsilon: 0.8341936500000764    steps: 226     evaluation reward: 2.52\n",
      "episode: 1436   score: 5.0   memory length: 274862   epsilon: 0.8338801500000765    steps: 330     evaluation reward: 2.55\n",
      "episode: 1437   score: 1.0   memory length: 275017   epsilon: 0.8337329000000766    steps: 155     evaluation reward: 2.54\n",
      "episode: 1438   score: 0.0   memory length: 275150   epsilon: 0.8336065500000767    steps: 133     evaluation reward: 2.52\n",
      "episode: 1439   score: 5.0   memory length: 275482   epsilon: 0.8332911500000768    steps: 332     evaluation reward: 2.53\n",
      "episode: 1440   score: 4.0   memory length: 275774   epsilon: 0.8330137500000769    steps: 292     evaluation reward: 2.56\n",
      "episode: 1441   score: 4.0   memory length: 276071   epsilon: 0.8327316000000771    steps: 297     evaluation reward: 2.56\n",
      "episode: 1442   score: 5.0   memory length: 276372   epsilon: 0.8324456500000772    steps: 301     evaluation reward: 2.57\n",
      "episode: 1443   score: 2.0   memory length: 276603   epsilon: 0.8322262000000773    steps: 231     evaluation reward: 2.57\n",
      "episode: 1444   score: 1.0   memory length: 276763   epsilon: 0.8320742000000774    steps: 160     evaluation reward: 2.56\n",
      "episode: 1445   score: 3.0   memory length: 277004   epsilon: 0.8318452500000775    steps: 241     evaluation reward: 2.57\n",
      "episode: 1446   score: 3.0   memory length: 277228   epsilon: 0.8316324500000776    steps: 224     evaluation reward: 2.58\n",
      "episode: 1447   score: 0.0   memory length: 277358   epsilon: 0.8315089500000776    steps: 130     evaluation reward: 2.57\n",
      "episode: 1448   score: 2.0   memory length: 277558   epsilon: 0.8313189500000777    steps: 200     evaluation reward: 2.58\n",
      "episode: 1449   score: 3.0   memory length: 277778   epsilon: 0.8311099500000778    steps: 220     evaluation reward: 2.59\n",
      "episode: 1450   score: 2.0   memory length: 277995   epsilon: 0.8309038000000779    steps: 217     evaluation reward: 2.59\n",
      "episode: 1451   score: 2.0   memory length: 278203   epsilon: 0.830706200000078    steps: 208     evaluation reward: 2.58\n",
      "episode: 1452   score: 1.0   memory length: 278356   epsilon: 0.8305608500000781    steps: 153     evaluation reward: 2.53\n",
      "episode: 1453   score: 4.0   memory length: 278631   epsilon: 0.8302996000000782    steps: 275     evaluation reward: 2.56\n",
      "episode: 1454   score: 1.0   memory length: 278785   epsilon: 0.8301533000000783    steps: 154     evaluation reward: 2.53\n",
      "episode: 1455   score: 5.0   memory length: 279100   epsilon: 0.8298540500000784    steps: 315     evaluation reward: 2.56\n",
      "episode: 1456   score: 2.0   memory length: 279308   epsilon: 0.8296564500000785    steps: 208     evaluation reward: 2.53\n",
      "episode: 1457   score: 1.0   memory length: 279494   epsilon: 0.8294797500000786    steps: 186     evaluation reward: 2.46\n",
      "episode: 1458   score: 1.0   memory length: 279647   epsilon: 0.8293344000000786    steps: 153     evaluation reward: 2.45\n",
      "episode: 1459   score: 1.0   memory length: 279824   epsilon: 0.8291662500000787    steps: 177     evaluation reward: 2.45\n",
      "episode: 1460   score: 3.0   memory length: 280059   epsilon: 0.8289430000000788    steps: 235     evaluation reward: 2.46\n",
      "episode: 1461   score: 3.0   memory length: 280297   epsilon: 0.8287169000000789    steps: 238     evaluation reward: 2.46\n",
      "episode: 1462   score: 6.0   memory length: 280675   epsilon: 0.8283578000000791    steps: 378     evaluation reward: 2.47\n",
      "episode: 1463   score: 2.0   memory length: 280865   epsilon: 0.8281773000000792    steps: 190     evaluation reward: 2.46\n",
      "episode: 1464   score: 5.0   memory length: 281206   epsilon: 0.8278533500000793    steps: 341     evaluation reward: 2.49\n",
      "episode: 1465   score: 2.0   memory length: 281416   epsilon: 0.8276538500000794    steps: 210     evaluation reward: 2.47\n",
      "episode: 1466   score: 3.0   memory length: 281638   epsilon: 0.8274429500000795    steps: 222     evaluation reward: 2.49\n",
      "episode: 1467   score: 6.0   memory length: 282009   epsilon: 0.8270905000000797    steps: 371     evaluation reward: 2.55\n",
      "episode: 1468   score: 4.0   memory length: 282282   epsilon: 0.8268311500000798    steps: 273     evaluation reward: 2.59\n",
      "episode: 1469   score: 2.0   memory length: 282491   epsilon: 0.8266326000000799    steps: 209     evaluation reward: 2.58\n",
      "episode: 1470   score: 2.0   memory length: 282681   epsilon: 0.82645210000008    steps: 190     evaluation reward: 2.59\n",
      "episode: 1471   score: 3.0   memory length: 282958   epsilon: 0.8261889500000801    steps: 277     evaluation reward: 2.62\n",
      "episode: 1472   score: 2.0   memory length: 283150   epsilon: 0.8260065500000802    steps: 192     evaluation reward: 2.59\n",
      "episode: 1473   score: 2.0   memory length: 283349   epsilon: 0.8258175000000803    steps: 199     evaluation reward: 2.6\n",
      "episode: 1474   score: 5.0   memory length: 283673   epsilon: 0.8255097000000804    steps: 324     evaluation reward: 2.62\n",
      "episode: 1475   score: 3.0   memory length: 283918   epsilon: 0.8252769500000805    steps: 245     evaluation reward: 2.64\n",
      "episode: 1476   score: 7.0   memory length: 284323   epsilon: 0.8248922000000807    steps: 405     evaluation reward: 2.7\n",
      "episode: 1477   score: 3.0   memory length: 284570   epsilon: 0.8246575500000808    steps: 247     evaluation reward: 2.69\n",
      "episode: 1478   score: 2.0   memory length: 284779   epsilon: 0.8244590000000809    steps: 209     evaluation reward: 2.68\n",
      "episode: 1479   score: 3.0   memory length: 285009   epsilon: 0.824240500000081    steps: 230     evaluation reward: 2.71\n",
      "episode: 1480   score: 9.0   memory length: 285497   epsilon: 0.8237769000000812    steps: 488     evaluation reward: 2.79\n",
      "episode: 1481   score: 3.0   memory length: 285757   epsilon: 0.8235299000000813    steps: 260     evaluation reward: 2.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1482   score: 1.0   memory length: 285916   epsilon: 0.8233788500000814    steps: 159     evaluation reward: 2.79\n",
      "episode: 1483   score: 3.0   memory length: 286153   epsilon: 0.8231537000000815    steps: 237     evaluation reward: 2.81\n",
      "episode: 1484   score: 4.0   memory length: 286472   epsilon: 0.8228506500000816    steps: 319     evaluation reward: 2.84\n",
      "episode: 1485   score: 5.0   memory length: 286800   epsilon: 0.8225390500000818    steps: 328     evaluation reward: 2.88\n",
      "episode: 1486   score: 1.0   memory length: 286957   epsilon: 0.8223899000000818    steps: 157     evaluation reward: 2.85\n",
      "episode: 1487   score: 3.0   memory length: 287196   epsilon: 0.8221628500000819    steps: 239     evaluation reward: 2.86\n",
      "episode: 1488   score: 1.0   memory length: 287361   epsilon: 0.822006100000082    steps: 165     evaluation reward: 2.84\n",
      "episode: 1489   score: 2.0   memory length: 287551   epsilon: 0.8218256000000821    steps: 190     evaluation reward: 2.84\n",
      "episode: 1490   score: 3.0   memory length: 287806   epsilon: 0.8215833500000822    steps: 255     evaluation reward: 2.84\n",
      "episode: 1491   score: 7.0   memory length: 288237   epsilon: 0.8211739000000824    steps: 431     evaluation reward: 2.87\n",
      "episode: 1492   score: 9.0   memory length: 288740   epsilon: 0.8206960500000826    steps: 503     evaluation reward: 2.96\n",
      "episode: 1493   score: 5.0   memory length: 289056   epsilon: 0.8203958500000827    steps: 316     evaluation reward: 3.0\n",
      "episode: 1494   score: 3.0   memory length: 289289   epsilon: 0.8201745000000829    steps: 233     evaluation reward: 3.03\n",
      "episode: 1495   score: 3.0   memory length: 289531   epsilon: 0.819944600000083    steps: 242     evaluation reward: 3.04\n",
      "episode: 1496   score: 1.0   memory length: 289707   epsilon: 0.819777400000083    steps: 176     evaluation reward: 3.03\n",
      "episode: 1497   score: 5.0   memory length: 290042   epsilon: 0.8194591500000832    steps: 335     evaluation reward: 3.06\n",
      "episode: 1498   score: 1.0   memory length: 290201   epsilon: 0.8193081000000833    steps: 159     evaluation reward: 3.05\n",
      "episode: 1499   score: 3.0   memory length: 290458   epsilon: 0.8190639500000834    steps: 257     evaluation reward: 3.04\n",
      "episode: 1500   score: 5.0   memory length: 290774   epsilon: 0.8187637500000835    steps: 316     evaluation reward: 3.05\n",
      "episode: 1501   score: 6.0   memory length: 291127   epsilon: 0.8184284000000837    steps: 353     evaluation reward: 3.09\n",
      "episode: 1502   score: 2.0   memory length: 291329   epsilon: 0.8182365000000837    steps: 202     evaluation reward: 3.09\n",
      "episode: 1503   score: 2.0   memory length: 291533   epsilon: 0.8180427000000838    steps: 204     evaluation reward: 3.05\n",
      "episode: 1504   score: 5.0   memory length: 291858   epsilon: 0.817733950000084    steps: 325     evaluation reward: 3.05\n",
      "episode: 1505   score: 6.0   memory length: 292201   epsilon: 0.8174081000000841    steps: 343     evaluation reward: 3.09\n",
      "episode: 1506   score: 1.0   memory length: 292361   epsilon: 0.8172561000000842    steps: 160     evaluation reward: 3.08\n",
      "episode: 1507   score: 5.0   memory length: 292688   epsilon: 0.8169454500000843    steps: 327     evaluation reward: 3.08\n",
      "episode: 1508   score: 4.0   memory length: 292965   epsilon: 0.8166823000000845    steps: 277     evaluation reward: 3.05\n",
      "episode: 1509   score: 1.0   memory length: 293121   epsilon: 0.8165341000000845    steps: 156     evaluation reward: 3.03\n",
      "episode: 1510   score: 0.0   memory length: 293254   epsilon: 0.8164077500000846    steps: 133     evaluation reward: 2.99\n",
      "episode: 1511   score: 3.0   memory length: 293484   epsilon: 0.8161892500000847    steps: 230     evaluation reward: 2.99\n",
      "episode: 1512   score: 4.0   memory length: 293793   epsilon: 0.8158957000000848    steps: 309     evaluation reward: 3.01\n",
      "episode: 1513   score: 7.0   memory length: 294191   epsilon: 0.815517600000085    steps: 398     evaluation reward: 3.06\n",
      "episode: 1514   score: 3.0   memory length: 294446   epsilon: 0.8152753500000851    steps: 255     evaluation reward: 3.08\n",
      "episode: 1515   score: 4.0   memory length: 294755   epsilon: 0.8149818000000852    steps: 309     evaluation reward: 3.08\n",
      "episode: 1516   score: 5.0   memory length: 295072   epsilon: 0.8146806500000854    steps: 317     evaluation reward: 3.13\n",
      "episode: 1517   score: 2.0   memory length: 295291   epsilon: 0.8144726000000855    steps: 219     evaluation reward: 3.15\n",
      "episode: 1518   score: 1.0   memory length: 295456   epsilon: 0.8143158500000856    steps: 165     evaluation reward: 3.16\n",
      "episode: 1519   score: 0.0   memory length: 295582   epsilon: 0.8141961500000856    steps: 126     evaluation reward: 3.13\n",
      "episode: 1520   score: 3.0   memory length: 295807   epsilon: 0.8139824000000857    steps: 225     evaluation reward: 3.13\n",
      "episode: 1521   score: 1.0   memory length: 295962   epsilon: 0.8138351500000858    steps: 155     evaluation reward: 3.11\n",
      "episode: 1522   score: 4.0   memory length: 296262   epsilon: 0.8135501500000859    steps: 300     evaluation reward: 3.07\n",
      "episode: 1523   score: 4.0   memory length: 296523   epsilon: 0.813302200000086    steps: 261     evaluation reward: 3.05\n",
      "episode: 1524   score: 3.0   memory length: 296768   epsilon: 0.8130694500000861    steps: 245     evaluation reward: 3.04\n",
      "episode: 1525   score: 6.0   memory length: 297157   epsilon: 0.8126999000000863    steps: 389     evaluation reward: 3.05\n",
      "episode: 1526   score: 3.0   memory length: 297436   epsilon: 0.8124348500000864    steps: 279     evaluation reward: 3.08\n",
      "episode: 1527   score: 6.0   memory length: 297825   epsilon: 0.8120653000000866    steps: 389     evaluation reward: 3.13\n",
      "episode: 1528   score: 3.0   memory length: 298087   epsilon: 0.8118164000000867    steps: 262     evaluation reward: 3.14\n",
      "episode: 1529   score: 2.0   memory length: 298323   epsilon: 0.8115922000000868    steps: 236     evaluation reward: 3.15\n",
      "episode: 1530   score: 2.0   memory length: 298511   epsilon: 0.8114136000000869    steps: 188     evaluation reward: 3.14\n",
      "episode: 1531   score: 3.0   memory length: 298746   epsilon: 0.811190350000087    steps: 235     evaluation reward: 3.16\n",
      "episode: 1532   score: 4.0   memory length: 299014   epsilon: 0.8109357500000871    steps: 268     evaluation reward: 3.17\n",
      "episode: 1533   score: 5.0   memory length: 299327   epsilon: 0.8106384000000872    steps: 313     evaluation reward: 3.19\n",
      "episode: 1534   score: 5.0   memory length: 299634   epsilon: 0.8103467500000874    steps: 307     evaluation reward: 3.21\n",
      "episode: 1535   score: 2.0   memory length: 299814   epsilon: 0.8101757500000875    steps: 180     evaluation reward: 3.2\n",
      "now time :  2018-12-14 08:42:20.790879\n",
      "episode: 1536   score: 7.0   memory length: 300184   epsilon: 0.8098242500000876    steps: 370     evaluation reward: 3.22\n",
      "episode: 1537   score: 2.0   memory length: 300398   epsilon: 0.8096209500000877    steps: 214     evaluation reward: 3.23\n",
      "episode: 1538   score: 2.0   memory length: 300604   epsilon: 0.8094252500000878    steps: 206     evaluation reward: 3.25\n",
      "episode: 1539   score: 5.0   memory length: 300956   epsilon: 0.809090850000088    steps: 352     evaluation reward: 3.25\n",
      "episode: 1540   score: 3.0   memory length: 301196   epsilon: 0.8088628500000881    steps: 240     evaluation reward: 3.24\n",
      "episode: 1541   score: 2.0   memory length: 301379   epsilon: 0.8086890000000881    steps: 183     evaluation reward: 3.22\n",
      "episode: 1542   score: 4.0   memory length: 301643   epsilon: 0.8084382000000883    steps: 264     evaluation reward: 3.21\n",
      "episode: 1543   score: 4.0   memory length: 301894   epsilon: 0.8081997500000884    steps: 251     evaluation reward: 3.23\n",
      "episode: 1544   score: 8.0   memory length: 302198   epsilon: 0.8079109500000885    steps: 304     evaluation reward: 3.3\n",
      "episode: 1545   score: 4.0   memory length: 302487   epsilon: 0.8076364000000886    steps: 289     evaluation reward: 3.31\n",
      "episode: 1546   score: 3.0   memory length: 302718   epsilon: 0.8074169500000887    steps: 231     evaluation reward: 3.31\n",
      "episode: 1547   score: 0.0   memory length: 302844   epsilon: 0.8072972500000888    steps: 126     evaluation reward: 3.31\n",
      "episode: 1548   score: 4.0   memory length: 303092   epsilon: 0.8070616500000889    steps: 248     evaluation reward: 3.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1549   score: 2.0   memory length: 303304   epsilon: 0.806860250000089    steps: 212     evaluation reward: 3.32\n",
      "episode: 1550   score: 4.0   memory length: 303598   epsilon: 0.8065809500000891    steps: 294     evaluation reward: 3.34\n",
      "episode: 1551   score: 1.0   memory length: 303753   epsilon: 0.8064337000000892    steps: 155     evaluation reward: 3.33\n",
      "episode: 1552   score: 6.0   memory length: 304119   epsilon: 0.8060860000000893    steps: 366     evaluation reward: 3.38\n",
      "episode: 1553   score: 6.0   memory length: 304498   epsilon: 0.8057259500000895    steps: 379     evaluation reward: 3.4\n",
      "episode: 1554   score: 5.0   memory length: 304826   epsilon: 0.8054143500000897    steps: 328     evaluation reward: 3.44\n",
      "episode: 1555   score: 1.0   memory length: 304984   epsilon: 0.8052642500000897    steps: 158     evaluation reward: 3.4\n",
      "episode: 1556   score: 7.0   memory length: 305388   epsilon: 0.8048804500000899    steps: 404     evaluation reward: 3.45\n",
      "episode: 1557   score: 3.0   memory length: 305653   epsilon: 0.80462870000009    steps: 265     evaluation reward: 3.47\n",
      "episode: 1558   score: 5.0   memory length: 305980   epsilon: 0.8043180500000902    steps: 327     evaluation reward: 3.51\n",
      "episode: 1559   score: 5.0   memory length: 306326   epsilon: 0.8039893500000903    steps: 346     evaluation reward: 3.55\n",
      "episode: 1560   score: 3.0   memory length: 306582   epsilon: 0.8037461500000904    steps: 256     evaluation reward: 3.55\n",
      "episode: 1561   score: 5.0   memory length: 306874   epsilon: 0.8034687500000905    steps: 292     evaluation reward: 3.57\n",
      "episode: 1562   score: 4.0   memory length: 307156   epsilon: 0.8032008500000907    steps: 282     evaluation reward: 3.55\n",
      "episode: 1563   score: 1.0   memory length: 307312   epsilon: 0.8030526500000907    steps: 156     evaluation reward: 3.54\n",
      "episode: 1564   score: 2.0   memory length: 307497   epsilon: 0.8028769000000908    steps: 185     evaluation reward: 3.51\n",
      "episode: 1565   score: 5.0   memory length: 307815   epsilon: 0.802574800000091    steps: 318     evaluation reward: 3.54\n",
      "episode: 1566   score: 0.0   memory length: 307945   epsilon: 0.802451300000091    steps: 130     evaluation reward: 3.51\n",
      "episode: 1567   score: 2.0   memory length: 308173   epsilon: 0.8022347000000911    steps: 228     evaluation reward: 3.47\n",
      "episode: 1568   score: 3.0   memory length: 308428   epsilon: 0.8019924500000912    steps: 255     evaluation reward: 3.46\n",
      "episode: 1569   score: 6.0   memory length: 308774   epsilon: 0.8016637500000914    steps: 346     evaluation reward: 3.5\n",
      "episode: 1570   score: 5.0   memory length: 309084   epsilon: 0.8013692500000915    steps: 310     evaluation reward: 3.53\n",
      "episode: 1571   score: 2.0   memory length: 309271   epsilon: 0.8011916000000916    steps: 187     evaluation reward: 3.52\n",
      "episode: 1572   score: 4.0   memory length: 309570   epsilon: 0.8009075500000917    steps: 299     evaluation reward: 3.54\n",
      "episode: 1573   score: 1.0   memory length: 309734   epsilon: 0.8007517500000918    steps: 164     evaluation reward: 3.53\n",
      "episode: 1574   score: 3.0   memory length: 309946   epsilon: 0.8005503500000919    steps: 212     evaluation reward: 3.51\n",
      "episode: 1575   score: 0.0   memory length: 310083   epsilon: 0.800420200000092    steps: 137     evaluation reward: 3.48\n",
      "episode: 1576   score: 1.0   memory length: 310238   epsilon: 0.800272950000092    steps: 155     evaluation reward: 3.42\n",
      "episode: 1577   score: 7.0   memory length: 310487   epsilon: 0.8000364000000921    steps: 249     evaluation reward: 3.46\n",
      "episode: 1578   score: 4.0   memory length: 310752   epsilon: 0.7997846500000922    steps: 265     evaluation reward: 3.48\n",
      "episode: 1579   score: 5.0   memory length: 311069   epsilon: 0.7994835000000924    steps: 317     evaluation reward: 3.5\n",
      "episode: 1580   score: 3.0   memory length: 311299   epsilon: 0.7992650000000925    steps: 230     evaluation reward: 3.44\n",
      "episode: 1581   score: 0.0   memory length: 311431   epsilon: 0.7991396000000925    steps: 132     evaluation reward: 3.41\n",
      "episode: 1582   score: 3.0   memory length: 311701   epsilon: 0.7988831000000927    steps: 270     evaluation reward: 3.43\n",
      "episode: 1583   score: 3.0   memory length: 311951   epsilon: 0.7986456000000928    steps: 250     evaluation reward: 3.43\n",
      "episode: 1584   score: 2.0   memory length: 312150   epsilon: 0.7984565500000929    steps: 199     evaluation reward: 3.41\n",
      "episode: 1585   score: 3.0   memory length: 312426   epsilon: 0.798194350000093    steps: 276     evaluation reward: 3.39\n",
      "episode: 1586   score: 4.0   memory length: 312709   epsilon: 0.7979255000000931    steps: 283     evaluation reward: 3.42\n",
      "episode: 1587   score: 1.0   memory length: 312889   epsilon: 0.7977545000000932    steps: 180     evaluation reward: 3.4\n",
      "episode: 1588   score: 5.0   memory length: 313224   epsilon: 0.7974362500000933    steps: 335     evaluation reward: 3.44\n",
      "episode: 1589   score: 3.0   memory length: 313451   epsilon: 0.7972206000000934    steps: 227     evaluation reward: 3.45\n",
      "episode: 1590   score: 4.0   memory length: 313738   epsilon: 0.7969479500000936    steps: 287     evaluation reward: 3.46\n",
      "episode: 1591   score: 2.0   memory length: 313934   epsilon: 0.7967617500000936    steps: 196     evaluation reward: 3.41\n",
      "episode: 1592   score: 2.0   memory length: 314144   epsilon: 0.7965622500000937    steps: 210     evaluation reward: 3.34\n",
      "episode: 1593   score: 3.0   memory length: 314355   epsilon: 0.7963618000000938    steps: 211     evaluation reward: 3.32\n",
      "episode: 1594   score: 2.0   memory length: 314575   epsilon: 0.7961528000000939    steps: 220     evaluation reward: 3.31\n",
      "episode: 1595   score: 2.0   memory length: 314800   epsilon: 0.795939050000094    steps: 225     evaluation reward: 3.3\n",
      "episode: 1596   score: 2.0   memory length: 315003   epsilon: 0.7957462000000941    steps: 203     evaluation reward: 3.31\n",
      "episode: 1597   score: 6.0   memory length: 315344   epsilon: 0.7954222500000943    steps: 341     evaluation reward: 3.32\n",
      "episode: 1598   score: 3.0   memory length: 315589   epsilon: 0.7951895000000944    steps: 245     evaluation reward: 3.34\n",
      "episode: 1599   score: 2.0   memory length: 315798   epsilon: 0.7949909500000945    steps: 209     evaluation reward: 3.33\n",
      "episode: 1600   score: 4.0   memory length: 316080   epsilon: 0.7947230500000946    steps: 282     evaluation reward: 3.32\n",
      "episode: 1601   score: 1.0   memory length: 316254   epsilon: 0.7945577500000947    steps: 174     evaluation reward: 3.27\n",
      "episode: 1602   score: 7.0   memory length: 316650   epsilon: 0.7941815500000948    steps: 396     evaluation reward: 3.32\n",
      "episode: 1603   score: 7.0   memory length: 317054   epsilon: 0.793797750000095    steps: 404     evaluation reward: 3.37\n",
      "episode: 1604   score: 2.0   memory length: 317242   epsilon: 0.7936191500000951    steps: 188     evaluation reward: 3.34\n",
      "episode: 1605   score: 2.0   memory length: 317428   epsilon: 0.7934424500000952    steps: 186     evaluation reward: 3.3\n",
      "episode: 1606   score: 3.0   memory length: 317681   epsilon: 0.7932021000000953    steps: 253     evaluation reward: 3.32\n",
      "episode: 1607   score: 4.0   memory length: 317974   epsilon: 0.7929237500000954    steps: 293     evaluation reward: 3.31\n",
      "episode: 1608   score: 3.0   memory length: 318228   epsilon: 0.7926824500000955    steps: 254     evaluation reward: 3.3\n",
      "episode: 1609   score: 8.0   memory length: 318661   epsilon: 0.7922711000000957    steps: 433     evaluation reward: 3.37\n",
      "episode: 1610   score: 1.0   memory length: 318836   epsilon: 0.7921048500000958    steps: 175     evaluation reward: 3.38\n",
      "episode: 1611   score: 4.0   memory length: 319138   epsilon: 0.7918179500000959    steps: 302     evaluation reward: 3.39\n",
      "episode: 1612   score: 6.0   memory length: 319518   epsilon: 0.7914569500000961    steps: 380     evaluation reward: 3.41\n",
      "episode: 1613   score: 1.0   memory length: 319673   epsilon: 0.7913097000000962    steps: 155     evaluation reward: 3.35\n",
      "episode: 1614   score: 3.0   memory length: 319943   epsilon: 0.7910532000000963    steps: 270     evaluation reward: 3.35\n",
      "episode: 1615   score: 2.0   memory length: 320171   epsilon: 0.7908366000000964    steps: 228     evaluation reward: 3.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1616   score: 2.0   memory length: 320378   epsilon: 0.7906399500000965    steps: 207     evaluation reward: 3.3\n",
      "episode: 1617   score: 14.0   memory length: 320798   epsilon: 0.7902409500000966    steps: 420     evaluation reward: 3.42\n",
      "episode: 1618   score: 6.0   memory length: 321162   epsilon: 0.7898951500000968    steps: 364     evaluation reward: 3.47\n",
      "episode: 1619   score: 4.0   memory length: 321429   epsilon: 0.7896415000000969    steps: 267     evaluation reward: 3.51\n",
      "episode: 1620   score: 2.0   memory length: 321638   epsilon: 0.789442950000097    steps: 209     evaluation reward: 3.5\n",
      "episode: 1621   score: 1.0   memory length: 321797   epsilon: 0.7892919000000971    steps: 159     evaluation reward: 3.5\n",
      "episode: 1622   score: 4.0   memory length: 322085   epsilon: 0.7890183000000972    steps: 288     evaluation reward: 3.5\n",
      "episode: 1623   score: 2.0   memory length: 322285   epsilon: 0.7888283000000973    steps: 200     evaluation reward: 3.48\n",
      "episode: 1624   score: 2.0   memory length: 322482   epsilon: 0.7886411500000974    steps: 197     evaluation reward: 3.47\n",
      "episode: 1625   score: 3.0   memory length: 322717   epsilon: 0.7884179000000975    steps: 235     evaluation reward: 3.44\n",
      "episode: 1626   score: 2.0   memory length: 322900   epsilon: 0.7882440500000976    steps: 183     evaluation reward: 3.43\n",
      "episode: 1627   score: 6.0   memory length: 323247   epsilon: 0.7879144000000977    steps: 347     evaluation reward: 3.43\n",
      "episode: 1628   score: 0.0   memory length: 323378   epsilon: 0.7877899500000978    steps: 131     evaluation reward: 3.4\n",
      "episode: 1629   score: 3.0   memory length: 323597   epsilon: 0.7875819000000979    steps: 219     evaluation reward: 3.41\n",
      "episode: 1630   score: 1.0   memory length: 323758   epsilon: 0.7874289500000979    steps: 161     evaluation reward: 3.4\n",
      "episode: 1631   score: 5.0   memory length: 324116   epsilon: 0.7870888500000981    steps: 358     evaluation reward: 3.42\n",
      "episode: 1632   score: 6.0   memory length: 324493   epsilon: 0.7867307000000983    steps: 377     evaluation reward: 3.44\n",
      "episode: 1633   score: 4.0   memory length: 324784   epsilon: 0.7864542500000984    steps: 291     evaluation reward: 3.43\n",
      "episode: 1634   score: 2.0   memory length: 324987   epsilon: 0.7862614000000985    steps: 203     evaluation reward: 3.4\n",
      "episode: 1635   score: 3.0   memory length: 325218   epsilon: 0.7860419500000986    steps: 231     evaluation reward: 3.41\n",
      "episode: 1636   score: 9.0   memory length: 325694   epsilon: 0.7855897500000988    steps: 476     evaluation reward: 3.43\n",
      "episode: 1637   score: 4.0   memory length: 325965   epsilon: 0.7853323000000989    steps: 271     evaluation reward: 3.45\n",
      "episode: 1638   score: 3.0   memory length: 326221   epsilon: 0.785089100000099    steps: 256     evaluation reward: 3.46\n",
      "episode: 1639   score: 8.0   memory length: 326684   epsilon: 0.7846492500000992    steps: 463     evaluation reward: 3.49\n",
      "episode: 1640   score: 0.0   memory length: 326828   epsilon: 0.7845124500000993    steps: 144     evaluation reward: 3.46\n",
      "episode: 1641   score: 2.0   memory length: 327016   epsilon: 0.7843338500000994    steps: 188     evaluation reward: 3.46\n",
      "episode: 1642   score: 1.0   memory length: 327197   epsilon: 0.7841619000000994    steps: 181     evaluation reward: 3.43\n",
      "episode: 1643   score: 2.0   memory length: 327394   epsilon: 0.7839747500000995    steps: 197     evaluation reward: 3.41\n",
      "episode: 1644   score: 7.0   memory length: 327806   epsilon: 0.7835833500000997    steps: 412     evaluation reward: 3.4\n",
      "episode: 1645   score: 1.0   memory length: 327988   epsilon: 0.7834104500000998    steps: 182     evaluation reward: 3.37\n",
      "episode: 1646   score: 4.0   memory length: 328300   epsilon: 0.7831140500000999    steps: 312     evaluation reward: 3.38\n",
      "episode: 1647   score: 8.0   memory length: 328591   epsilon: 0.7828376000001    steps: 291     evaluation reward: 3.46\n",
      "episode: 1648   score: 4.0   memory length: 328854   epsilon: 0.7825877500001002    steps: 263     evaluation reward: 3.46\n",
      "episode: 1649   score: 3.0   memory length: 329110   epsilon: 0.7823445500001003    steps: 256     evaluation reward: 3.47\n",
      "episode: 1650   score: 4.0   memory length: 329369   epsilon: 0.7820985000001004    steps: 259     evaluation reward: 3.47\n",
      "episode: 1651   score: 0.0   memory length: 329507   epsilon: 0.7819674000001005    steps: 138     evaluation reward: 3.46\n",
      "episode: 1652   score: 1.0   memory length: 329662   epsilon: 0.7818201500001005    steps: 155     evaluation reward: 3.41\n",
      "episode: 1653   score: 3.0   memory length: 329913   epsilon: 0.7815817000001006    steps: 251     evaluation reward: 3.38\n",
      "episode: 1654   score: 2.0   memory length: 330139   epsilon: 0.7813670000001007    steps: 226     evaluation reward: 3.35\n",
      "episode: 1655   score: 3.0   memory length: 330382   epsilon: 0.7811361500001008    steps: 243     evaluation reward: 3.37\n",
      "episode: 1656   score: 4.0   memory length: 330675   epsilon: 0.780857800000101    steps: 293     evaluation reward: 3.34\n",
      "episode: 1657   score: 3.0   memory length: 330922   epsilon: 0.7806231500001011    steps: 247     evaluation reward: 3.34\n",
      "episode: 1658   score: 2.0   memory length: 331145   epsilon: 0.7804113000001012    steps: 223     evaluation reward: 3.31\n",
      "episode: 1659   score: 4.0   memory length: 331420   epsilon: 0.7801500500001013    steps: 275     evaluation reward: 3.3\n",
      "episode: 1660   score: 3.0   memory length: 331653   epsilon: 0.7799287000001014    steps: 233     evaluation reward: 3.3\n",
      "episode: 1661   score: 3.0   memory length: 331890   epsilon: 0.7797035500001015    steps: 237     evaluation reward: 3.28\n",
      "episode: 1662   score: 3.0   memory length: 332136   epsilon: 0.7794698500001016    steps: 246     evaluation reward: 3.27\n",
      "episode: 1663   score: 1.0   memory length: 332318   epsilon: 0.7792969500001017    steps: 182     evaluation reward: 3.27\n",
      "episode: 1664   score: 5.0   memory length: 332627   epsilon: 0.7790034000001018    steps: 309     evaluation reward: 3.3\n",
      "episode: 1665   score: 3.0   memory length: 332874   epsilon: 0.7787687500001019    steps: 247     evaluation reward: 3.28\n",
      "episode: 1666   score: 4.0   memory length: 333163   epsilon: 0.778494200000102    steps: 289     evaluation reward: 3.32\n",
      "episode: 1667   score: 3.0   memory length: 333408   epsilon: 0.7782614500001022    steps: 245     evaluation reward: 3.33\n",
      "episode: 1668   score: 2.0   memory length: 333603   epsilon: 0.7780762000001022    steps: 195     evaluation reward: 3.32\n",
      "episode: 1669   score: 6.0   memory length: 333986   epsilon: 0.7777123500001024    steps: 383     evaluation reward: 3.32\n",
      "episode: 1670   score: 2.0   memory length: 334174   epsilon: 0.7775337500001025    steps: 188     evaluation reward: 3.29\n",
      "episode: 1671   score: 4.0   memory length: 334464   epsilon: 0.7772582500001026    steps: 290     evaluation reward: 3.31\n",
      "episode: 1672   score: 2.0   memory length: 334660   epsilon: 0.7770720500001027    steps: 196     evaluation reward: 3.29\n",
      "episode: 1673   score: 4.0   memory length: 334947   epsilon: 0.7767994000001028    steps: 287     evaluation reward: 3.32\n",
      "episode: 1674   score: 3.0   memory length: 335204   epsilon: 0.776555250000103    steps: 257     evaluation reward: 3.32\n",
      "episode: 1675   score: 0.0   memory length: 335327   epsilon: 0.776438400000103    steps: 123     evaluation reward: 3.32\n",
      "episode: 1676   score: 2.0   memory length: 335531   epsilon: 0.7762446000001031    steps: 204     evaluation reward: 3.33\n",
      "episode: 1677   score: 4.0   memory length: 335806   epsilon: 0.7759833500001032    steps: 275     evaluation reward: 3.3\n",
      "episode: 1678   score: 3.0   memory length: 336044   epsilon: 0.7757572500001033    steps: 238     evaluation reward: 3.29\n",
      "episode: 1679   score: 0.0   memory length: 336179   epsilon: 0.7756290000001034    steps: 135     evaluation reward: 3.24\n",
      "episode: 1680   score: 2.0   memory length: 336382   epsilon: 0.7754361500001035    steps: 203     evaluation reward: 3.23\n",
      "episode: 1681   score: 6.0   memory length: 336774   epsilon: 0.7750637500001036    steps: 392     evaluation reward: 3.29\n",
      "episode: 1682   score: 4.0   memory length: 337045   epsilon: 0.7748063000001038    steps: 271     evaluation reward: 3.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1683   score: 3.0   memory length: 337274   epsilon: 0.7745887500001039    steps: 229     evaluation reward: 3.3\n",
      "episode: 1684   score: 2.0   memory length: 337504   epsilon: 0.774370250000104    steps: 230     evaluation reward: 3.3\n",
      "episode: 1685   score: 4.0   memory length: 337781   epsilon: 0.7741071000001041    steps: 277     evaluation reward: 3.31\n",
      "episode: 1686   score: 2.0   memory length: 338007   epsilon: 0.7738924000001042    steps: 226     evaluation reward: 3.29\n",
      "episode: 1687   score: 2.0   memory length: 338192   epsilon: 0.7737166500001043    steps: 185     evaluation reward: 3.3\n",
      "episode: 1688   score: 4.0   memory length: 338474   epsilon: 0.7734487500001044    steps: 282     evaluation reward: 3.29\n",
      "episode: 1689   score: 4.0   memory length: 338749   epsilon: 0.7731875000001045    steps: 275     evaluation reward: 3.3\n",
      "episode: 1690   score: 4.0   memory length: 339016   epsilon: 0.7729338500001046    steps: 267     evaluation reward: 3.3\n",
      "episode: 1691   score: 6.0   memory length: 339376   epsilon: 0.7725918500001048    steps: 360     evaluation reward: 3.34\n",
      "episode: 1692   score: 4.0   memory length: 339665   epsilon: 0.7723173000001049    steps: 289     evaluation reward: 3.36\n",
      "episode: 1693   score: 0.0   memory length: 339801   epsilon: 0.772188100000105    steps: 136     evaluation reward: 3.33\n",
      "episode: 1694   score: 3.0   memory length: 340062   epsilon: 0.7719401500001051    steps: 261     evaluation reward: 3.34\n",
      "episode: 1695   score: 3.0   memory length: 340321   epsilon: 0.7716941000001052    steps: 259     evaluation reward: 3.35\n",
      "episode: 1696   score: 4.0   memory length: 340612   epsilon: 0.7714176500001053    steps: 291     evaluation reward: 3.37\n",
      "episode: 1697   score: 1.0   memory length: 340768   epsilon: 0.7712694500001054    steps: 156     evaluation reward: 3.32\n",
      "episode: 1698   score: 3.0   memory length: 341014   epsilon: 0.7710357500001055    steps: 246     evaluation reward: 3.32\n",
      "episode: 1699   score: 4.0   memory length: 341308   epsilon: 0.7707564500001056    steps: 294     evaluation reward: 3.34\n",
      "episode: 1700   score: 6.0   memory length: 341705   epsilon: 0.7703793000001058    steps: 397     evaluation reward: 3.36\n",
      "episode: 1701   score: 7.0   memory length: 342097   epsilon: 0.770006900000106    steps: 392     evaluation reward: 3.42\n",
      "episode: 1702   score: 5.0   memory length: 342455   epsilon: 0.7696668000001061    steps: 358     evaluation reward: 3.4\n",
      "episode: 1703   score: 8.0   memory length: 342879   epsilon: 0.7692640000001063    steps: 424     evaluation reward: 3.41\n",
      "episode: 1704   score: 12.0   memory length: 343481   epsilon: 0.7686921000001066    steps: 602     evaluation reward: 3.51\n",
      "episode: 1705   score: 0.0   memory length: 343627   epsilon: 0.7685534000001066    steps: 146     evaluation reward: 3.49\n",
      "episode: 1706   score: 3.0   memory length: 343868   epsilon: 0.7683244500001067    steps: 241     evaluation reward: 3.49\n",
      "episode: 1707   score: 3.0   memory length: 344103   epsilon: 0.7681012000001068    steps: 235     evaluation reward: 3.48\n",
      "episode: 1708   score: 1.0   memory length: 344261   epsilon: 0.7679511000001069    steps: 158     evaluation reward: 3.46\n",
      "episode: 1709   score: 2.0   memory length: 344476   epsilon: 0.767746850000107    steps: 215     evaluation reward: 3.4\n",
      "episode: 1710   score: 1.0   memory length: 344651   epsilon: 0.7675806000001071    steps: 175     evaluation reward: 3.4\n",
      "episode: 1711   score: 3.0   memory length: 344878   epsilon: 0.7673649500001072    steps: 227     evaluation reward: 3.39\n",
      "episode: 1712   score: 4.0   memory length: 345158   epsilon: 0.7670989500001073    steps: 280     evaluation reward: 3.37\n",
      "episode: 1713   score: 2.0   memory length: 345380   epsilon: 0.7668880500001074    steps: 222     evaluation reward: 3.38\n",
      "episode: 1714   score: 3.0   memory length: 345639   epsilon: 0.7666420000001075    steps: 259     evaluation reward: 3.38\n",
      "episode: 1715   score: 2.0   memory length: 345840   epsilon: 0.7664510500001076    steps: 201     evaluation reward: 3.38\n",
      "episode: 1716   score: 5.0   memory length: 346165   epsilon: 0.7661423000001077    steps: 325     evaluation reward: 3.41\n",
      "episode: 1717   score: 4.0   memory length: 346456   epsilon: 0.7658658500001079    steps: 291     evaluation reward: 3.31\n",
      "episode: 1718   score: 2.0   memory length: 346655   epsilon: 0.765676800000108    steps: 199     evaluation reward: 3.27\n",
      "episode: 1719   score: 4.0   memory length: 346910   epsilon: 0.7654345500001081    steps: 255     evaluation reward: 3.27\n",
      "episode: 1720   score: 4.0   memory length: 347220   epsilon: 0.7651400500001082    steps: 310     evaluation reward: 3.29\n",
      "episode: 1721   score: 1.0   memory length: 347388   epsilon: 0.7649804500001083    steps: 168     evaluation reward: 3.29\n",
      "episode: 1722   score: 5.0   memory length: 347714   epsilon: 0.7646707500001084    steps: 326     evaluation reward: 3.3\n",
      "episode: 1723   score: 5.0   memory length: 348064   epsilon: 0.7643382500001086    steps: 350     evaluation reward: 3.33\n",
      "episode: 1724   score: 2.0   memory length: 348271   epsilon: 0.7641416000001087    steps: 207     evaluation reward: 3.33\n",
      "episode: 1725   score: 3.0   memory length: 348509   epsilon: 0.7639155000001088    steps: 238     evaluation reward: 3.33\n",
      "episode: 1726   score: 3.0   memory length: 348742   epsilon: 0.7636941500001089    steps: 233     evaluation reward: 3.34\n",
      "episode: 1727   score: 0.0   memory length: 348870   epsilon: 0.7635725500001089    steps: 128     evaluation reward: 3.28\n",
      "episode: 1728   score: 4.0   memory length: 349140   epsilon: 0.763316050000109    steps: 270     evaluation reward: 3.32\n",
      "episode: 1729   score: 2.0   memory length: 349339   epsilon: 0.7631270000001091    steps: 199     evaluation reward: 3.31\n",
      "episode: 1730   score: 5.0   memory length: 349659   epsilon: 0.7628230000001093    steps: 320     evaluation reward: 3.35\n",
      "episode: 1731   score: 3.0   memory length: 349898   epsilon: 0.7625959500001094    steps: 239     evaluation reward: 3.33\n",
      "now time :  2018-12-14 08:58:45.135147\n",
      "episode: 1732   score: 2.0   memory length: 350093   epsilon: 0.7624107000001095    steps: 195     evaluation reward: 3.29\n",
      "episode: 1733   score: 9.0   memory length: 350613   epsilon: 0.7619167000001097    steps: 520     evaluation reward: 3.34\n",
      "episode: 1734   score: 1.0   memory length: 350795   epsilon: 0.7617438000001098    steps: 182     evaluation reward: 3.33\n",
      "episode: 1735   score: 3.0   memory length: 351018   epsilon: 0.7615319500001099    steps: 223     evaluation reward: 3.33\n",
      "episode: 1736   score: 4.0   memory length: 351296   epsilon: 0.76126785000011    steps: 278     evaluation reward: 3.28\n",
      "episode: 1737   score: 7.0   memory length: 351718   epsilon: 0.7608669500001102    steps: 422     evaluation reward: 3.31\n",
      "episode: 1738   score: 3.0   memory length: 351936   epsilon: 0.7606598500001103    steps: 218     evaluation reward: 3.31\n",
      "episode: 1739   score: 1.0   memory length: 352115   epsilon: 0.7604898000001103    steps: 179     evaluation reward: 3.24\n",
      "episode: 1740   score: 4.0   memory length: 352404   epsilon: 0.7602152500001105    steps: 289     evaluation reward: 3.28\n",
      "episode: 1741   score: 3.0   memory length: 352643   epsilon: 0.7599882000001106    steps: 239     evaluation reward: 3.29\n",
      "episode: 1742   score: 3.0   memory length: 352902   epsilon: 0.7597421500001107    steps: 259     evaluation reward: 3.31\n",
      "episode: 1743   score: 1.0   memory length: 353055   epsilon: 0.7595968000001108    steps: 153     evaluation reward: 3.3\n",
      "episode: 1744   score: 5.0   memory length: 353371   epsilon: 0.7592966000001109    steps: 316     evaluation reward: 3.28\n",
      "episode: 1745   score: 4.0   memory length: 353635   epsilon: 0.759045800000111    steps: 264     evaluation reward: 3.31\n",
      "episode: 1746   score: 1.0   memory length: 353791   epsilon: 0.7588976000001111    steps: 156     evaluation reward: 3.28\n",
      "episode: 1747   score: 3.0   memory length: 354041   epsilon: 0.7586601000001112    steps: 250     evaluation reward: 3.23\n",
      "episode: 1748   score: 2.0   memory length: 354223   epsilon: 0.7584872000001113    steps: 182     evaluation reward: 3.21\n",
      "episode: 1749   score: 14.0   memory length: 354590   epsilon: 0.7581385500001114    steps: 367     evaluation reward: 3.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1750   score: 1.0   memory length: 354747   epsilon: 0.7579894000001115    steps: 157     evaluation reward: 3.29\n",
      "episode: 1751   score: 3.0   memory length: 354983   epsilon: 0.7577652000001116    steps: 236     evaluation reward: 3.32\n",
      "episode: 1752   score: 6.0   memory length: 355361   epsilon: 0.7574061000001118    steps: 378     evaluation reward: 3.37\n",
      "episode: 1753   score: 1.0   memory length: 355529   epsilon: 0.7572465000001118    steps: 168     evaluation reward: 3.35\n",
      "episode: 1754   score: 5.0   memory length: 355846   epsilon: 0.756945350000112    steps: 317     evaluation reward: 3.38\n",
      "episode: 1755   score: 5.0   memory length: 356175   epsilon: 0.7566328000001121    steps: 329     evaluation reward: 3.4\n",
      "episode: 1756   score: 2.0   memory length: 356381   epsilon: 0.7564371000001122    steps: 206     evaluation reward: 3.38\n",
      "episode: 1757   score: 6.0   memory length: 356749   epsilon: 0.7560875000001124    steps: 368     evaluation reward: 3.41\n",
      "episode: 1758   score: 0.0   memory length: 356876   epsilon: 0.7559668500001124    steps: 127     evaluation reward: 3.39\n",
      "episode: 1759   score: 5.0   memory length: 357179   epsilon: 0.7556790000001126    steps: 303     evaluation reward: 3.4\n",
      "episode: 1760   score: 4.0   memory length: 357431   epsilon: 0.7554396000001127    steps: 252     evaluation reward: 3.41\n",
      "episode: 1761   score: 4.0   memory length: 357707   epsilon: 0.7551774000001128    steps: 276     evaluation reward: 3.42\n",
      "episode: 1762   score: 5.0   memory length: 358067   epsilon: 0.754835400000113    steps: 360     evaluation reward: 3.44\n",
      "episode: 1763   score: 3.0   memory length: 358345   epsilon: 0.7545713000001131    steps: 278     evaluation reward: 3.46\n",
      "episode: 1764   score: 4.0   memory length: 358630   epsilon: 0.7543005500001132    steps: 285     evaluation reward: 3.45\n",
      "episode: 1765   score: 2.0   memory length: 358835   epsilon: 0.7541058000001133    steps: 205     evaluation reward: 3.44\n",
      "episode: 1766   score: 3.0   memory length: 359067   epsilon: 0.7538854000001134    steps: 232     evaluation reward: 3.43\n",
      "episode: 1767   score: 4.0   memory length: 359326   epsilon: 0.7536393500001135    steps: 259     evaluation reward: 3.44\n",
      "episode: 1768   score: 4.0   memory length: 359580   epsilon: 0.7533980500001136    steps: 254     evaluation reward: 3.46\n",
      "episode: 1769   score: 2.0   memory length: 359780   epsilon: 0.7532080500001137    steps: 200     evaluation reward: 3.42\n",
      "episode: 1770   score: 6.0   memory length: 360130   epsilon: 0.7528755500001139    steps: 350     evaluation reward: 3.46\n",
      "episode: 1771   score: 1.0   memory length: 360295   epsilon: 0.7527188000001139    steps: 165     evaluation reward: 3.43\n",
      "episode: 1772   score: 5.0   memory length: 360662   epsilon: 0.7523701500001141    steps: 367     evaluation reward: 3.46\n",
      "episode: 1773   score: 1.0   memory length: 360830   epsilon: 0.7522105500001142    steps: 168     evaluation reward: 3.43\n",
      "episode: 1774   score: 2.0   memory length: 361040   epsilon: 0.7520110500001143    steps: 210     evaluation reward: 3.42\n",
      "episode: 1775   score: 3.0   memory length: 361258   epsilon: 0.7518039500001144    steps: 218     evaluation reward: 3.45\n",
      "episode: 1776   score: 6.0   memory length: 361592   epsilon: 0.7514866500001145    steps: 334     evaluation reward: 3.49\n",
      "episode: 1777   score: 6.0   memory length: 361952   epsilon: 0.7511446500001147    steps: 360     evaluation reward: 3.51\n",
      "episode: 1778   score: 3.0   memory length: 362205   epsilon: 0.7509043000001148    steps: 253     evaluation reward: 3.51\n",
      "episode: 1779   score: 6.0   memory length: 362551   epsilon: 0.7505756000001149    steps: 346     evaluation reward: 3.57\n",
      "episode: 1780   score: 4.0   memory length: 362857   epsilon: 0.750284900000115    steps: 306     evaluation reward: 3.59\n",
      "episode: 1781   score: 0.0   memory length: 362984   epsilon: 0.7501642500001151    steps: 127     evaluation reward: 3.53\n",
      "episode: 1782   score: 1.0   memory length: 363159   epsilon: 0.7499980000001152    steps: 175     evaluation reward: 3.5\n",
      "episode: 1783   score: 6.0   memory length: 363482   epsilon: 0.7496911500001153    steps: 323     evaluation reward: 3.53\n",
      "episode: 1784   score: 4.0   memory length: 363782   epsilon: 0.7494061500001155    steps: 300     evaluation reward: 3.55\n",
      "episode: 1785   score: 5.0   memory length: 364071   epsilon: 0.7491316000001156    steps: 289     evaluation reward: 3.56\n",
      "episode: 1786   score: 6.0   memory length: 364434   epsilon: 0.7487867500001157    steps: 363     evaluation reward: 3.6\n",
      "episode: 1787   score: 5.0   memory length: 364735   epsilon: 0.7485008000001159    steps: 301     evaluation reward: 3.63\n",
      "episode: 1788   score: 3.0   memory length: 364972   epsilon: 0.748275650000116    steps: 237     evaluation reward: 3.62\n",
      "episode: 1789   score: 12.0   memory length: 365299   epsilon: 0.7479650000001161    steps: 327     evaluation reward: 3.7\n",
      "episode: 1790   score: 4.0   memory length: 365556   epsilon: 0.7477208500001162    steps: 257     evaluation reward: 3.7\n",
      "episode: 1791   score: 9.0   memory length: 366074   epsilon: 0.7472287500001165    steps: 518     evaluation reward: 3.73\n",
      "episode: 1792   score: 4.0   memory length: 366344   epsilon: 0.7469722500001166    steps: 270     evaluation reward: 3.73\n",
      "episode: 1793   score: 2.0   memory length: 366571   epsilon: 0.7467566000001167    steps: 227     evaluation reward: 3.75\n",
      "episode: 1794   score: 1.0   memory length: 366732   epsilon: 0.7466036500001167    steps: 161     evaluation reward: 3.73\n",
      "episode: 1795   score: 9.0   memory length: 367202   epsilon: 0.746157150000117    steps: 470     evaluation reward: 3.79\n",
      "episode: 1796   score: 7.0   memory length: 367561   epsilon: 0.7458161000001171    steps: 359     evaluation reward: 3.82\n",
      "episode: 1797   score: 10.0   memory length: 367949   epsilon: 0.7454475000001173    steps: 388     evaluation reward: 3.91\n",
      "episode: 1798   score: 6.0   memory length: 368328   epsilon: 0.7450874500001174    steps: 379     evaluation reward: 3.94\n",
      "episode: 1799   score: 6.0   memory length: 368677   epsilon: 0.7447559000001176    steps: 349     evaluation reward: 3.96\n",
      "episode: 1800   score: 4.0   memory length: 368928   epsilon: 0.7445174500001177    steps: 251     evaluation reward: 3.94\n",
      "episode: 1801   score: 5.0   memory length: 369251   epsilon: 0.7442106000001179    steps: 323     evaluation reward: 3.92\n",
      "episode: 1802   score: 1.0   memory length: 369422   epsilon: 0.7440481500001179    steps: 171     evaluation reward: 3.88\n",
      "episode: 1803   score: 7.0   memory length: 369835   epsilon: 0.7436558000001181    steps: 413     evaluation reward: 3.87\n",
      "episode: 1804   score: 3.0   memory length: 370085   epsilon: 0.7434183000001182    steps: 250     evaluation reward: 3.78\n",
      "episode: 1805   score: 4.0   memory length: 370370   epsilon: 0.7431475500001183    steps: 285     evaluation reward: 3.82\n",
      "episode: 1806   score: 4.0   memory length: 370638   epsilon: 0.7428929500001185    steps: 268     evaluation reward: 3.83\n",
      "episode: 1807   score: 9.0   memory length: 370978   epsilon: 0.7425699500001186    steps: 340     evaluation reward: 3.89\n",
      "episode: 1808   score: 6.0   memory length: 371326   epsilon: 0.7422393500001188    steps: 348     evaluation reward: 3.94\n",
      "episode: 1809   score: 4.0   memory length: 371590   epsilon: 0.7419885500001189    steps: 264     evaluation reward: 3.96\n",
      "episode: 1810   score: 5.0   memory length: 371937   epsilon: 0.741658900000119    steps: 347     evaluation reward: 4.0\n",
      "episode: 1811   score: 5.0   memory length: 372265   epsilon: 0.7413473000001192    steps: 328     evaluation reward: 4.02\n",
      "episode: 1812   score: 3.0   memory length: 372518   epsilon: 0.7411069500001193    steps: 253     evaluation reward: 4.01\n",
      "episode: 1813   score: 2.0   memory length: 372706   epsilon: 0.7409283500001194    steps: 188     evaluation reward: 4.01\n",
      "episode: 1814   score: 4.0   memory length: 372956   epsilon: 0.7406908500001195    steps: 250     evaluation reward: 4.02\n",
      "episode: 1815   score: 4.0   memory length: 373259   epsilon: 0.7404030000001196    steps: 303     evaluation reward: 4.04\n",
      "episode: 1816   score: 1.0   memory length: 373418   epsilon: 0.7402519500001197    steps: 159     evaluation reward: 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1817   score: 1.0   memory length: 373579   epsilon: 0.7400990000001197    steps: 161     evaluation reward: 3.97\n",
      "episode: 1818   score: 1.0   memory length: 373742   epsilon: 0.7399441500001198    steps: 163     evaluation reward: 3.96\n",
      "episode: 1819   score: 2.0   memory length: 373980   epsilon: 0.7397180500001199    steps: 238     evaluation reward: 3.94\n",
      "episode: 1820   score: 4.0   memory length: 374247   epsilon: 0.73946440000012    steps: 267     evaluation reward: 3.94\n",
      "episode: 1821   score: 2.0   memory length: 374442   epsilon: 0.7392791500001201    steps: 195     evaluation reward: 3.95\n",
      "episode: 1822   score: 4.0   memory length: 374742   epsilon: 0.7389941500001203    steps: 300     evaluation reward: 3.94\n",
      "episode: 1823   score: 6.0   memory length: 375083   epsilon: 0.7386702000001204    steps: 341     evaluation reward: 3.95\n",
      "episode: 1824   score: 6.0   memory length: 375426   epsilon: 0.7383443500001206    steps: 343     evaluation reward: 3.99\n",
      "episode: 1825   score: 6.0   memory length: 375771   epsilon: 0.7380166000001207    steps: 345     evaluation reward: 4.02\n",
      "episode: 1826   score: 3.0   memory length: 376000   epsilon: 0.7377990500001208    steps: 229     evaluation reward: 4.02\n",
      "episode: 1827   score: 2.0   memory length: 376211   epsilon: 0.7375986000001209    steps: 211     evaluation reward: 4.04\n",
      "episode: 1828   score: 2.0   memory length: 376423   epsilon: 0.737397200000121    steps: 212     evaluation reward: 4.02\n",
      "episode: 1829   score: 7.0   memory length: 376849   epsilon: 0.7369925000001212    steps: 426     evaluation reward: 4.07\n",
      "episode: 1830   score: 7.0   memory length: 377243   epsilon: 0.7366182000001213    steps: 394     evaluation reward: 4.09\n",
      "episode: 1831   score: 12.0   memory length: 377548   epsilon: 0.7363284500001215    steps: 305     evaluation reward: 4.18\n",
      "episode: 1832   score: 7.0   memory length: 377926   epsilon: 0.7359693500001216    steps: 378     evaluation reward: 4.23\n",
      "episode: 1833   score: 3.0   memory length: 378179   epsilon: 0.7357290000001218    steps: 253     evaluation reward: 4.17\n",
      "episode: 1834   score: 2.0   memory length: 378382   epsilon: 0.7355361500001218    steps: 203     evaluation reward: 4.18\n",
      "episode: 1835   score: 3.0   memory length: 378631   epsilon: 0.735299600000122    steps: 249     evaluation reward: 4.18\n",
      "episode: 1836   score: 2.0   memory length: 378840   epsilon: 0.735101050000122    steps: 209     evaluation reward: 4.16\n",
      "episode: 1837   score: 9.0   memory length: 379275   epsilon: 0.7346878000001222    steps: 435     evaluation reward: 4.18\n",
      "episode: 1838   score: 4.0   memory length: 379558   epsilon: 0.7344189500001224    steps: 283     evaluation reward: 4.19\n",
      "episode: 1839   score: 5.0   memory length: 379899   epsilon: 0.7340950000001225    steps: 341     evaluation reward: 4.23\n",
      "episode: 1840   score: 7.0   memory length: 380314   epsilon: 0.7337007500001227    steps: 415     evaluation reward: 4.26\n",
      "episode: 1841   score: 5.0   memory length: 380629   epsilon: 0.7334015000001228    steps: 315     evaluation reward: 4.28\n",
      "episode: 1842   score: 1.0   memory length: 380802   epsilon: 0.7332371500001229    steps: 173     evaluation reward: 4.26\n",
      "episode: 1843   score: 6.0   memory length: 381159   epsilon: 0.7328980000001231    steps: 357     evaluation reward: 4.31\n",
      "episode: 1844   score: 7.0   memory length: 381410   epsilon: 0.7326595500001232    steps: 251     evaluation reward: 4.33\n",
      "episode: 1845   score: 7.0   memory length: 381804   epsilon: 0.7322852500001233    steps: 394     evaluation reward: 4.36\n",
      "episode: 1846   score: 6.0   memory length: 382145   epsilon: 0.7319613000001235    steps: 341     evaluation reward: 4.41\n",
      "episode: 1847   score: 4.0   memory length: 382433   epsilon: 0.7316877000001236    steps: 288     evaluation reward: 4.42\n",
      "episode: 1848   score: 4.0   memory length: 382727   epsilon: 0.7314084000001237    steps: 294     evaluation reward: 4.44\n",
      "episode: 1849   score: 10.0   memory length: 383083   epsilon: 0.7310702000001239    steps: 356     evaluation reward: 4.4\n",
      "episode: 1850   score: 6.0   memory length: 383447   epsilon: 0.7307244000001241    steps: 364     evaluation reward: 4.45\n",
      "episode: 1851   score: 8.0   memory length: 383837   epsilon: 0.7303539000001242    steps: 390     evaluation reward: 4.5\n",
      "episode: 1852   score: 2.0   memory length: 384026   epsilon: 0.7301743500001243    steps: 189     evaluation reward: 4.46\n",
      "episode: 1853   score: 2.0   memory length: 384234   epsilon: 0.7299767500001244    steps: 208     evaluation reward: 4.47\n",
      "episode: 1854   score: 4.0   memory length: 384521   epsilon: 0.7297041000001245    steps: 287     evaluation reward: 4.46\n",
      "episode: 1855   score: 2.0   memory length: 384744   epsilon: 0.7294922500001246    steps: 223     evaluation reward: 4.43\n",
      "episode: 1856   score: 4.0   memory length: 385041   epsilon: 0.7292101000001248    steps: 297     evaluation reward: 4.45\n",
      "episode: 1857   score: 2.0   memory length: 385236   epsilon: 0.7290248500001248    steps: 195     evaluation reward: 4.41\n",
      "episode: 1858   score: 6.0   memory length: 385573   epsilon: 0.728704700000125    steps: 337     evaluation reward: 4.47\n",
      "episode: 1859   score: 3.0   memory length: 385808   epsilon: 0.7284814500001251    steps: 235     evaluation reward: 4.45\n",
      "episode: 1860   score: 4.0   memory length: 386093   epsilon: 0.7282107000001252    steps: 285     evaluation reward: 4.45\n",
      "episode: 1861   score: 2.0   memory length: 386282   epsilon: 0.7280311500001253    steps: 189     evaluation reward: 4.43\n",
      "episode: 1862   score: 2.0   memory length: 386465   epsilon: 0.7278573000001254    steps: 183     evaluation reward: 4.4\n",
      "episode: 1863   score: 2.0   memory length: 386678   epsilon: 0.7276549500001255    steps: 213     evaluation reward: 4.39\n",
      "episode: 1864   score: 6.0   memory length: 387056   epsilon: 0.7272958500001256    steps: 378     evaluation reward: 4.41\n",
      "episode: 1865   score: 7.0   memory length: 387466   epsilon: 0.7269063500001258    steps: 410     evaluation reward: 4.46\n",
      "episode: 1866   score: 5.0   memory length: 387824   epsilon: 0.726566250000126    steps: 358     evaluation reward: 4.48\n",
      "episode: 1867   score: 6.0   memory length: 388203   epsilon: 0.7262062000001261    steps: 379     evaluation reward: 4.5\n",
      "episode: 1868   score: 3.0   memory length: 388426   epsilon: 0.7259943500001262    steps: 223     evaluation reward: 4.49\n",
      "episode: 1869   score: 1.0   memory length: 388595   epsilon: 0.7258338000001263    steps: 169     evaluation reward: 4.48\n",
      "episode: 1870   score: 7.0   memory length: 389018   epsilon: 0.7254319500001265    steps: 423     evaluation reward: 4.49\n",
      "episode: 1871   score: 5.0   memory length: 389306   epsilon: 0.7251583500001266    steps: 288     evaluation reward: 4.53\n",
      "episode: 1872   score: 4.0   memory length: 389561   epsilon: 0.7249161000001267    steps: 255     evaluation reward: 4.52\n",
      "episode: 1873   score: 5.0   memory length: 389889   epsilon: 0.7246045000001269    steps: 328     evaluation reward: 4.56\n",
      "episode: 1874   score: 3.0   memory length: 390154   epsilon: 0.724352750000127    steps: 265     evaluation reward: 4.57\n",
      "episode: 1875   score: 5.0   memory length: 390453   epsilon: 0.7240687000001271    steps: 299     evaluation reward: 4.59\n",
      "episode: 1876   score: 2.0   memory length: 390662   epsilon: 0.7238701500001272    steps: 209     evaluation reward: 4.55\n",
      "episode: 1877   score: 4.0   memory length: 390967   epsilon: 0.7235804000001274    steps: 305     evaluation reward: 4.53\n",
      "episode: 1878   score: 2.0   memory length: 391163   epsilon: 0.7233942000001274    steps: 196     evaluation reward: 4.52\n",
      "episode: 1879   score: 6.0   memory length: 391511   epsilon: 0.7230636000001276    steps: 348     evaluation reward: 4.52\n",
      "episode: 1880   score: 1.0   memory length: 391674   epsilon: 0.7229087500001277    steps: 163     evaluation reward: 4.49\n",
      "episode: 1881   score: 8.0   memory length: 392122   epsilon: 0.7224831500001279    steps: 448     evaluation reward: 4.57\n",
      "episode: 1882   score: 15.0   memory length: 392672   epsilon: 0.7219606500001281    steps: 550     evaluation reward: 4.71\n",
      "episode: 1883   score: 7.0   memory length: 393069   epsilon: 0.7215835000001283    steps: 397     evaluation reward: 4.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1884   score: 6.0   memory length: 393437   epsilon: 0.7212339000001284    steps: 368     evaluation reward: 4.74\n",
      "episode: 1885   score: 5.0   memory length: 393731   epsilon: 0.7209546000001286    steps: 294     evaluation reward: 4.74\n",
      "episode: 1886   score: 1.0   memory length: 393883   epsilon: 0.7208102000001286    steps: 152     evaluation reward: 4.69\n",
      "episode: 1887   score: 1.0   memory length: 394071   epsilon: 0.7206316000001287    steps: 188     evaluation reward: 4.65\n",
      "episode: 1888   score: 1.0   memory length: 394229   epsilon: 0.7204815000001288    steps: 158     evaluation reward: 4.63\n",
      "episode: 1889   score: 5.0   memory length: 394583   epsilon: 0.7201452000001289    steps: 354     evaluation reward: 4.56\n",
      "episode: 1890   score: 5.0   memory length: 394922   epsilon: 0.7198231500001291    steps: 339     evaluation reward: 4.57\n",
      "episode: 1891   score: 4.0   memory length: 395187   epsilon: 0.7195714000001292    steps: 265     evaluation reward: 4.52\n",
      "episode: 1892   score: 7.0   memory length: 395578   epsilon: 0.7191999500001294    steps: 391     evaluation reward: 4.55\n",
      "episode: 1893   score: 7.0   memory length: 395833   epsilon: 0.7189577000001295    steps: 255     evaluation reward: 4.6\n",
      "episode: 1894   score: 1.0   memory length: 395999   epsilon: 0.7188000000001296    steps: 166     evaluation reward: 4.6\n",
      "episode: 1895   score: 4.0   memory length: 396276   epsilon: 0.7185368500001297    steps: 277     evaluation reward: 4.55\n",
      "episode: 1896   score: 3.0   memory length: 396521   epsilon: 0.7183041000001298    steps: 245     evaluation reward: 4.51\n",
      "episode: 1897   score: 4.0   memory length: 396811   epsilon: 0.7180286000001299    steps: 290     evaluation reward: 4.45\n",
      "episode: 1898   score: 7.0   memory length: 397196   epsilon: 0.7176628500001301    steps: 385     evaluation reward: 4.46\n",
      "episode: 1899   score: 5.0   memory length: 397504   epsilon: 0.7173702500001302    steps: 308     evaluation reward: 4.45\n",
      "episode: 1900   score: 7.0   memory length: 397918   epsilon: 0.7169769500001304    steps: 414     evaluation reward: 4.48\n",
      "episode: 1901   score: 7.0   memory length: 398313   epsilon: 0.7166017000001306    steps: 395     evaluation reward: 4.5\n",
      "episode: 1902   score: 6.0   memory length: 398657   epsilon: 0.7162749000001307    steps: 344     evaluation reward: 4.55\n",
      "episode: 1903   score: 13.0   memory length: 399122   epsilon: 0.7158331500001309    steps: 465     evaluation reward: 4.61\n",
      "episode: 1904   score: 2.0   memory length: 399308   epsilon: 0.715656450000131    steps: 186     evaluation reward: 4.6\n",
      "episode: 1905   score: 6.0   memory length: 399687   epsilon: 0.7152964000001312    steps: 379     evaluation reward: 4.62\n",
      "now time :  2018-12-14 09:15:47.744985\n",
      "episode: 1906   score: 6.0   memory length: 400077   epsilon: 0.7149259000001313    steps: 390     evaluation reward: 4.64\n",
      "episode: 1907   score: 5.0   memory length: 400417   epsilon: 0.7146029000001315    steps: 340     evaluation reward: 4.6\n",
      "episode: 1908   score: 2.0   memory length: 400627   epsilon: 0.7144034000001316    steps: 210     evaluation reward: 4.56\n",
      "episode: 1909   score: 22.0   memory length: 401310   epsilon: 0.7137545500001319    steps: 683     evaluation reward: 4.74\n",
      "episode: 1910   score: 4.0   memory length: 401558   epsilon: 0.713518950000132    steps: 248     evaluation reward: 4.73\n",
      "episode: 1911   score: 6.0   memory length: 401919   epsilon: 0.7131760000001321    steps: 361     evaluation reward: 4.74\n",
      "episode: 1912   score: 11.0   memory length: 402333   epsilon: 0.7127827000001323    steps: 414     evaluation reward: 4.82\n",
      "episode: 1913   score: 5.0   memory length: 402661   epsilon: 0.7124711000001325    steps: 328     evaluation reward: 4.85\n",
      "episode: 1914   score: 4.0   memory length: 402920   epsilon: 0.7122250500001326    steps: 259     evaluation reward: 4.85\n",
      "episode: 1915   score: 4.0   memory length: 403180   epsilon: 0.7119780500001327    steps: 260     evaluation reward: 4.85\n",
      "episode: 1916   score: 4.0   memory length: 403479   epsilon: 0.7116940000001328    steps: 299     evaluation reward: 4.88\n",
      "episode: 1917   score: 2.0   memory length: 403687   epsilon: 0.7114964000001329    steps: 208     evaluation reward: 4.89\n",
      "episode: 1918   score: 4.0   memory length: 403973   epsilon: 0.711224700000133    steps: 286     evaluation reward: 4.92\n",
      "episode: 1919   score: 6.0   memory length: 404366   epsilon: 0.7108513500001332    steps: 393     evaluation reward: 4.96\n",
      "episode: 1920   score: 5.0   memory length: 404678   epsilon: 0.7105549500001334    steps: 312     evaluation reward: 4.97\n",
      "episode: 1921   score: 3.0   memory length: 404904   epsilon: 0.7103402500001335    steps: 226     evaluation reward: 4.98\n",
      "episode: 1922   score: 2.0   memory length: 405121   epsilon: 0.7101341000001336    steps: 217     evaluation reward: 4.96\n",
      "episode: 1923   score: 9.0   memory length: 405576   epsilon: 0.7097018500001337    steps: 455     evaluation reward: 4.99\n",
      "episode: 1924   score: 6.0   memory length: 405925   epsilon: 0.7093703000001339    steps: 349     evaluation reward: 4.99\n",
      "episode: 1925   score: 2.0   memory length: 406135   epsilon: 0.709170800000134    steps: 210     evaluation reward: 4.95\n",
      "episode: 1926   score: 3.0   memory length: 406368   epsilon: 0.7089494500001341    steps: 233     evaluation reward: 4.95\n",
      "episode: 1927   score: 4.0   memory length: 406630   epsilon: 0.7087005500001342    steps: 262     evaluation reward: 4.97\n",
      "episode: 1928   score: 4.0   memory length: 406930   epsilon: 0.7084155500001343    steps: 300     evaluation reward: 4.99\n",
      "episode: 1929   score: 6.0   memory length: 407303   epsilon: 0.7080612000001345    steps: 373     evaluation reward: 4.98\n",
      "episode: 1930   score: 2.0   memory length: 407486   epsilon: 0.7078873500001346    steps: 183     evaluation reward: 4.93\n",
      "episode: 1931   score: 2.0   memory length: 407669   epsilon: 0.7077135000001347    steps: 183     evaluation reward: 4.83\n",
      "episode: 1932   score: 8.0   memory length: 408116   epsilon: 0.7072888500001349    steps: 447     evaluation reward: 4.84\n",
      "episode: 1933   score: 4.0   memory length: 408387   epsilon: 0.707031400000135    steps: 271     evaluation reward: 4.85\n",
      "episode: 1934   score: 8.0   memory length: 408811   epsilon: 0.7066286000001352    steps: 424     evaluation reward: 4.91\n",
      "episode: 1935   score: 8.0   memory length: 409099   epsilon: 0.7063550000001353    steps: 288     evaluation reward: 4.96\n",
      "episode: 1936   score: 2.0   memory length: 409305   epsilon: 0.7061593000001354    steps: 206     evaluation reward: 4.96\n",
      "episode: 1937   score: 5.0   memory length: 409636   epsilon: 0.7058448500001355    steps: 331     evaluation reward: 4.92\n",
      "episode: 1938   score: 5.0   memory length: 409956   epsilon: 0.7055408500001357    steps: 320     evaluation reward: 4.93\n",
      "episode: 1939   score: 14.0   memory length: 410585   epsilon: 0.7049433000001359    steps: 629     evaluation reward: 5.02\n",
      "episode: 1940   score: 3.0   memory length: 410822   epsilon: 0.704718150000136    steps: 237     evaluation reward: 4.98\n",
      "episode: 1941   score: 9.0   memory length: 411163   epsilon: 0.7043942000001362    steps: 341     evaluation reward: 5.02\n",
      "episode: 1942   score: 7.0   memory length: 411558   epsilon: 0.7040189500001364    steps: 395     evaluation reward: 5.08\n",
      "episode: 1943   score: 5.0   memory length: 411869   epsilon: 0.7037235000001365    steps: 311     evaluation reward: 5.07\n",
      "episode: 1944   score: 5.0   memory length: 412188   epsilon: 0.7034204500001366    steps: 319     evaluation reward: 5.05\n",
      "episode: 1945   score: 5.0   memory length: 412504   epsilon: 0.7031202500001368    steps: 316     evaluation reward: 5.03\n",
      "episode: 1946   score: 5.0   memory length: 412829   epsilon: 0.7028115000001369    steps: 325     evaluation reward: 5.02\n",
      "episode: 1947   score: 6.0   memory length: 413154   epsilon: 0.7025027500001371    steps: 325     evaluation reward: 5.04\n",
      "episode: 1948   score: 10.0   memory length: 413692   epsilon: 0.7019916500001373    steps: 538     evaluation reward: 5.1\n",
      "episode: 1949   score: 3.0   memory length: 413919   epsilon: 0.7017760000001374    steps: 227     evaluation reward: 5.03\n",
      "episode: 1950   score: 5.0   memory length: 414217   epsilon: 0.7014929000001375    steps: 298     evaluation reward: 5.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1951   score: 3.0   memory length: 414446   epsilon: 0.7012753500001376    steps: 229     evaluation reward: 4.97\n",
      "episode: 1952   score: 6.0   memory length: 414791   epsilon: 0.7009476000001378    steps: 345     evaluation reward: 5.01\n",
      "episode: 1953   score: 8.0   memory length: 415219   epsilon: 0.700541000000138    steps: 428     evaluation reward: 5.07\n",
      "episode: 1954   score: 4.0   memory length: 415487   epsilon: 0.7002864000001381    steps: 268     evaluation reward: 5.07\n",
      "episode: 1955   score: 6.0   memory length: 415843   epsilon: 0.6999482000001382    steps: 356     evaluation reward: 5.11\n",
      "episode: 1956   score: 4.0   memory length: 416139   epsilon: 0.6996670000001384    steps: 296     evaluation reward: 5.11\n",
      "episode: 1957   score: 6.0   memory length: 416496   epsilon: 0.6993278500001385    steps: 357     evaluation reward: 5.15\n",
      "episode: 1958   score: 5.0   memory length: 416817   epsilon: 0.6990229000001387    steps: 321     evaluation reward: 5.14\n",
      "episode: 1959   score: 2.0   memory length: 417037   epsilon: 0.6988139000001388    steps: 220     evaluation reward: 5.13\n",
      "episode: 1960   score: 11.0   memory length: 417479   epsilon: 0.698394000000139    steps: 442     evaluation reward: 5.2\n",
      "episode: 1961   score: 4.0   memory length: 417792   epsilon: 0.6980966500001391    steps: 313     evaluation reward: 5.22\n",
      "episode: 1962   score: 8.0   memory length: 418218   epsilon: 0.6976919500001393    steps: 426     evaluation reward: 5.28\n",
      "episode: 1963   score: 2.0   memory length: 418412   epsilon: 0.6975076500001394    steps: 194     evaluation reward: 5.28\n",
      "episode: 1964   score: 5.0   memory length: 418707   epsilon: 0.6972274000001395    steps: 295     evaluation reward: 5.27\n",
      "episode: 1965   score: 8.0   memory length: 419165   epsilon: 0.6967923000001397    steps: 458     evaluation reward: 5.28\n",
      "episode: 1966   score: 8.0   memory length: 419464   epsilon: 0.6965082500001398    steps: 299     evaluation reward: 5.31\n",
      "episode: 1967   score: 2.0   memory length: 419725   epsilon: 0.6962603000001399    steps: 261     evaluation reward: 5.27\n",
      "episode: 1968   score: 3.0   memory length: 419956   epsilon: 0.69604085000014    steps: 231     evaluation reward: 5.27\n",
      "episode: 1969   score: 4.0   memory length: 420230   epsilon: 0.6957805500001402    steps: 274     evaluation reward: 5.3\n",
      "episode: 1970   score: 5.0   memory length: 420569   epsilon: 0.6954585000001403    steps: 339     evaluation reward: 5.28\n",
      "episode: 1971   score: 4.0   memory length: 420879   epsilon: 0.6951640000001404    steps: 310     evaluation reward: 5.27\n",
      "episode: 1972   score: 9.0   memory length: 421213   epsilon: 0.6948467000001406    steps: 334     evaluation reward: 5.32\n",
      "episode: 1973   score: 6.0   memory length: 421598   epsilon: 0.6944809500001408    steps: 385     evaluation reward: 5.33\n",
      "episode: 1974   score: 4.0   memory length: 421883   epsilon: 0.6942102000001409    steps: 285     evaluation reward: 5.34\n",
      "episode: 1975   score: 1.0   memory length: 422061   epsilon: 0.694041100000141    steps: 178     evaluation reward: 5.3\n",
      "episode: 1976   score: 3.0   memory length: 422341   epsilon: 0.6937751000001411    steps: 280     evaluation reward: 5.31\n",
      "episode: 1977   score: 6.0   memory length: 422705   epsilon: 0.6934293000001412    steps: 364     evaluation reward: 5.33\n",
      "episode: 1978   score: 2.0   memory length: 422897   epsilon: 0.6932469000001413    steps: 192     evaluation reward: 5.33\n",
      "episode: 1979   score: 4.0   memory length: 423162   epsilon: 0.6929951500001414    steps: 265     evaluation reward: 5.31\n",
      "episode: 1980   score: 5.0   memory length: 423500   epsilon: 0.6926740500001416    steps: 338     evaluation reward: 5.35\n",
      "episode: 1981   score: 5.0   memory length: 423840   epsilon: 0.6923510500001417    steps: 340     evaluation reward: 5.32\n",
      "episode: 1982   score: 9.0   memory length: 424300   epsilon: 0.691914050000142    steps: 460     evaluation reward: 5.26\n",
      "episode: 1983   score: 3.0   memory length: 424575   epsilon: 0.6916528000001421    steps: 275     evaluation reward: 5.22\n",
      "episode: 1984   score: 4.0   memory length: 424880   epsilon: 0.6913630500001422    steps: 305     evaluation reward: 5.2\n",
      "episode: 1985   score: 4.0   memory length: 425183   epsilon: 0.6910752000001423    steps: 303     evaluation reward: 5.19\n",
      "episode: 1986   score: 7.0   memory length: 425561   epsilon: 0.6907161000001425    steps: 378     evaluation reward: 5.25\n",
      "episode: 1987   score: 3.0   memory length: 425804   epsilon: 0.6904852500001426    steps: 243     evaluation reward: 5.27\n",
      "episode: 1988   score: 5.0   memory length: 426141   epsilon: 0.6901651000001428    steps: 337     evaluation reward: 5.31\n",
      "episode: 1989   score: 5.0   memory length: 426471   epsilon: 0.6898516000001429    steps: 330     evaluation reward: 5.31\n",
      "episode: 1990   score: 3.0   memory length: 426731   epsilon: 0.689604600000143    steps: 260     evaluation reward: 5.29\n",
      "episode: 1991   score: 7.0   memory length: 427100   epsilon: 0.6892540500001432    steps: 369     evaluation reward: 5.32\n",
      "episode: 1992   score: 3.0   memory length: 427327   epsilon: 0.6890384000001433    steps: 227     evaluation reward: 5.28\n",
      "episode: 1993   score: 5.0   memory length: 427672   epsilon: 0.6887106500001434    steps: 345     evaluation reward: 5.26\n",
      "episode: 1994   score: 3.0   memory length: 427920   epsilon: 0.6884750500001435    steps: 248     evaluation reward: 5.28\n",
      "episode: 1995   score: 2.0   memory length: 428137   epsilon: 0.6882689000001436    steps: 217     evaluation reward: 5.26\n",
      "episode: 1996   score: 7.0   memory length: 428404   epsilon: 0.6880152500001437    steps: 267     evaluation reward: 5.3\n",
      "episode: 1997   score: 4.0   memory length: 428682   epsilon: 0.6877511500001439    steps: 278     evaluation reward: 5.3\n",
      "episode: 1998   score: 3.0   memory length: 428938   epsilon: 0.687507950000144    steps: 256     evaluation reward: 5.26\n",
      "episode: 1999   score: 2.0   memory length: 429123   epsilon: 0.6873322000001441    steps: 185     evaluation reward: 5.23\n",
      "episode: 2000   score: 9.0   memory length: 429615   epsilon: 0.6868648000001443    steps: 492     evaluation reward: 5.25\n",
      "episode: 2001   score: 8.0   memory length: 430036   epsilon: 0.6864648500001445    steps: 421     evaluation reward: 5.26\n",
      "episode: 2002   score: 3.0   memory length: 430268   epsilon: 0.6862444500001446    steps: 232     evaluation reward: 5.23\n",
      "episode: 2003   score: 2.0   memory length: 430482   epsilon: 0.6860411500001447    steps: 214     evaluation reward: 5.12\n",
      "episode: 2004   score: 3.0   memory length: 430696   epsilon: 0.6858378500001447    steps: 214     evaluation reward: 5.13\n",
      "episode: 2005   score: 1.0   memory length: 430874   epsilon: 0.6856687500001448    steps: 178     evaluation reward: 5.08\n",
      "episode: 2006   score: 3.0   memory length: 431113   epsilon: 0.6854417000001449    steps: 239     evaluation reward: 5.05\n",
      "episode: 2007   score: 2.0   memory length: 431320   epsilon: 0.685245050000145    steps: 207     evaluation reward: 5.02\n",
      "episode: 2008   score: 8.0   memory length: 431704   epsilon: 0.6848802500001452    steps: 384     evaluation reward: 5.08\n",
      "episode: 2009   score: 4.0   memory length: 431948   epsilon: 0.6846484500001453    steps: 244     evaluation reward: 4.9\n",
      "episode: 2010   score: 8.0   memory length: 432419   epsilon: 0.6842010000001455    steps: 471     evaluation reward: 4.94\n",
      "episode: 2011   score: 6.0   memory length: 432789   epsilon: 0.6838495000001457    steps: 370     evaluation reward: 4.94\n",
      "episode: 2012   score: 4.0   memory length: 433090   epsilon: 0.6835635500001458    steps: 301     evaluation reward: 4.87\n",
      "episode: 2013   score: 5.0   memory length: 433419   epsilon: 0.6832510000001459    steps: 329     evaluation reward: 4.87\n",
      "episode: 2014   score: 9.0   memory length: 433884   epsilon: 0.6828092500001461    steps: 465     evaluation reward: 4.92\n",
      "episode: 2015   score: 7.0   memory length: 434265   epsilon: 0.6824473000001463    steps: 381     evaluation reward: 4.95\n",
      "episode: 2016   score: 5.0   memory length: 434595   epsilon: 0.6821338000001465    steps: 330     evaluation reward: 4.96\n",
      "episode: 2017   score: 2.0   memory length: 434793   epsilon: 0.6819457000001465    steps: 198     evaluation reward: 4.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2018   score: 7.0   memory length: 435190   epsilon: 0.6815685500001467    steps: 397     evaluation reward: 4.99\n",
      "episode: 2019   score: 2.0   memory length: 435430   epsilon: 0.6813405500001468    steps: 240     evaluation reward: 4.95\n",
      "episode: 2020   score: 6.0   memory length: 435792   epsilon: 0.680996650000147    steps: 362     evaluation reward: 4.96\n",
      "episode: 2021   score: 6.0   memory length: 436127   epsilon: 0.6806784000001471    steps: 335     evaluation reward: 4.99\n",
      "episode: 2022   score: 12.0   memory length: 436643   epsilon: 0.6801882000001473    steps: 516     evaluation reward: 5.09\n",
      "episode: 2023   score: 7.0   memory length: 436996   epsilon: 0.6798528500001475    steps: 353     evaluation reward: 5.07\n",
      "episode: 2024   score: 5.0   memory length: 437358   epsilon: 0.6795089500001477    steps: 362     evaluation reward: 5.06\n",
      "episode: 2025   score: 5.0   memory length: 437703   epsilon: 0.6791812000001478    steps: 345     evaluation reward: 5.09\n",
      "episode: 2026   score: 5.0   memory length: 438018   epsilon: 0.678881950000148    steps: 315     evaluation reward: 5.11\n",
      "episode: 2027   score: 3.0   memory length: 438238   epsilon: 0.678672950000148    steps: 220     evaluation reward: 5.1\n",
      "episode: 2028   score: 2.0   memory length: 438422   epsilon: 0.6784981500001481    steps: 184     evaluation reward: 5.08\n",
      "episode: 2029   score: 4.0   memory length: 438730   epsilon: 0.6782055500001483    steps: 308     evaluation reward: 5.06\n",
      "episode: 2030   score: 1.0   memory length: 438890   epsilon: 0.6780535500001483    steps: 160     evaluation reward: 5.05\n",
      "episode: 2031   score: 2.0   memory length: 439087   epsilon: 0.6778664000001484    steps: 197     evaluation reward: 5.05\n",
      "episode: 2032   score: 4.0   memory length: 439365   epsilon: 0.6776023000001485    steps: 278     evaluation reward: 5.01\n",
      "episode: 2033   score: 2.0   memory length: 439563   epsilon: 0.6774142000001486    steps: 198     evaluation reward: 4.99\n",
      "episode: 2034   score: 5.0   memory length: 439859   epsilon: 0.6771330000001488    steps: 296     evaluation reward: 4.96\n",
      "episode: 2035   score: 3.0   memory length: 440086   epsilon: 0.6769173500001489    steps: 227     evaluation reward: 4.91\n",
      "episode: 2036   score: 2.0   memory length: 440297   epsilon: 0.676716900000149    steps: 211     evaluation reward: 4.91\n",
      "episode: 2037   score: 5.0   memory length: 440663   epsilon: 0.6763692000001491    steps: 366     evaluation reward: 4.91\n",
      "episode: 2038   score: 5.0   memory length: 440961   epsilon: 0.6760861000001492    steps: 298     evaluation reward: 4.91\n",
      "episode: 2039   score: 6.0   memory length: 441321   epsilon: 0.6757441000001494    steps: 360     evaluation reward: 4.83\n",
      "episode: 2040   score: 3.0   memory length: 441552   epsilon: 0.6755246500001495    steps: 231     evaluation reward: 4.83\n",
      "episode: 2041   score: 7.0   memory length: 441934   epsilon: 0.6751617500001497    steps: 382     evaluation reward: 4.81\n",
      "episode: 2042   score: 10.0   memory length: 442416   epsilon: 0.6747038500001499    steps: 482     evaluation reward: 4.84\n",
      "episode: 2043   score: 3.0   memory length: 442673   epsilon: 0.67445970000015    steps: 257     evaluation reward: 4.82\n",
      "episode: 2044   score: 2.0   memory length: 442855   epsilon: 0.6742868000001501    steps: 182     evaluation reward: 4.79\n",
      "episode: 2045   score: 4.0   memory length: 443169   epsilon: 0.6739885000001502    steps: 314     evaluation reward: 4.78\n",
      "episode: 2046   score: 3.0   memory length: 443421   epsilon: 0.6737491000001503    steps: 252     evaluation reward: 4.76\n",
      "episode: 2047   score: 4.0   memory length: 443691   epsilon: 0.6734926000001504    steps: 270     evaluation reward: 4.74\n",
      "episode: 2048   score: 8.0   memory length: 444070   epsilon: 0.6731325500001506    steps: 379     evaluation reward: 4.72\n",
      "episode: 2049   score: 5.0   memory length: 444378   epsilon: 0.6728399500001507    steps: 308     evaluation reward: 4.74\n",
      "episode: 2050   score: 4.0   memory length: 444660   epsilon: 0.6725720500001509    steps: 282     evaluation reward: 4.73\n",
      "episode: 2051   score: 6.0   memory length: 445049   epsilon: 0.672202500000151    steps: 389     evaluation reward: 4.76\n",
      "episode: 2052   score: 3.0   memory length: 445289   epsilon: 0.6719745000001511    steps: 240     evaluation reward: 4.73\n",
      "episode: 2053   score: 3.0   memory length: 445545   epsilon: 0.6717313000001512    steps: 256     evaluation reward: 4.68\n",
      "episode: 2054   score: 6.0   memory length: 445890   epsilon: 0.6714035500001514    steps: 345     evaluation reward: 4.7\n",
      "episode: 2055   score: 8.0   memory length: 446243   epsilon: 0.6710682000001515    steps: 353     evaluation reward: 4.72\n",
      "episode: 2056   score: 5.0   memory length: 446596   epsilon: 0.6707328500001517    steps: 353     evaluation reward: 4.73\n",
      "episode: 2057   score: 1.0   memory length: 446771   epsilon: 0.6705666000001518    steps: 175     evaluation reward: 4.68\n",
      "episode: 2058   score: 11.0   memory length: 447171   epsilon: 0.670186600000152    steps: 400     evaluation reward: 4.74\n",
      "episode: 2059   score: 3.0   memory length: 447398   epsilon: 0.669970950000152    steps: 227     evaluation reward: 4.75\n",
      "episode: 2060   score: 11.0   memory length: 447829   epsilon: 0.6695615000001522    steps: 431     evaluation reward: 4.75\n",
      "episode: 2061   score: 3.0   memory length: 448065   epsilon: 0.6693373000001523    steps: 236     evaluation reward: 4.74\n",
      "episode: 2062   score: 8.0   memory length: 448511   epsilon: 0.6689136000001525    steps: 446     evaluation reward: 4.74\n",
      "episode: 2063   score: 5.0   memory length: 448808   epsilon: 0.6686314500001527    steps: 297     evaluation reward: 4.77\n",
      "episode: 2064   score: 3.0   memory length: 449082   epsilon: 0.6683711500001528    steps: 274     evaluation reward: 4.75\n",
      "episode: 2065   score: 6.0   memory length: 449430   epsilon: 0.6680405500001529    steps: 348     evaluation reward: 4.73\n",
      "episode: 2066   score: 8.0   memory length: 449896   epsilon: 0.6675978500001531    steps: 466     evaluation reward: 4.73\n",
      "now time :  2018-12-14 09:33:51.620314\n",
      "episode: 2067   score: 6.0   memory length: 450248   epsilon: 0.6672634500001533    steps: 352     evaluation reward: 4.77\n",
      "episode: 2068   score: 2.0   memory length: 450434   epsilon: 0.6670867500001534    steps: 186     evaluation reward: 4.76\n",
      "episode: 2069   score: 3.0   memory length: 450670   epsilon: 0.6668625500001535    steps: 236     evaluation reward: 4.75\n",
      "episode: 2070   score: 3.0   memory length: 450935   epsilon: 0.6666108000001536    steps: 265     evaluation reward: 4.73\n",
      "episode: 2071   score: 0.0   memory length: 451067   epsilon: 0.6664854000001537    steps: 132     evaluation reward: 4.69\n",
      "episode: 2072   score: 8.0   memory length: 451358   epsilon: 0.6662089500001538    steps: 291     evaluation reward: 4.68\n",
      "episode: 2073   score: 9.0   memory length: 451717   epsilon: 0.665867900000154    steps: 359     evaluation reward: 4.71\n",
      "episode: 2074   score: 6.0   memory length: 452097   epsilon: 0.6655069000001541    steps: 380     evaluation reward: 4.73\n",
      "episode: 2075   score: 5.0   memory length: 452409   epsilon: 0.6652105000001542    steps: 312     evaluation reward: 4.77\n",
      "episode: 2076   score: 7.0   memory length: 452836   epsilon: 0.6648048500001544    steps: 427     evaluation reward: 4.81\n",
      "episode: 2077   score: 8.0   memory length: 453248   epsilon: 0.6644134500001546    steps: 412     evaluation reward: 4.83\n",
      "episode: 2078   score: 5.0   memory length: 453589   epsilon: 0.6640895000001548    steps: 341     evaluation reward: 4.86\n",
      "episode: 2079   score: 7.0   memory length: 454005   epsilon: 0.663694300000155    steps: 416     evaluation reward: 4.89\n",
      "episode: 2080   score: 5.0   memory length: 454307   epsilon: 0.6634074000001551    steps: 302     evaluation reward: 4.89\n",
      "episode: 2081   score: 11.0   memory length: 454719   epsilon: 0.6630160000001553    steps: 412     evaluation reward: 4.95\n",
      "episode: 2082   score: 2.0   memory length: 454921   epsilon: 0.6628241000001553    steps: 202     evaluation reward: 4.88\n",
      "episode: 2083   score: 5.0   memory length: 455257   epsilon: 0.6625049000001555    steps: 336     evaluation reward: 4.9\n",
      "episode: 2084   score: 6.0   memory length: 455645   epsilon: 0.6621363000001557    steps: 388     evaluation reward: 4.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2085   score: 3.0   memory length: 455866   epsilon: 0.6619263500001558    steps: 221     evaluation reward: 4.91\n",
      "episode: 2086   score: 9.0   memory length: 456393   epsilon: 0.661425700000156    steps: 527     evaluation reward: 4.93\n",
      "episode: 2087   score: 9.0   memory length: 456892   epsilon: 0.6609516500001562    steps: 499     evaluation reward: 4.99\n",
      "episode: 2088   score: 10.0   memory length: 457258   epsilon: 0.6606039500001564    steps: 366     evaluation reward: 5.04\n",
      "episode: 2089   score: 6.0   memory length: 457637   epsilon: 0.6602439000001565    steps: 379     evaluation reward: 5.05\n",
      "episode: 2090   score: 5.0   memory length: 457974   epsilon: 0.6599237500001567    steps: 337     evaluation reward: 5.07\n",
      "episode: 2091   score: 6.0   memory length: 458341   epsilon: 0.6595751000001568    steps: 367     evaluation reward: 5.06\n",
      "episode: 2092   score: 9.0   memory length: 458771   epsilon: 0.659166600000157    steps: 430     evaluation reward: 5.12\n",
      "episode: 2093   score: 3.0   memory length: 459026   epsilon: 0.6589243500001571    steps: 255     evaluation reward: 5.1\n",
      "episode: 2094   score: 7.0   memory length: 459413   epsilon: 0.6585567000001573    steps: 387     evaluation reward: 5.14\n",
      "episode: 2095   score: 6.0   memory length: 459776   epsilon: 0.6582118500001575    steps: 363     evaluation reward: 5.18\n",
      "episode: 2096   score: 6.0   memory length: 460120   epsilon: 0.6578850500001576    steps: 344     evaluation reward: 5.17\n",
      "episode: 2097   score: 11.0   memory length: 460545   epsilon: 0.6574813000001578    steps: 425     evaluation reward: 5.24\n",
      "episode: 2098   score: 2.0   memory length: 460758   epsilon: 0.6572789500001579    steps: 213     evaluation reward: 5.23\n",
      "episode: 2099   score: 6.0   memory length: 461099   epsilon: 0.656955000000158    steps: 341     evaluation reward: 5.27\n",
      "episode: 2100   score: 6.0   memory length: 461443   epsilon: 0.6566282000001582    steps: 344     evaluation reward: 5.24\n",
      "episode: 2101   score: 7.0   memory length: 461836   epsilon: 0.6562548500001584    steps: 393     evaluation reward: 5.23\n",
      "episode: 2102   score: 8.0   memory length: 462256   epsilon: 0.6558558500001586    steps: 420     evaluation reward: 5.28\n",
      "episode: 2103   score: 5.0   memory length: 462602   epsilon: 0.6555271500001587    steps: 346     evaluation reward: 5.31\n",
      "episode: 2104   score: 4.0   memory length: 462886   epsilon: 0.6552573500001588    steps: 284     evaluation reward: 5.32\n",
      "episode: 2105   score: 2.0   memory length: 463089   epsilon: 0.6550645000001589    steps: 203     evaluation reward: 5.33\n",
      "episode: 2106   score: 9.0   memory length: 463530   epsilon: 0.6546455500001591    steps: 441     evaluation reward: 5.39\n",
      "episode: 2107   score: 2.0   memory length: 463712   epsilon: 0.6544726500001592    steps: 182     evaluation reward: 5.39\n",
      "episode: 2108   score: 8.0   memory length: 464119   epsilon: 0.6540860000001594    steps: 407     evaluation reward: 5.39\n",
      "episode: 2109   score: 5.0   memory length: 464436   epsilon: 0.6537848500001595    steps: 317     evaluation reward: 5.4\n",
      "episode: 2110   score: 4.0   memory length: 464729   epsilon: 0.6535065000001596    steps: 293     evaluation reward: 5.36\n",
      "episode: 2111   score: 14.0   memory length: 465240   epsilon: 0.6530210500001599    steps: 511     evaluation reward: 5.44\n",
      "episode: 2112   score: 9.0   memory length: 465728   epsilon: 0.6525574500001601    steps: 488     evaluation reward: 5.49\n",
      "episode: 2113   score: 7.0   memory length: 466139   epsilon: 0.6521670000001603    steps: 411     evaluation reward: 5.51\n",
      "episode: 2114   score: 10.0   memory length: 466498   epsilon: 0.6518259500001604    steps: 359     evaluation reward: 5.52\n",
      "episode: 2115   score: 4.0   memory length: 466818   epsilon: 0.6515219500001606    steps: 320     evaluation reward: 5.49\n",
      "episode: 2116   score: 4.0   memory length: 467102   epsilon: 0.6512521500001607    steps: 284     evaluation reward: 5.48\n",
      "episode: 2117   score: 4.0   memory length: 467380   epsilon: 0.6509880500001608    steps: 278     evaluation reward: 5.5\n",
      "episode: 2118   score: 0.0   memory length: 467506   epsilon: 0.6508683500001609    steps: 126     evaluation reward: 5.43\n",
      "episode: 2119   score: 3.0   memory length: 467725   epsilon: 0.650660300000161    steps: 219     evaluation reward: 5.44\n",
      "episode: 2120   score: 5.0   memory length: 468041   epsilon: 0.6503601000001611    steps: 316     evaluation reward: 5.43\n",
      "episode: 2121   score: 8.0   memory length: 468495   epsilon: 0.6499288000001613    steps: 454     evaluation reward: 5.45\n",
      "episode: 2122   score: 9.0   memory length: 468977   epsilon: 0.6494709000001615    steps: 482     evaluation reward: 5.42\n",
      "episode: 2123   score: 5.0   memory length: 469301   epsilon: 0.6491631000001616    steps: 324     evaluation reward: 5.4\n",
      "episode: 2124   score: 2.0   memory length: 469492   epsilon: 0.6489816500001617    steps: 191     evaluation reward: 5.37\n",
      "episode: 2125   score: 9.0   memory length: 469846   epsilon: 0.6486453500001619    steps: 354     evaluation reward: 5.41\n",
      "episode: 2126   score: 6.0   memory length: 470180   epsilon: 0.648328050000162    steps: 334     evaluation reward: 5.42\n",
      "episode: 2127   score: 10.0   memory length: 470570   epsilon: 0.6479575500001622    steps: 390     evaluation reward: 5.49\n",
      "episode: 2128   score: 2.0   memory length: 470762   epsilon: 0.6477751500001623    steps: 192     evaluation reward: 5.49\n",
      "episode: 2129   score: 6.0   memory length: 471131   epsilon: 0.6474246000001624    steps: 369     evaluation reward: 5.51\n",
      "episode: 2130   score: 7.0   memory length: 471527   epsilon: 0.6470484000001626    steps: 396     evaluation reward: 5.57\n",
      "episode: 2131   score: 5.0   memory length: 471840   epsilon: 0.6467510500001628    steps: 313     evaluation reward: 5.6\n",
      "episode: 2132   score: 5.0   memory length: 472159   epsilon: 0.6464480000001629    steps: 319     evaluation reward: 5.61\n",
      "episode: 2133   score: 5.0   memory length: 472487   epsilon: 0.646136400000163    steps: 328     evaluation reward: 5.64\n",
      "episode: 2134   score: 12.0   memory length: 473068   epsilon: 0.6455844500001633    steps: 581     evaluation reward: 5.71\n",
      "episode: 2135   score: 4.0   memory length: 473371   epsilon: 0.6452966000001634    steps: 303     evaluation reward: 5.72\n",
      "episode: 2136   score: 13.0   memory length: 473740   epsilon: 0.6449460500001636    steps: 369     evaluation reward: 5.83\n",
      "episode: 2137   score: 4.0   memory length: 474003   epsilon: 0.6446962000001637    steps: 263     evaluation reward: 5.82\n",
      "episode: 2138   score: 2.0   memory length: 474190   epsilon: 0.6445185500001638    steps: 187     evaluation reward: 5.79\n",
      "episode: 2139   score: 9.0   memory length: 474534   epsilon: 0.6441917500001639    steps: 344     evaluation reward: 5.82\n",
      "episode: 2140   score: 2.0   memory length: 474744   epsilon: 0.643992250000164    steps: 210     evaluation reward: 5.81\n",
      "episode: 2141   score: 5.0   memory length: 475089   epsilon: 0.6436645000001642    steps: 345     evaluation reward: 5.79\n",
      "episode: 2142   score: 7.0   memory length: 475481   epsilon: 0.6432921000001643    steps: 392     evaluation reward: 5.76\n",
      "episode: 2143   score: 4.0   memory length: 475764   epsilon: 0.6430232500001645    steps: 283     evaluation reward: 5.77\n",
      "episode: 2144   score: 12.0   memory length: 476184   epsilon: 0.6426242500001647    steps: 420     evaluation reward: 5.87\n",
      "episode: 2145   score: 3.0   memory length: 476421   epsilon: 0.6423991000001648    steps: 237     evaluation reward: 5.86\n",
      "episode: 2146   score: 8.0   memory length: 476899   epsilon: 0.641945000000165    steps: 478     evaluation reward: 5.91\n",
      "episode: 2147   score: 14.0   memory length: 477430   epsilon: 0.6414405500001652    steps: 531     evaluation reward: 6.01\n",
      "episode: 2148   score: 10.0   memory length: 477885   epsilon: 0.6410083000001654    steps: 455     evaluation reward: 6.03\n",
      "episode: 2149   score: 5.0   memory length: 478185   epsilon: 0.6407233000001655    steps: 300     evaluation reward: 6.03\n",
      "episode: 2150   score: 6.0   memory length: 478551   epsilon: 0.6403756000001657    steps: 366     evaluation reward: 6.05\n",
      "episode: 2151   score: 4.0   memory length: 478837   epsilon: 0.6401039000001658    steps: 286     evaluation reward: 6.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2152   score: 8.0   memory length: 479305   epsilon: 0.639659300000166    steps: 468     evaluation reward: 6.08\n",
      "episode: 2153   score: 2.0   memory length: 479515   epsilon: 0.6394598000001661    steps: 210     evaluation reward: 6.07\n",
      "episode: 2154   score: 17.0   memory length: 480136   epsilon: 0.6388698500001664    steps: 621     evaluation reward: 6.18\n",
      "episode: 2155   score: 6.0   memory length: 480551   epsilon: 0.6384756000001666    steps: 415     evaluation reward: 6.16\n",
      "episode: 2156   score: 2.0   memory length: 480767   epsilon: 0.6382704000001667    steps: 216     evaluation reward: 6.13\n",
      "episode: 2157   score: 7.0   memory length: 481175   epsilon: 0.6378828000001668    steps: 408     evaluation reward: 6.19\n",
      "episode: 2158   score: 6.0   memory length: 481528   epsilon: 0.637547450000167    steps: 353     evaluation reward: 6.14\n",
      "episode: 2159   score: 4.0   memory length: 481844   epsilon: 0.6372472500001671    steps: 316     evaluation reward: 6.15\n",
      "episode: 2160   score: 4.0   memory length: 482120   epsilon: 0.6369850500001673    steps: 276     evaluation reward: 6.08\n",
      "episode: 2161   score: 4.0   memory length: 482386   epsilon: 0.6367323500001674    steps: 266     evaluation reward: 6.09\n",
      "episode: 2162   score: 3.0   memory length: 482623   epsilon: 0.6365072000001675    steps: 237     evaluation reward: 6.04\n",
      "episode: 2163   score: 8.0   memory length: 483054   epsilon: 0.6360977500001677    steps: 431     evaluation reward: 6.07\n",
      "episode: 2164   score: 6.0   memory length: 483449   epsilon: 0.6357225000001678    steps: 395     evaluation reward: 6.1\n",
      "episode: 2165   score: 6.0   memory length: 483826   epsilon: 0.635364350000168    steps: 377     evaluation reward: 6.1\n",
      "episode: 2166   score: 5.0   memory length: 484138   epsilon: 0.6350679500001681    steps: 312     evaluation reward: 6.07\n",
      "episode: 2167   score: 12.0   memory length: 484579   epsilon: 0.6346490000001683    steps: 441     evaluation reward: 6.13\n",
      "episode: 2168   score: 13.0   memory length: 485085   epsilon: 0.6341683000001685    steps: 506     evaluation reward: 6.24\n",
      "episode: 2169   score: 2.0   memory length: 485300   epsilon: 0.6339640500001686    steps: 215     evaluation reward: 6.23\n",
      "episode: 2170   score: 10.0   memory length: 485844   epsilon: 0.6334472500001689    steps: 544     evaluation reward: 6.3\n",
      "episode: 2171   score: 12.0   memory length: 486131   epsilon: 0.633174600000169    steps: 287     evaluation reward: 6.42\n",
      "episode: 2172   score: 6.0   memory length: 486490   epsilon: 0.6328335500001692    steps: 359     evaluation reward: 6.4\n",
      "episode: 2173   score: 7.0   memory length: 486883   epsilon: 0.6324602000001693    steps: 393     evaluation reward: 6.38\n",
      "episode: 2174   score: 11.0   memory length: 487417   epsilon: 0.6319529000001696    steps: 534     evaluation reward: 6.43\n",
      "episode: 2175   score: 5.0   memory length: 487775   epsilon: 0.6316128000001697    steps: 358     evaluation reward: 6.43\n",
      "episode: 2176   score: 7.0   memory length: 488190   epsilon: 0.6312185500001699    steps: 415     evaluation reward: 6.43\n",
      "episode: 2177   score: 7.0   memory length: 488569   epsilon: 0.6308585000001701    steps: 379     evaluation reward: 6.42\n",
      "episode: 2178   score: 13.0   memory length: 489263   epsilon: 0.6301992000001704    steps: 694     evaluation reward: 6.5\n",
      "episode: 2179   score: 4.0   memory length: 489568   epsilon: 0.6299094500001705    steps: 305     evaluation reward: 6.47\n",
      "episode: 2180   score: 5.0   memory length: 489873   epsilon: 0.6296197000001706    steps: 305     evaluation reward: 6.47\n",
      "episode: 2181   score: 7.0   memory length: 490281   epsilon: 0.6292321000001708    steps: 408     evaluation reward: 6.43\n",
      "episode: 2182   score: 9.0   memory length: 490688   epsilon: 0.628845450000171    steps: 407     evaluation reward: 6.5\n",
      "episode: 2183   score: 1.0   memory length: 490849   epsilon: 0.6286925000001711    steps: 161     evaluation reward: 6.46\n",
      "episode: 2184   score: 10.0   memory length: 491237   epsilon: 0.6283239000001712    steps: 388     evaluation reward: 6.5\n",
      "episode: 2185   score: 3.0   memory length: 491486   epsilon: 0.6280873500001714    steps: 249     evaluation reward: 6.5\n",
      "episode: 2186   score: 10.0   memory length: 491945   epsilon: 0.6276513000001716    steps: 459     evaluation reward: 6.51\n",
      "episode: 2187   score: 6.0   memory length: 492302   epsilon: 0.6273121500001717    steps: 357     evaluation reward: 6.48\n",
      "episode: 2188   score: 5.0   memory length: 492629   epsilon: 0.6270015000001719    steps: 327     evaluation reward: 6.43\n",
      "episode: 2189   score: 8.0   memory length: 492939   epsilon: 0.626707000000172    steps: 310     evaluation reward: 6.45\n",
      "episode: 2190   score: 6.0   memory length: 493305   epsilon: 0.6263593000001721    steps: 366     evaluation reward: 6.46\n",
      "episode: 2191   score: 6.0   memory length: 493662   epsilon: 0.6260201500001723    steps: 357     evaluation reward: 6.46\n",
      "episode: 2192   score: 5.0   memory length: 493982   epsilon: 0.6257161500001724    steps: 320     evaluation reward: 6.42\n",
      "episode: 2193   score: 7.0   memory length: 494373   epsilon: 0.6253447000001726    steps: 391     evaluation reward: 6.46\n",
      "episode: 2194   score: 6.0   memory length: 494709   epsilon: 0.6250255000001728    steps: 336     evaluation reward: 6.45\n",
      "episode: 2195   score: 2.0   memory length: 494895   epsilon: 0.6248488000001728    steps: 186     evaluation reward: 6.41\n",
      "episode: 2196   score: 12.0   memory length: 495397   epsilon: 0.6243719000001731    steps: 502     evaluation reward: 6.47\n",
      "episode: 2197   score: 3.0   memory length: 495627   epsilon: 0.6241534000001732    steps: 230     evaluation reward: 6.39\n",
      "episode: 2198   score: 7.0   memory length: 496029   epsilon: 0.6237715000001733    steps: 402     evaluation reward: 6.44\n",
      "episode: 2199   score: 4.0   memory length: 496308   epsilon: 0.6235064500001735    steps: 279     evaluation reward: 6.42\n",
      "episode: 2200   score: 3.0   memory length: 496535   epsilon: 0.6232908000001736    steps: 227     evaluation reward: 6.39\n",
      "episode: 2201   score: 6.0   memory length: 496896   epsilon: 0.6229478500001737    steps: 361     evaluation reward: 6.38\n",
      "episode: 2202   score: 7.0   memory length: 497282   epsilon: 0.6225811500001739    steps: 386     evaluation reward: 6.37\n",
      "episode: 2203   score: 6.0   memory length: 497643   epsilon: 0.622238200000174    steps: 361     evaluation reward: 6.38\n",
      "episode: 2204   score: 3.0   memory length: 497892   epsilon: 0.6220016500001742    steps: 249     evaluation reward: 6.37\n",
      "episode: 2205   score: 10.0   memory length: 498388   epsilon: 0.6215304500001744    steps: 496     evaluation reward: 6.45\n",
      "episode: 2206   score: 5.0   memory length: 498730   epsilon: 0.6212055500001745    steps: 342     evaluation reward: 6.41\n",
      "episode: 2207   score: 7.0   memory length: 499112   epsilon: 0.6208426500001747    steps: 382     evaluation reward: 6.46\n",
      "episode: 2208   score: 4.0   memory length: 499403   epsilon: 0.6205662000001748    steps: 291     evaluation reward: 6.42\n",
      "episode: 2209   score: 6.0   memory length: 499763   epsilon: 0.620224200000175    steps: 360     evaluation reward: 6.43\n",
      "now time :  2018-12-14 09:52:47.368281\n",
      "episode: 2210   score: 9.0   memory length: 500259   epsilon: 0.6197530000001752    steps: 496     evaluation reward: 6.48\n",
      "episode: 2211   score: 5.0   memory length: 500570   epsilon: 0.6194575500001753    steps: 311     evaluation reward: 6.39\n",
      "episode: 2212   score: 3.0   memory length: 500823   epsilon: 0.6192172000001754    steps: 253     evaluation reward: 6.33\n",
      "episode: 2213   score: 5.0   memory length: 501135   epsilon: 0.6189208000001756    steps: 312     evaluation reward: 6.31\n",
      "episode: 2214   score: 1.0   memory length: 501298   epsilon: 0.6187659500001756    steps: 163     evaluation reward: 6.22\n",
      "episode: 2215   score: 5.0   memory length: 501617   epsilon: 0.6184629000001758    steps: 319     evaluation reward: 6.23\n",
      "episode: 2216   score: 4.0   memory length: 501899   epsilon: 0.6181950000001759    steps: 282     evaluation reward: 6.23\n",
      "episode: 2217   score: 4.0   memory length: 502146   epsilon: 0.617960350000176    steps: 247     evaluation reward: 6.23\n",
      "episode: 2218   score: 7.0   memory length: 502558   epsilon: 0.6175689500001762    steps: 412     evaluation reward: 6.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2219   score: 3.0   memory length: 502789   epsilon: 0.6173495000001763    steps: 231     evaluation reward: 6.3\n",
      "episode: 2220   score: 1.0   memory length: 502939   epsilon: 0.6172070000001764    steps: 150     evaluation reward: 6.26\n",
      "episode: 2221   score: 6.0   memory length: 503283   epsilon: 0.6168802000001765    steps: 344     evaluation reward: 6.24\n",
      "episode: 2222   score: 8.0   memory length: 503581   epsilon: 0.6165971000001766    steps: 298     evaluation reward: 6.23\n",
      "episode: 2223   score: 15.0   memory length: 504022   epsilon: 0.6161781500001768    steps: 441     evaluation reward: 6.33\n",
      "episode: 2224   score: 10.0   memory length: 504530   epsilon: 0.6156955500001771    steps: 508     evaluation reward: 6.41\n",
      "episode: 2225   score: 9.0   memory length: 504859   epsilon: 0.6153830000001772    steps: 329     evaluation reward: 6.41\n",
      "episode: 2226   score: 3.0   memory length: 505090   epsilon: 0.6151635500001773    steps: 231     evaluation reward: 6.38\n",
      "episode: 2227   score: 7.0   memory length: 505492   epsilon: 0.6147816500001775    steps: 402     evaluation reward: 6.35\n",
      "episode: 2228   score: 10.0   memory length: 505879   epsilon: 0.6144140000001777    steps: 387     evaluation reward: 6.43\n",
      "episode: 2229   score: 8.0   memory length: 506313   epsilon: 0.6140017000001778    steps: 434     evaluation reward: 6.45\n",
      "episode: 2230   score: 2.0   memory length: 506531   epsilon: 0.6137946000001779    steps: 218     evaluation reward: 6.4\n",
      "episode: 2231   score: 11.0   memory length: 507068   epsilon: 0.6132844500001782    steps: 537     evaluation reward: 6.46\n",
      "episode: 2232   score: 7.0   memory length: 507500   epsilon: 0.6128740500001784    steps: 432     evaluation reward: 6.48\n",
      "episode: 2233   score: 7.0   memory length: 507760   epsilon: 0.6126270500001785    steps: 260     evaluation reward: 6.5\n",
      "episode: 2234   score: 9.0   memory length: 508263   epsilon: 0.6121492000001787    steps: 503     evaluation reward: 6.47\n",
      "episode: 2235   score: 3.0   memory length: 508497   epsilon: 0.6119269000001788    steps: 234     evaluation reward: 6.46\n",
      "episode: 2236   score: 7.0   memory length: 508871   epsilon: 0.611571600000179    steps: 374     evaluation reward: 6.4\n",
      "episode: 2237   score: 6.0   memory length: 509222   epsilon: 0.6112381500001791    steps: 351     evaluation reward: 6.42\n",
      "episode: 2238   score: 3.0   memory length: 509460   epsilon: 0.6110120500001792    steps: 238     evaluation reward: 6.43\n",
      "episode: 2239   score: 8.0   memory length: 509921   epsilon: 0.6105741000001794    steps: 461     evaluation reward: 6.42\n",
      "episode: 2240   score: 4.0   memory length: 510210   epsilon: 0.6102995500001795    steps: 289     evaluation reward: 6.44\n",
      "episode: 2241   score: 11.0   memory length: 510622   epsilon: 0.6099081500001797    steps: 412     evaluation reward: 6.5\n",
      "episode: 2242   score: 7.0   memory length: 511016   epsilon: 0.6095338500001799    steps: 394     evaluation reward: 6.5\n",
      "episode: 2243   score: 8.0   memory length: 511458   epsilon: 0.6091139500001801    steps: 442     evaluation reward: 6.54\n",
      "episode: 2244   score: 3.0   memory length: 511694   epsilon: 0.6088897500001802    steps: 236     evaluation reward: 6.45\n",
      "episode: 2245   score: 7.0   memory length: 512100   epsilon: 0.6085040500001804    steps: 406     evaluation reward: 6.49\n",
      "episode: 2246   score: 4.0   memory length: 512369   epsilon: 0.6082485000001805    steps: 269     evaluation reward: 6.45\n",
      "episode: 2247   score: 6.0   memory length: 512692   epsilon: 0.6079416500001806    steps: 323     evaluation reward: 6.37\n",
      "episode: 2248   score: 9.0   memory length: 513185   epsilon: 0.6074733000001808    steps: 493     evaluation reward: 6.36\n",
      "episode: 2249   score: 4.0   memory length: 513446   epsilon: 0.607225350000181    steps: 261     evaluation reward: 6.35\n",
      "episode: 2250   score: 10.0   memory length: 513955   epsilon: 0.6067418000001812    steps: 509     evaluation reward: 6.39\n",
      "episode: 2251   score: 13.0   memory length: 514426   epsilon: 0.6062943500001814    steps: 471     evaluation reward: 6.48\n",
      "episode: 2252   score: 7.0   memory length: 514816   epsilon: 0.6059238500001816    steps: 390     evaluation reward: 6.47\n",
      "episode: 2253   score: 7.0   memory length: 515227   epsilon: 0.6055334000001817    steps: 411     evaluation reward: 6.52\n",
      "episode: 2254   score: 1.0   memory length: 515412   epsilon: 0.6053576500001818    steps: 185     evaluation reward: 6.36\n",
      "episode: 2255   score: 3.0   memory length: 515661   epsilon: 0.6051211000001819    steps: 249     evaluation reward: 6.33\n",
      "episode: 2256   score: 6.0   memory length: 516028   epsilon: 0.6047724500001821    steps: 367     evaluation reward: 6.37\n",
      "episode: 2257   score: 4.0   memory length: 516316   epsilon: 0.6044988500001822    steps: 288     evaluation reward: 6.34\n",
      "episode: 2258   score: 6.0   memory length: 516633   epsilon: 0.6041977000001824    steps: 317     evaluation reward: 6.34\n",
      "episode: 2259   score: 8.0   memory length: 517053   epsilon: 0.6037987000001825    steps: 420     evaluation reward: 6.38\n",
      "episode: 2260   score: 5.0   memory length: 517392   epsilon: 0.6034766500001827    steps: 339     evaluation reward: 6.39\n",
      "episode: 2261   score: 7.0   memory length: 517794   epsilon: 0.6030947500001829    steps: 402     evaluation reward: 6.42\n",
      "episode: 2262   score: 10.0   memory length: 518310   epsilon: 0.6026045500001831    steps: 516     evaluation reward: 6.49\n",
      "episode: 2263   score: 2.0   memory length: 518511   epsilon: 0.6024136000001832    steps: 201     evaluation reward: 6.43\n",
      "episode: 2264   score: 7.0   memory length: 518904   epsilon: 0.6020402500001834    steps: 393     evaluation reward: 6.44\n",
      "episode: 2265   score: 7.0   memory length: 519334   epsilon: 0.6016317500001835    steps: 430     evaluation reward: 6.45\n",
      "episode: 2266   score: 11.0   memory length: 519738   epsilon: 0.6012479500001837    steps: 404     evaluation reward: 6.51\n",
      "episode: 2267   score: 8.0   memory length: 520163   epsilon: 0.6008442000001839    steps: 425     evaluation reward: 6.47\n",
      "episode: 2268   score: 5.0   memory length: 520509   epsilon: 0.600515500000184    steps: 346     evaluation reward: 6.39\n",
      "episode: 2269   score: 3.0   memory length: 520743   epsilon: 0.6002932000001842    steps: 234     evaluation reward: 6.4\n",
      "episode: 2270   score: 8.0   memory length: 521166   epsilon: 0.5998913500001843    steps: 423     evaluation reward: 6.38\n",
      "episode: 2271   score: 7.0   memory length: 521574   epsilon: 0.5995037500001845    steps: 408     evaluation reward: 6.33\n",
      "episode: 2272   score: 10.0   memory length: 521936   epsilon: 0.5991598500001847    steps: 362     evaluation reward: 6.37\n",
      "episode: 2273   score: 6.0   memory length: 522303   epsilon: 0.5988112000001848    steps: 367     evaluation reward: 6.36\n",
      "episode: 2274   score: 5.0   memory length: 522612   epsilon: 0.598517650000185    steps: 309     evaluation reward: 6.3\n",
      "episode: 2275   score: 8.0   memory length: 523053   epsilon: 0.5980987000001852    steps: 441     evaluation reward: 6.33\n",
      "episode: 2276   score: 7.0   memory length: 523435   epsilon: 0.5977358000001853    steps: 382     evaluation reward: 6.33\n",
      "episode: 2277   score: 12.0   memory length: 523885   epsilon: 0.5973083000001855    steps: 450     evaluation reward: 6.38\n",
      "episode: 2278   score: 6.0   memory length: 524240   epsilon: 0.5969710500001857    steps: 355     evaluation reward: 6.31\n",
      "episode: 2279   score: 4.0   memory length: 524543   epsilon: 0.5966832000001858    steps: 303     evaluation reward: 6.31\n",
      "episode: 2280   score: 8.0   memory length: 525026   epsilon: 0.596224350000186    steps: 483     evaluation reward: 6.34\n",
      "episode: 2281   score: 5.0   memory length: 525358   epsilon: 0.5959089500001862    steps: 332     evaluation reward: 6.32\n",
      "episode: 2282   score: 7.0   memory length: 525800   epsilon: 0.5954890500001864    steps: 442     evaluation reward: 6.3\n",
      "episode: 2283   score: 5.0   memory length: 526154   epsilon: 0.5951527500001865    steps: 354     evaluation reward: 6.34\n",
      "episode: 2284   score: 12.0   memory length: 526709   epsilon: 0.5946255000001868    steps: 555     evaluation reward: 6.36\n",
      "episode: 2285   score: 4.0   memory length: 527006   epsilon: 0.5943433500001869    steps: 297     evaluation reward: 6.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2286   score: 5.0   memory length: 527342   epsilon: 0.594024150000187    steps: 336     evaluation reward: 6.32\n",
      "episode: 2287   score: 3.0   memory length: 527564   epsilon: 0.5938132500001871    steps: 222     evaluation reward: 6.29\n",
      "episode: 2288   score: 4.0   memory length: 527814   epsilon: 0.5935757500001873    steps: 250     evaluation reward: 6.28\n",
      "episode: 2289   score: 4.0   memory length: 528100   epsilon: 0.5933040500001874    steps: 286     evaluation reward: 6.24\n",
      "episode: 2290   score: 4.0   memory length: 528366   epsilon: 0.5930513500001875    steps: 266     evaluation reward: 6.22\n",
      "episode: 2291   score: 6.0   memory length: 528699   epsilon: 0.5927350000001876    steps: 333     evaluation reward: 6.22\n",
      "episode: 2292   score: 4.0   memory length: 528986   epsilon: 0.5924623500001878    steps: 287     evaluation reward: 6.21\n",
      "episode: 2293   score: 8.0   memory length: 529456   epsilon: 0.592015850000188    steps: 470     evaluation reward: 6.22\n",
      "episode: 2294   score: 6.0   memory length: 529813   epsilon: 0.5916767000001881    steps: 357     evaluation reward: 6.22\n",
      "episode: 2295   score: 2.0   memory length: 530018   epsilon: 0.5914819500001882    steps: 205     evaluation reward: 6.22\n",
      "episode: 2296   score: 3.0   memory length: 530252   epsilon: 0.5912596500001883    steps: 234     evaluation reward: 6.13\n",
      "episode: 2297   score: 16.0   memory length: 530705   epsilon: 0.5908293000001885    steps: 453     evaluation reward: 6.26\n",
      "episode: 2298   score: 5.0   memory length: 531054   epsilon: 0.5904977500001887    steps: 349     evaluation reward: 6.24\n",
      "episode: 2299   score: 9.0   memory length: 531552   epsilon: 0.5900246500001889    steps: 498     evaluation reward: 6.29\n",
      "episode: 2300   score: 3.0   memory length: 531794   epsilon: 0.589794750000189    steps: 242     evaluation reward: 6.29\n",
      "episode: 2301   score: 7.0   memory length: 532205   epsilon: 0.5894043000001892    steps: 411     evaluation reward: 6.3\n",
      "episode: 2302   score: 8.0   memory length: 532645   epsilon: 0.5889863000001894    steps: 440     evaluation reward: 6.31\n",
      "episode: 2303   score: 4.0   memory length: 532926   epsilon: 0.5887193500001895    steps: 281     evaluation reward: 6.29\n",
      "episode: 2304   score: 6.0   memory length: 533309   epsilon: 0.5883555000001897    steps: 383     evaluation reward: 6.32\n",
      "episode: 2305   score: 17.0   memory length: 533788   epsilon: 0.5879004500001899    steps: 479     evaluation reward: 6.39\n",
      "episode: 2306   score: 4.0   memory length: 534117   epsilon: 0.58758790000019    steps: 329     evaluation reward: 6.38\n",
      "episode: 2307   score: 13.0   memory length: 534501   epsilon: 0.5872231000001902    steps: 384     evaluation reward: 6.44\n",
      "episode: 2308   score: 4.0   memory length: 534745   epsilon: 0.5869913000001903    steps: 244     evaluation reward: 6.44\n",
      "episode: 2309   score: 12.0   memory length: 535199   epsilon: 0.5865600000001905    steps: 454     evaluation reward: 6.5\n",
      "episode: 2310   score: 4.0   memory length: 535466   epsilon: 0.5863063500001906    steps: 267     evaluation reward: 6.45\n",
      "episode: 2311   score: 7.0   memory length: 535863   epsilon: 0.5859292000001908    steps: 397     evaluation reward: 6.47\n",
      "episode: 2312   score: 6.0   memory length: 536228   epsilon: 0.5855824500001909    steps: 365     evaluation reward: 6.5\n",
      "episode: 2313   score: 6.0   memory length: 536565   epsilon: 0.5852623000001911    steps: 337     evaluation reward: 6.51\n",
      "episode: 2314   score: 6.0   memory length: 536892   epsilon: 0.5849516500001912    steps: 327     evaluation reward: 6.56\n",
      "episode: 2315   score: 11.0   memory length: 537435   epsilon: 0.5844358000001915    steps: 543     evaluation reward: 6.62\n",
      "episode: 2316   score: 17.0   memory length: 537948   epsilon: 0.5839484500001917    steps: 513     evaluation reward: 6.75\n",
      "episode: 2317   score: 6.0   memory length: 538302   epsilon: 0.5836121500001918    steps: 354     evaluation reward: 6.77\n",
      "episode: 2318   score: 5.0   memory length: 538655   epsilon: 0.583276800000192    steps: 353     evaluation reward: 6.75\n",
      "episode: 2319   score: 6.0   memory length: 539039   epsilon: 0.5829120000001922    steps: 384     evaluation reward: 6.78\n",
      "episode: 2320   score: 6.0   memory length: 539371   epsilon: 0.5825966000001923    steps: 332     evaluation reward: 6.83\n",
      "episode: 2321   score: 10.0   memory length: 539758   epsilon: 0.5822289500001925    steps: 387     evaluation reward: 6.87\n",
      "episode: 2322   score: 4.0   memory length: 540022   epsilon: 0.5819781500001926    steps: 264     evaluation reward: 6.83\n",
      "episode: 2323   score: 7.0   memory length: 540427   epsilon: 0.5815934000001928    steps: 405     evaluation reward: 6.75\n",
      "episode: 2324   score: 4.0   memory length: 540680   epsilon: 0.5813530500001929    steps: 253     evaluation reward: 6.69\n",
      "episode: 2325   score: 7.0   memory length: 541077   epsilon: 0.5809759000001931    steps: 397     evaluation reward: 6.67\n",
      "episode: 2326   score: 11.0   memory length: 541633   epsilon: 0.5804477000001933    steps: 556     evaluation reward: 6.75\n",
      "episode: 2327   score: 6.0   memory length: 541985   epsilon: 0.5801133000001935    steps: 352     evaluation reward: 6.74\n",
      "episode: 2328   score: 8.0   memory length: 542432   epsilon: 0.5796886500001937    steps: 447     evaluation reward: 6.72\n",
      "episode: 2329   score: 8.0   memory length: 542748   epsilon: 0.5793884500001938    steps: 316     evaluation reward: 6.72\n",
      "episode: 2330   score: 11.0   memory length: 543273   epsilon: 0.578889700000194    steps: 525     evaluation reward: 6.81\n",
      "episode: 2331   score: 11.0   memory length: 543824   epsilon: 0.5783662500001943    steps: 551     evaluation reward: 6.81\n",
      "episode: 2332   score: 7.0   memory length: 544182   epsilon: 0.5780261500001944    steps: 358     evaluation reward: 6.81\n",
      "episode: 2333   score: 11.0   memory length: 544599   epsilon: 0.5776300000001946    steps: 417     evaluation reward: 6.85\n",
      "episode: 2334   score: 12.0   memory length: 545060   epsilon: 0.5771920500001948    steps: 461     evaluation reward: 6.88\n",
      "episode: 2335   score: 6.0   memory length: 545399   epsilon: 0.576870000000195    steps: 339     evaluation reward: 6.91\n",
      "episode: 2336   score: 9.0   memory length: 545889   epsilon: 0.5764045000001952    steps: 490     evaluation reward: 6.93\n",
      "episode: 2337   score: 3.0   memory length: 546125   epsilon: 0.5761803000001953    steps: 236     evaluation reward: 6.9\n",
      "episode: 2338   score: 12.0   memory length: 546692   epsilon: 0.5756416500001955    steps: 567     evaluation reward: 6.99\n",
      "episode: 2339   score: 12.0   memory length: 547192   epsilon: 0.5751666500001957    steps: 500     evaluation reward: 7.03\n",
      "episode: 2340   score: 6.0   memory length: 547514   epsilon: 0.5748607500001959    steps: 322     evaluation reward: 7.05\n",
      "episode: 2341   score: 11.0   memory length: 547927   epsilon: 0.5744684000001961    steps: 413     evaluation reward: 7.05\n",
      "episode: 2342   score: 16.0   memory length: 548567   epsilon: 0.5738604000001963    steps: 640     evaluation reward: 7.14\n",
      "episode: 2343   score: 10.0   memory length: 549049   epsilon: 0.5734025000001965    steps: 482     evaluation reward: 7.16\n",
      "episode: 2344   score: 8.0   memory length: 549520   epsilon: 0.5729550500001968    steps: 471     evaluation reward: 7.21\n",
      "episode: 2345   score: 4.0   memory length: 549777   epsilon: 0.5727109000001969    steps: 257     evaluation reward: 7.18\n",
      "now time :  2018-12-14 10:12:41.609180\n",
      "episode: 2346   score: 8.0   memory length: 550167   epsilon: 0.572340400000197    steps: 390     evaluation reward: 7.22\n",
      "episode: 2347   score: 7.0   memory length: 550594   epsilon: 0.5719347500001972    steps: 427     evaluation reward: 7.23\n",
      "episode: 2348   score: 8.0   memory length: 551020   epsilon: 0.5715300500001974    steps: 426     evaluation reward: 7.22\n",
      "episode: 2349   score: 6.0   memory length: 551357   epsilon: 0.5712099000001976    steps: 337     evaluation reward: 7.24\n",
      "episode: 2350   score: 3.0   memory length: 551601   epsilon: 0.5709781000001977    steps: 244     evaluation reward: 7.17\n",
      "episode: 2351   score: 11.0   memory length: 552164   epsilon: 0.5704432500001979    steps: 563     evaluation reward: 7.15\n",
      "episode: 2352   score: 4.0   memory length: 552431   epsilon: 0.570189600000198    steps: 267     evaluation reward: 7.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2353   score: 6.0   memory length: 552778   epsilon: 0.5698599500001982    steps: 347     evaluation reward: 7.11\n",
      "episode: 2354   score: 2.0   memory length: 552999   epsilon: 0.5696500000001983    steps: 221     evaluation reward: 7.12\n",
      "episode: 2355   score: 10.0   memory length: 553374   epsilon: 0.5692937500001984    steps: 375     evaluation reward: 7.19\n",
      "episode: 2356   score: 4.0   memory length: 553640   epsilon: 0.5690410500001986    steps: 266     evaluation reward: 7.17\n",
      "episode: 2357   score: 4.0   memory length: 553901   epsilon: 0.5687931000001987    steps: 261     evaluation reward: 7.17\n",
      "episode: 2358   score: 15.0   memory length: 554437   epsilon: 0.5682839000001989    steps: 536     evaluation reward: 7.26\n",
      "episode: 2359   score: 8.0   memory length: 554860   epsilon: 0.5678820500001991    steps: 423     evaluation reward: 7.26\n",
      "episode: 2360   score: 6.0   memory length: 555200   epsilon: 0.5675590500001992    steps: 340     evaluation reward: 7.27\n",
      "episode: 2361   score: 5.0   memory length: 555503   epsilon: 0.5672712000001994    steps: 303     evaluation reward: 7.25\n",
      "episode: 2362   score: 6.0   memory length: 555824   epsilon: 0.5669662500001995    steps: 321     evaluation reward: 7.21\n",
      "episode: 2363   score: 6.0   memory length: 556184   epsilon: 0.5666242500001997    steps: 360     evaluation reward: 7.25\n",
      "episode: 2364   score: 7.0   memory length: 556559   epsilon: 0.5662680000001998    steps: 375     evaluation reward: 7.25\n",
      "episode: 2365   score: 11.0   memory length: 557112   epsilon: 0.5657426500002001    steps: 553     evaluation reward: 7.29\n",
      "episode: 2366   score: 4.0   memory length: 557386   epsilon: 0.5654823500002002    steps: 274     evaluation reward: 7.22\n",
      "episode: 2367   score: 6.0   memory length: 557737   epsilon: 0.5651489000002003    steps: 351     evaluation reward: 7.2\n",
      "episode: 2368   score: 9.0   memory length: 558193   epsilon: 0.5647157000002005    steps: 456     evaluation reward: 7.24\n",
      "episode: 2369   score: 7.0   memory length: 558609   epsilon: 0.5643205000002007    steps: 416     evaluation reward: 7.28\n",
      "episode: 2370   score: 10.0   memory length: 559064   epsilon: 0.5638882500002009    steps: 455     evaluation reward: 7.3\n",
      "episode: 2371   score: 7.0   memory length: 559507   epsilon: 0.5634674000002011    steps: 443     evaluation reward: 7.3\n",
      "episode: 2372   score: 10.0   memory length: 559896   epsilon: 0.5630978500002013    steps: 389     evaluation reward: 7.3\n",
      "episode: 2373   score: 3.0   memory length: 560158   epsilon: 0.5628489500002014    steps: 262     evaluation reward: 7.27\n",
      "episode: 2374   score: 3.0   memory length: 560388   epsilon: 0.5626304500002015    steps: 230     evaluation reward: 7.25\n",
      "episode: 2375   score: 3.0   memory length: 560645   epsilon: 0.5623863000002016    steps: 257     evaluation reward: 7.2\n",
      "episode: 2376   score: 5.0   memory length: 560983   epsilon: 0.5620652000002018    steps: 338     evaluation reward: 7.18\n",
      "episode: 2377   score: 11.0   memory length: 561439   epsilon: 0.561632000000202    steps: 456     evaluation reward: 7.17\n",
      "episode: 2378   score: 3.0   memory length: 561665   epsilon: 0.5614173000002021    steps: 226     evaluation reward: 7.14\n",
      "episode: 2379   score: 2.0   memory length: 561890   epsilon: 0.5612035500002022    steps: 225     evaluation reward: 7.12\n",
      "episode: 2380   score: 7.0   memory length: 562246   epsilon: 0.5608653500002023    steps: 356     evaluation reward: 7.11\n",
      "episode: 2381   score: 3.0   memory length: 562480   epsilon: 0.5606430500002024    steps: 234     evaluation reward: 7.09\n",
      "episode: 2382   score: 6.0   memory length: 562785   epsilon: 0.5603533000002026    steps: 305     evaluation reward: 7.08\n",
      "episode: 2383   score: 7.0   memory length: 563197   epsilon: 0.5599619000002027    steps: 412     evaluation reward: 7.1\n",
      "episode: 2384   score: 11.0   memory length: 563724   epsilon: 0.559461250000203    steps: 527     evaluation reward: 7.09\n",
      "episode: 2385   score: 13.0   memory length: 564201   epsilon: 0.5590081000002032    steps: 477     evaluation reward: 7.18\n",
      "episode: 2386   score: 7.0   memory length: 564561   epsilon: 0.5586661000002033    steps: 360     evaluation reward: 7.2\n",
      "episode: 2387   score: 6.0   memory length: 564916   epsilon: 0.5583288500002035    steps: 355     evaluation reward: 7.23\n",
      "episode: 2388   score: 6.0   memory length: 565225   epsilon: 0.5580353000002036    steps: 309     evaluation reward: 7.25\n",
      "episode: 2389   score: 11.0   memory length: 565755   epsilon: 0.5575318000002039    steps: 530     evaluation reward: 7.32\n",
      "episode: 2390   score: 4.0   memory length: 566075   epsilon: 0.557227800000204    steps: 320     evaluation reward: 7.32\n",
      "episode: 2391   score: 6.0   memory length: 566413   epsilon: 0.5569067000002041    steps: 338     evaluation reward: 7.32\n",
      "episode: 2392   score: 9.0   memory length: 566729   epsilon: 0.5566065000002043    steps: 316     evaluation reward: 7.37\n",
      "episode: 2393   score: 13.0   memory length: 567135   epsilon: 0.5562208000002045    steps: 406     evaluation reward: 7.42\n",
      "episode: 2394   score: 5.0   memory length: 567480   epsilon: 0.5558930500002046    steps: 345     evaluation reward: 7.41\n",
      "episode: 2395   score: 11.0   memory length: 568034   epsilon: 0.5553667500002049    steps: 554     evaluation reward: 7.5\n",
      "episode: 2396   score: 7.0   memory length: 568471   epsilon: 0.554951600000205    steps: 437     evaluation reward: 7.54\n",
      "episode: 2397   score: 7.0   memory length: 568825   epsilon: 0.5546153000002052    steps: 354     evaluation reward: 7.45\n",
      "episode: 2398   score: 5.0   memory length: 569151   epsilon: 0.5543056000002053    steps: 326     evaluation reward: 7.45\n",
      "episode: 2399   score: 4.0   memory length: 569441   epsilon: 0.5540301000002055    steps: 290     evaluation reward: 7.4\n",
      "episode: 2400   score: 4.0   memory length: 569721   epsilon: 0.5537641000002056    steps: 280     evaluation reward: 7.41\n",
      "episode: 2401   score: 4.0   memory length: 569988   epsilon: 0.5535104500002057    steps: 267     evaluation reward: 7.38\n",
      "episode: 2402   score: 9.0   memory length: 570467   epsilon: 0.5530554000002059    steps: 479     evaluation reward: 7.39\n",
      "episode: 2403   score: 6.0   memory length: 570834   epsilon: 0.5527067500002061    steps: 367     evaluation reward: 7.41\n",
      "episode: 2404   score: 6.0   memory length: 571197   epsilon: 0.5523619000002062    steps: 363     evaluation reward: 7.41\n",
      "episode: 2405   score: 7.0   memory length: 571576   epsilon: 0.5520018500002064    steps: 379     evaluation reward: 7.31\n",
      "episode: 2406   score: 8.0   memory length: 571881   epsilon: 0.5517121000002065    steps: 305     evaluation reward: 7.35\n",
      "episode: 2407   score: 6.0   memory length: 572238   epsilon: 0.5513729500002067    steps: 357     evaluation reward: 7.28\n",
      "episode: 2408   score: 4.0   memory length: 572525   epsilon: 0.5511003000002068    steps: 287     evaluation reward: 7.28\n",
      "episode: 2409   score: 7.0   memory length: 572879   epsilon: 0.550764000000207    steps: 354     evaluation reward: 7.23\n",
      "episode: 2410   score: 12.0   memory length: 573423   epsilon: 0.5502472000002072    steps: 544     evaluation reward: 7.31\n",
      "episode: 2411   score: 6.0   memory length: 573776   epsilon: 0.5499118500002074    steps: 353     evaluation reward: 7.3\n",
      "episode: 2412   score: 10.0   memory length: 574158   epsilon: 0.5495489500002075    steps: 382     evaluation reward: 7.34\n",
      "episode: 2413   score: 7.0   memory length: 574555   epsilon: 0.5491718000002077    steps: 397     evaluation reward: 7.35\n",
      "episode: 2414   score: 5.0   memory length: 574862   epsilon: 0.5488801500002078    steps: 307     evaluation reward: 7.34\n",
      "episode: 2415   score: 7.0   memory length: 575143   epsilon: 0.548613200000208    steps: 281     evaluation reward: 7.3\n",
      "episode: 2416   score: 11.0   memory length: 575543   epsilon: 0.5482332000002081    steps: 400     evaluation reward: 7.24\n",
      "episode: 2417   score: 10.0   memory length: 575957   epsilon: 0.5478399000002083    steps: 414     evaluation reward: 7.28\n",
      "episode: 2418   score: 10.0   memory length: 576353   epsilon: 0.5474637000002085    steps: 396     evaluation reward: 7.33\n",
      "episode: 2419   score: 13.0   memory length: 576788   epsilon: 0.5470504500002087    steps: 435     evaluation reward: 7.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2420   score: 9.0   memory length: 577260   epsilon: 0.5466020500002089    steps: 472     evaluation reward: 7.43\n",
      "episode: 2421   score: 8.0   memory length: 577657   epsilon: 0.5462249000002091    steps: 397     evaluation reward: 7.41\n",
      "episode: 2422   score: 8.0   memory length: 578100   epsilon: 0.5458040500002093    steps: 443     evaluation reward: 7.45\n",
      "episode: 2423   score: 5.0   memory length: 578437   epsilon: 0.5454839000002094    steps: 337     evaluation reward: 7.43\n",
      "episode: 2424   score: 6.0   memory length: 578784   epsilon: 0.5451542500002096    steps: 347     evaluation reward: 7.45\n",
      "episode: 2425   score: 5.0   memory length: 579112   epsilon: 0.5448426500002097    steps: 328     evaluation reward: 7.43\n",
      "episode: 2426   score: 12.0   memory length: 579576   epsilon: 0.5444018500002099    steps: 464     evaluation reward: 7.44\n",
      "episode: 2427   score: 8.0   memory length: 579864   epsilon: 0.54412825000021    steps: 288     evaluation reward: 7.46\n",
      "episode: 2428   score: 4.0   memory length: 580133   epsilon: 0.5438727000002102    steps: 269     evaluation reward: 7.42\n",
      "episode: 2429   score: 7.0   memory length: 580522   epsilon: 0.5435031500002103    steps: 389     evaluation reward: 7.41\n",
      "episode: 2430   score: 7.0   memory length: 580795   epsilon: 0.5432438000002104    steps: 273     evaluation reward: 7.37\n",
      "episode: 2431   score: 4.0   memory length: 581076   epsilon: 0.5429768500002106    steps: 281     evaluation reward: 7.3\n",
      "episode: 2432   score: 3.0   memory length: 581294   epsilon: 0.5427697500002107    steps: 218     evaluation reward: 7.26\n",
      "episode: 2433   score: 12.0   memory length: 581755   epsilon: 0.5423318000002109    steps: 461     evaluation reward: 7.27\n",
      "episode: 2434   score: 5.0   memory length: 582059   epsilon: 0.542043000000211    steps: 304     evaluation reward: 7.2\n",
      "episode: 2435   score: 9.0   memory length: 582545   epsilon: 0.5415813000002112    steps: 486     evaluation reward: 7.23\n",
      "episode: 2436   score: 7.0   memory length: 582904   epsilon: 0.5412402500002114    steps: 359     evaluation reward: 7.21\n",
      "episode: 2437   score: 6.0   memory length: 583236   epsilon: 0.5409248500002115    steps: 332     evaluation reward: 7.24\n",
      "episode: 2438   score: 7.0   memory length: 583635   epsilon: 0.5405458000002117    steps: 399     evaluation reward: 7.19\n",
      "episode: 2439   score: 8.0   memory length: 584084   epsilon: 0.5401192500002119    steps: 449     evaluation reward: 7.15\n",
      "episode: 2440   score: 4.0   memory length: 584352   epsilon: 0.539864650000212    steps: 268     evaluation reward: 7.13\n",
      "episode: 2441   score: 5.0   memory length: 584667   epsilon: 0.5395654000002121    steps: 315     evaluation reward: 7.07\n",
      "episode: 2442   score: 2.0   memory length: 584879   epsilon: 0.5393640000002122    steps: 212     evaluation reward: 6.93\n",
      "episode: 2443   score: 4.0   memory length: 585147   epsilon: 0.5391094000002123    steps: 268     evaluation reward: 6.87\n",
      "episode: 2444   score: 10.0   memory length: 585615   epsilon: 0.5386648000002126    steps: 468     evaluation reward: 6.89\n",
      "episode: 2445   score: 6.0   memory length: 585930   epsilon: 0.5383655500002127    steps: 315     evaluation reward: 6.91\n",
      "episode: 2446   score: 4.0   memory length: 586206   epsilon: 0.5381033500002128    steps: 276     evaluation reward: 6.87\n",
      "episode: 2447   score: 6.0   memory length: 586566   epsilon: 0.537761350000213    steps: 360     evaluation reward: 6.86\n",
      "episode: 2448   score: 6.0   memory length: 586958   epsilon: 0.5373889500002131    steps: 392     evaluation reward: 6.84\n",
      "episode: 2449   score: 5.0   memory length: 587260   epsilon: 0.5371020500002133    steps: 302     evaluation reward: 6.83\n",
      "episode: 2450   score: 8.0   memory length: 587684   epsilon: 0.5366992500002135    steps: 424     evaluation reward: 6.88\n",
      "episode: 2451   score: 4.0   memory length: 587991   epsilon: 0.5364076000002136    steps: 307     evaluation reward: 6.81\n",
      "episode: 2452   score: 6.0   memory length: 588332   epsilon: 0.5360836500002137    steps: 341     evaluation reward: 6.83\n",
      "episode: 2453   score: 12.0   memory length: 588804   epsilon: 0.535635250000214    steps: 472     evaluation reward: 6.89\n",
      "episode: 2454   score: 3.0   memory length: 589020   epsilon: 0.535430050000214    steps: 216     evaluation reward: 6.9\n",
      "episode: 2455   score: 2.0   memory length: 589221   epsilon: 0.5352391000002141    steps: 201     evaluation reward: 6.82\n",
      "episode: 2456   score: 6.0   memory length: 589550   epsilon: 0.5349265500002143    steps: 329     evaluation reward: 6.84\n",
      "episode: 2457   score: 6.0   memory length: 589937   epsilon: 0.5345589000002144    steps: 387     evaluation reward: 6.86\n",
      "episode: 2458   score: 4.0   memory length: 590200   epsilon: 0.5343090500002146    steps: 263     evaluation reward: 6.75\n",
      "episode: 2459   score: 10.0   memory length: 590560   epsilon: 0.5339670500002147    steps: 360     evaluation reward: 6.77\n",
      "episode: 2460   score: 7.0   memory length: 590930   epsilon: 0.5336155500002149    steps: 370     evaluation reward: 6.78\n",
      "episode: 2461   score: 7.0   memory length: 591363   epsilon: 0.5332042000002151    steps: 433     evaluation reward: 6.8\n",
      "episode: 2462   score: 8.0   memory length: 591766   epsilon: 0.5328213500002152    steps: 403     evaluation reward: 6.82\n",
      "episode: 2463   score: 5.0   memory length: 592074   epsilon: 0.5325287500002154    steps: 308     evaluation reward: 6.81\n",
      "episode: 2464   score: 12.0   memory length: 592517   epsilon: 0.5321079000002156    steps: 443     evaluation reward: 6.86\n",
      "episode: 2465   score: 9.0   memory length: 593010   epsilon: 0.5316395500002158    steps: 493     evaluation reward: 6.84\n",
      "episode: 2466   score: 7.0   memory length: 593425   epsilon: 0.531245300000216    steps: 415     evaluation reward: 6.87\n",
      "episode: 2467   score: 15.0   memory length: 594030   epsilon: 0.5306705500002162    steps: 605     evaluation reward: 6.96\n",
      "episode: 2468   score: 4.0   memory length: 594321   epsilon: 0.5303941000002164    steps: 291     evaluation reward: 6.91\n",
      "episode: 2469   score: 4.0   memory length: 594584   epsilon: 0.5301442500002165    steps: 263     evaluation reward: 6.88\n",
      "episode: 2470   score: 11.0   memory length: 594979   epsilon: 0.5297690000002166    steps: 395     evaluation reward: 6.89\n",
      "episode: 2471   score: 9.0   memory length: 595327   epsilon: 0.5294384000002168    steps: 348     evaluation reward: 6.91\n",
      "episode: 2472   score: 13.0   memory length: 595801   epsilon: 0.528988100000217    steps: 474     evaluation reward: 6.94\n",
      "episode: 2473   score: 6.0   memory length: 596196   epsilon: 0.5286128500002172    steps: 395     evaluation reward: 6.97\n",
      "episode: 2474   score: 5.0   memory length: 596507   epsilon: 0.5283174000002173    steps: 311     evaluation reward: 6.99\n",
      "episode: 2475   score: 7.0   memory length: 596860   epsilon: 0.5279820500002175    steps: 353     evaluation reward: 7.03\n",
      "episode: 2476   score: 6.0   memory length: 597186   epsilon: 0.5276723500002176    steps: 326     evaluation reward: 7.04\n",
      "episode: 2477   score: 11.0   memory length: 597473   epsilon: 0.5273997000002177    steps: 287     evaluation reward: 7.04\n",
      "episode: 2478   score: 5.0   memory length: 597811   epsilon: 0.5270786000002179    steps: 338     evaluation reward: 7.06\n",
      "episode: 2479   score: 17.0   memory length: 598434   epsilon: 0.5264867500002182    steps: 623     evaluation reward: 7.21\n",
      "episode: 2480   score: 3.0   memory length: 598697   epsilon: 0.5262369000002183    steps: 263     evaluation reward: 7.17\n",
      "episode: 2481   score: 8.0   memory length: 599147   epsilon: 0.5258094000002185    steps: 450     evaluation reward: 7.22\n",
      "episode: 2482   score: 9.0   memory length: 599581   epsilon: 0.5253971000002187    steps: 434     evaluation reward: 7.25\n",
      "episode: 2483   score: 4.0   memory length: 599862   epsilon: 0.5251301500002188    steps: 281     evaluation reward: 7.22\n",
      "now time :  2018-12-14 10:33:50.549986\n",
      "episode: 2484   score: 5.0   memory length: 600183   epsilon: 0.5248252000002189    steps: 321     evaluation reward: 7.16\n",
      "episode: 2485   score: 9.0   memory length: 600662   epsilon: 0.5243701500002191    steps: 479     evaluation reward: 7.12\n",
      "episode: 2486   score: 9.0   memory length: 601135   epsilon: 0.5239208000002193    steps: 473     evaluation reward: 7.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2487   score: 6.0   memory length: 601495   epsilon: 0.5235788000002195    steps: 360     evaluation reward: 7.14\n",
      "episode: 2488   score: 9.0   memory length: 601978   epsilon: 0.5231199500002197    steps: 483     evaluation reward: 7.17\n",
      "episode: 2489   score: 4.0   memory length: 602274   epsilon: 0.5228387500002198    steps: 296     evaluation reward: 7.1\n",
      "episode: 2490   score: 13.0   memory length: 602812   epsilon: 0.5223276500002201    steps: 538     evaluation reward: 7.19\n",
      "episode: 2491   score: 16.0   memory length: 603247   epsilon: 0.5219144000002203    steps: 435     evaluation reward: 7.29\n",
      "episode: 2492   score: 9.0   memory length: 603693   epsilon: 0.5214907000002205    steps: 446     evaluation reward: 7.29\n",
      "episode: 2493   score: 7.0   memory length: 604132   epsilon: 0.5210736500002207    steps: 439     evaluation reward: 7.23\n",
      "episode: 2494   score: 9.0   memory length: 604485   epsilon: 0.5207383000002208    steps: 353     evaluation reward: 7.27\n",
      "episode: 2495   score: 10.0   memory length: 604884   epsilon: 0.520359250000221    steps: 399     evaluation reward: 7.26\n",
      "episode: 2496   score: 15.0   memory length: 605486   epsilon: 0.5197873500002212    steps: 602     evaluation reward: 7.34\n",
      "episode: 2497   score: 8.0   memory length: 605938   epsilon: 0.5193579500002214    steps: 452     evaluation reward: 7.35\n",
      "episode: 2498   score: 9.0   memory length: 606430   epsilon: 0.5188905500002217    steps: 492     evaluation reward: 7.39\n",
      "episode: 2499   score: 7.0   memory length: 606833   epsilon: 0.5185077000002218    steps: 403     evaluation reward: 7.42\n",
      "episode: 2500   score: 10.0   memory length: 607229   epsilon: 0.518131500000222    steps: 396     evaluation reward: 7.48\n",
      "episode: 2501   score: 6.0   memory length: 607596   epsilon: 0.5177828500002222    steps: 367     evaluation reward: 7.5\n",
      "episode: 2502   score: 10.0   memory length: 608082   epsilon: 0.5173211500002224    steps: 486     evaluation reward: 7.51\n",
      "episode: 2503   score: 12.0   memory length: 608591   epsilon: 0.5168376000002226    steps: 509     evaluation reward: 7.57\n",
      "episode: 2504   score: 8.0   memory length: 608999   epsilon: 0.5164500000002228    steps: 408     evaluation reward: 7.59\n",
      "episode: 2505   score: 10.0   memory length: 609458   epsilon: 0.516013950000223    steps: 459     evaluation reward: 7.62\n",
      "episode: 2506   score: 5.0   memory length: 609765   epsilon: 0.5157223000002231    steps: 307     evaluation reward: 7.59\n",
      "episode: 2507   score: 10.0   memory length: 610217   epsilon: 0.5152929000002233    steps: 452     evaluation reward: 7.63\n",
      "episode: 2508   score: 4.0   memory length: 610513   epsilon: 0.5150117000002234    steps: 296     evaluation reward: 7.63\n",
      "episode: 2509   score: 9.0   memory length: 610977   epsilon: 0.5145709000002237    steps: 464     evaluation reward: 7.65\n",
      "episode: 2510   score: 12.0   memory length: 611423   epsilon: 0.5141472000002238    steps: 446     evaluation reward: 7.65\n",
      "episode: 2511   score: 8.0   memory length: 611825   epsilon: 0.513765300000224    steps: 402     evaluation reward: 7.67\n",
      "episode: 2512   score: 4.0   memory length: 612078   epsilon: 0.5135249500002241    steps: 253     evaluation reward: 7.61\n",
      "episode: 2513   score: 9.0   memory length: 612571   epsilon: 0.5130566000002243    steps: 493     evaluation reward: 7.63\n",
      "episode: 2514   score: 5.0   memory length: 612854   epsilon: 0.5127877500002245    steps: 283     evaluation reward: 7.63\n",
      "episode: 2515   score: 9.0   memory length: 613322   epsilon: 0.5123431500002247    steps: 468     evaluation reward: 7.65\n",
      "episode: 2516   score: 7.0   memory length: 613741   epsilon: 0.5119451000002249    steps: 419     evaluation reward: 7.61\n",
      "episode: 2517   score: 7.0   memory length: 614105   epsilon: 0.511599300000225    steps: 364     evaluation reward: 7.58\n",
      "episode: 2518   score: 13.0   memory length: 614783   epsilon: 0.5109552000002253    steps: 678     evaluation reward: 7.61\n",
      "episode: 2519   score: 10.0   memory length: 615183   epsilon: 0.5105752000002255    steps: 400     evaluation reward: 7.58\n",
      "episode: 2520   score: 7.0   memory length: 615570   epsilon: 0.5102075500002257    steps: 387     evaluation reward: 7.56\n",
      "episode: 2521   score: 8.0   memory length: 615985   epsilon: 0.5098133000002258    steps: 415     evaluation reward: 7.56\n",
      "episode: 2522   score: 5.0   memory length: 616306   epsilon: 0.509508350000226    steps: 321     evaluation reward: 7.53\n",
      "episode: 2523   score: 7.0   memory length: 616708   epsilon: 0.5091264500002262    steps: 402     evaluation reward: 7.55\n",
      "episode: 2524   score: 9.0   memory length: 617158   epsilon: 0.5086989500002264    steps: 450     evaluation reward: 7.58\n",
      "episode: 2525   score: 6.0   memory length: 617506   epsilon: 0.5083683500002265    steps: 348     evaluation reward: 7.59\n",
      "episode: 2526   score: 2.0   memory length: 617690   epsilon: 0.5081935500002266    steps: 184     evaluation reward: 7.49\n",
      "episode: 2527   score: 7.0   memory length: 618087   epsilon: 0.5078164000002268    steps: 397     evaluation reward: 7.48\n",
      "episode: 2528   score: 4.0   memory length: 618381   epsilon: 0.5075371000002269    steps: 294     evaluation reward: 7.48\n",
      "episode: 2529   score: 8.0   memory length: 618845   epsilon: 0.5070963000002271    steps: 464     evaluation reward: 7.49\n",
      "episode: 2530   score: 7.0   memory length: 619204   epsilon: 0.5067552500002273    steps: 359     evaluation reward: 7.49\n",
      "episode: 2531   score: 10.0   memory length: 619693   epsilon: 0.5062907000002275    steps: 489     evaluation reward: 7.55\n",
      "episode: 2532   score: 10.0   memory length: 620195   epsilon: 0.5058138000002277    steps: 502     evaluation reward: 7.62\n",
      "episode: 2533   score: 6.0   memory length: 620528   epsilon: 0.5054974500002278    steps: 333     evaluation reward: 7.56\n",
      "episode: 2534   score: 4.0   memory length: 620787   epsilon: 0.505251400000228    steps: 259     evaluation reward: 7.55\n",
      "episode: 2535   score: 8.0   memory length: 621199   epsilon: 0.5048600000002281    steps: 412     evaluation reward: 7.54\n",
      "episode: 2536   score: 5.0   memory length: 621514   epsilon: 0.5045607500002283    steps: 315     evaluation reward: 7.52\n",
      "episode: 2537   score: 7.0   memory length: 621915   epsilon: 0.5041798000002284    steps: 401     evaluation reward: 7.53\n",
      "episode: 2538   score: 4.0   memory length: 622159   epsilon: 0.5039480000002285    steps: 244     evaluation reward: 7.5\n",
      "episode: 2539   score: 10.0   memory length: 622720   epsilon: 0.5034150500002288    steps: 561     evaluation reward: 7.52\n",
      "episode: 2540   score: 11.0   memory length: 623124   epsilon: 0.503031250000229    steps: 404     evaluation reward: 7.59\n",
      "episode: 2541   score: 9.0   memory length: 623631   epsilon: 0.5025496000002292    steps: 507     evaluation reward: 7.63\n",
      "episode: 2542   score: 7.0   memory length: 624026   epsilon: 0.5021743500002294    steps: 395     evaluation reward: 7.68\n",
      "episode: 2543   score: 9.0   memory length: 624465   epsilon: 0.5017573000002296    steps: 439     evaluation reward: 7.73\n",
      "episode: 2544   score: 10.0   memory length: 624967   epsilon: 0.5012804000002298    steps: 502     evaluation reward: 7.73\n",
      "episode: 2545   score: 8.0   memory length: 625407   epsilon: 0.50086240000023    steps: 440     evaluation reward: 7.75\n",
      "episode: 2546   score: 4.0   memory length: 625672   epsilon: 0.5006106500002301    steps: 265     evaluation reward: 7.75\n",
      "episode: 2547   score: 12.0   memory length: 626124   epsilon: 0.5001812500002303    steps: 452     evaluation reward: 7.81\n",
      "episode: 2548   score: 11.0   memory length: 626566   epsilon: 0.4997613500002305    steps: 442     evaluation reward: 7.86\n",
      "episode: 2549   score: 18.0   memory length: 627056   epsilon: 0.4992958500002307    steps: 490     evaluation reward: 7.99\n",
      "episode: 2550   score: 8.0   memory length: 627487   epsilon: 0.4988864000002309    steps: 431     evaluation reward: 7.99\n",
      "episode: 2551   score: 14.0   memory length: 627909   epsilon: 0.49848550000023106    steps: 422     evaluation reward: 8.09\n",
      "episode: 2552   score: 8.0   memory length: 628336   epsilon: 0.49807985000023125    steps: 427     evaluation reward: 8.11\n",
      "episode: 2553   score: 9.0   memory length: 628808   epsilon: 0.49763145000023146    steps: 472     evaluation reward: 8.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2554   score: 10.0   memory length: 629175   epsilon: 0.4972828000002316    steps: 367     evaluation reward: 8.15\n",
      "episode: 2555   score: 10.0   memory length: 629692   epsilon: 0.49679165000023184    steps: 517     evaluation reward: 8.23\n",
      "episode: 2556   score: 5.0   memory length: 630026   epsilon: 0.496474350000232    steps: 334     evaluation reward: 8.22\n",
      "episode: 2557   score: 12.0   memory length: 630563   epsilon: 0.4959642000002322    steps: 537     evaluation reward: 8.28\n",
      "episode: 2558   score: 11.0   memory length: 631000   epsilon: 0.4955490500002324    steps: 437     evaluation reward: 8.35\n",
      "episode: 2559   score: 2.0   memory length: 631199   epsilon: 0.4953600000002325    steps: 199     evaluation reward: 8.27\n",
      "episode: 2560   score: 4.0   memory length: 631449   epsilon: 0.4951225000002326    steps: 250     evaluation reward: 8.24\n",
      "episode: 2561   score: 7.0   memory length: 631828   epsilon: 0.4947624500002328    steps: 379     evaluation reward: 8.24\n",
      "episode: 2562   score: 11.0   memory length: 632350   epsilon: 0.494266550000233    steps: 522     evaluation reward: 8.27\n",
      "episode: 2563   score: 12.0   memory length: 632818   epsilon: 0.4938219500002332    steps: 468     evaluation reward: 8.34\n",
      "episode: 2564   score: 10.0   memory length: 633181   epsilon: 0.49347710000023337    steps: 363     evaluation reward: 8.32\n",
      "episode: 2565   score: 11.0   memory length: 633571   epsilon: 0.49310660000023354    steps: 390     evaluation reward: 8.34\n",
      "episode: 2566   score: 4.0   memory length: 633895   epsilon: 0.4927988000002337    steps: 324     evaluation reward: 8.31\n",
      "episode: 2567   score: 14.0   memory length: 634430   epsilon: 0.4922905500002339    steps: 535     evaluation reward: 8.3\n",
      "episode: 2568   score: 10.0   memory length: 634817   epsilon: 0.4919229000002341    steps: 387     evaluation reward: 8.36\n",
      "episode: 2569   score: 4.0   memory length: 635097   epsilon: 0.4916569000002342    steps: 280     evaluation reward: 8.36\n",
      "episode: 2570   score: 5.0   memory length: 635414   epsilon: 0.49135575000023435    steps: 317     evaluation reward: 8.3\n",
      "episode: 2571   score: 7.0   memory length: 635834   epsilon: 0.49095675000023453    steps: 420     evaluation reward: 8.28\n",
      "episode: 2572   score: 9.0   memory length: 636162   epsilon: 0.4906451500002347    steps: 328     evaluation reward: 8.24\n",
      "episode: 2573   score: 15.0   memory length: 636733   epsilon: 0.4901027000002349    steps: 571     evaluation reward: 8.33\n",
      "episode: 2574   score: 2.0   memory length: 636957   epsilon: 0.489889900000235    steps: 224     evaluation reward: 8.3\n",
      "episode: 2575   score: 4.0   memory length: 637231   epsilon: 0.48962960000023514    steps: 274     evaluation reward: 8.27\n",
      "episode: 2576   score: 5.0   memory length: 637538   epsilon: 0.4893379500002353    steps: 307     evaluation reward: 8.26\n",
      "episode: 2577   score: 4.0   memory length: 637819   epsilon: 0.4890710000002354    steps: 281     evaluation reward: 8.19\n",
      "episode: 2578   score: 6.0   memory length: 638170   epsilon: 0.48873755000023555    steps: 351     evaluation reward: 8.2\n",
      "episode: 2579   score: 6.0   memory length: 638529   epsilon: 0.4883965000002357    steps: 359     evaluation reward: 8.09\n",
      "episode: 2580   score: 15.0   memory length: 639075   epsilon: 0.48787780000023595    steps: 546     evaluation reward: 8.21\n",
      "episode: 2581   score: 7.0   memory length: 639449   epsilon: 0.4875225000002361    steps: 374     evaluation reward: 8.2\n",
      "episode: 2582   score: 15.0   memory length: 639922   epsilon: 0.4870731500002363    steps: 473     evaluation reward: 8.26\n",
      "episode: 2583   score: 12.0   memory length: 640456   epsilon: 0.48656585000023655    steps: 534     evaluation reward: 8.34\n",
      "episode: 2584   score: 8.0   memory length: 640881   epsilon: 0.48616210000023674    steps: 425     evaluation reward: 8.37\n",
      "episode: 2585   score: 8.0   memory length: 641339   epsilon: 0.48572700000023694    steps: 458     evaluation reward: 8.36\n",
      "episode: 2586   score: 15.0   memory length: 641897   epsilon: 0.4851969000002372    steps: 558     evaluation reward: 8.42\n",
      "episode: 2587   score: 7.0   memory length: 642256   epsilon: 0.48485585000023734    steps: 359     evaluation reward: 8.43\n",
      "episode: 2588   score: 7.0   memory length: 642663   epsilon: 0.4844692000002375    steps: 407     evaluation reward: 8.41\n",
      "episode: 2589   score: 8.0   memory length: 643103   epsilon: 0.4840512000002377    steps: 440     evaluation reward: 8.45\n",
      "episode: 2590   score: 8.0   memory length: 643503   epsilon: 0.4836712000002379    steps: 400     evaluation reward: 8.4\n",
      "episode: 2591   score: 5.0   memory length: 643810   epsilon: 0.483379550000238    steps: 307     evaluation reward: 8.29\n",
      "episode: 2592   score: 6.0   memory length: 644188   epsilon: 0.4830204500002382    steps: 378     evaluation reward: 8.26\n",
      "episode: 2593   score: 12.0   memory length: 644802   epsilon: 0.48243715000023846    steps: 614     evaluation reward: 8.31\n",
      "episode: 2594   score: 5.0   memory length: 645111   epsilon: 0.4821436000002386    steps: 309     evaluation reward: 8.27\n",
      "episode: 2595   score: 5.0   memory length: 645446   epsilon: 0.48182535000023874    steps: 335     evaluation reward: 8.22\n",
      "episode: 2596   score: 10.0   memory length: 645993   epsilon: 0.481305700000239    steps: 547     evaluation reward: 8.17\n",
      "episode: 2597   score: 6.0   memory length: 646344   epsilon: 0.48097225000023913    steps: 351     evaluation reward: 8.15\n",
      "episode: 2598   score: 7.0   memory length: 646702   epsilon: 0.4806321500002393    steps: 358     evaluation reward: 8.13\n",
      "episode: 2599   score: 10.0   memory length: 647187   epsilon: 0.4801714000002395    steps: 485     evaluation reward: 8.16\n",
      "episode: 2600   score: 18.0   memory length: 647878   epsilon: 0.4795149500002398    steps: 691     evaluation reward: 8.24\n",
      "episode: 2601   score: 9.0   memory length: 648236   epsilon: 0.47917485000023996    steps: 358     evaluation reward: 8.27\n",
      "episode: 2602   score: 16.0   memory length: 648735   epsilon: 0.4787008000002402    steps: 499     evaluation reward: 8.33\n",
      "episode: 2603   score: 10.0   memory length: 649190   epsilon: 0.4782685500002404    steps: 455     evaluation reward: 8.31\n",
      "episode: 2604   score: 2.0   memory length: 649406   epsilon: 0.4780633500002405    steps: 216     evaluation reward: 8.25\n",
      "episode: 2605   score: 8.0   memory length: 649875   epsilon: 0.4776178000002407    steps: 469     evaluation reward: 8.23\n",
      "now time :  2018-12-14 10:56:19.013791\n",
      "episode: 2606   score: 16.0   memory length: 650364   epsilon: 0.4771532500002409    steps: 489     evaluation reward: 8.34\n",
      "episode: 2607   score: 11.0   memory length: 650955   epsilon: 0.47659180000024115    steps: 591     evaluation reward: 8.35\n",
      "episode: 2608   score: 9.0   memory length: 651435   epsilon: 0.47613580000024136    steps: 480     evaluation reward: 8.4\n",
      "episode: 2609   score: 5.0   memory length: 651755   epsilon: 0.4758318000002415    steps: 320     evaluation reward: 8.36\n",
      "episode: 2610   score: 5.0   memory length: 652066   epsilon: 0.47553635000024164    steps: 311     evaluation reward: 8.29\n",
      "episode: 2611   score: 7.0   memory length: 652475   epsilon: 0.4751478000002418    steps: 409     evaluation reward: 8.28\n",
      "episode: 2612   score: 9.0   memory length: 652889   epsilon: 0.474754500000242    steps: 414     evaluation reward: 8.33\n",
      "episode: 2613   score: 4.0   memory length: 653188   epsilon: 0.4744704500002421    steps: 299     evaluation reward: 8.28\n",
      "episode: 2614   score: 8.0   memory length: 653605   epsilon: 0.4740743000002423    steps: 417     evaluation reward: 8.31\n",
      "episode: 2615   score: 6.0   memory length: 653952   epsilon: 0.47374465000024246    steps: 347     evaluation reward: 8.28\n",
      "episode: 2616   score: 11.0   memory length: 654473   epsilon: 0.4732497000002427    steps: 521     evaluation reward: 8.32\n",
      "episode: 2617   score: 8.0   memory length: 654876   epsilon: 0.47286685000024287    steps: 403     evaluation reward: 8.33\n",
      "episode: 2618   score: 9.0   memory length: 655209   epsilon: 0.472550500000243    steps: 333     evaluation reward: 8.29\n",
      "episode: 2619   score: 11.0   memory length: 655643   epsilon: 0.4721382000002432    steps: 434     evaluation reward: 8.3\n",
      "episode: 2620   score: 11.0   memory length: 656173   epsilon: 0.47163470000024343    steps: 530     evaluation reward: 8.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2621   score: 5.0   memory length: 656508   epsilon: 0.4713164500002436    steps: 335     evaluation reward: 8.31\n",
      "episode: 2622   score: 12.0   memory length: 656985   epsilon: 0.4708633000002438    steps: 477     evaluation reward: 8.38\n",
      "episode: 2623   score: 15.0   memory length: 657436   epsilon: 0.470434850000244    steps: 451     evaluation reward: 8.46\n",
      "episode: 2624   score: 10.0   memory length: 657933   epsilon: 0.4699627000002442    steps: 497     evaluation reward: 8.47\n",
      "episode: 2625   score: 12.0   memory length: 658347   epsilon: 0.4695694000002444    steps: 414     evaluation reward: 8.53\n",
      "episode: 2626   score: 11.0   memory length: 658921   epsilon: 0.46902410000024464    steps: 574     evaluation reward: 8.62\n",
      "episode: 2627   score: 10.0   memory length: 659399   epsilon: 0.46857000000024485    steps: 478     evaluation reward: 8.65\n",
      "episode: 2628   score: 20.0   memory length: 660130   epsilon: 0.46787555000024517    steps: 731     evaluation reward: 8.81\n",
      "episode: 2629   score: 12.0   memory length: 660614   epsilon: 0.4674157500002454    steps: 484     evaluation reward: 8.85\n",
      "episode: 2630   score: 15.0   memory length: 661344   epsilon: 0.4667222500002457    steps: 730     evaluation reward: 8.93\n",
      "episode: 2631   score: 2.0   memory length: 661533   epsilon: 0.4665427000002458    steps: 189     evaluation reward: 8.85\n",
      "episode: 2632   score: 4.0   memory length: 661804   epsilon: 0.4662852500002459    steps: 271     evaluation reward: 8.79\n",
      "episode: 2633   score: 8.0   memory length: 662100   epsilon: 0.46600405000024603    steps: 296     evaluation reward: 8.81\n",
      "episode: 2634   score: 13.0   memory length: 662644   epsilon: 0.46548725000024627    steps: 544     evaluation reward: 8.9\n",
      "episode: 2635   score: 8.0   memory length: 662953   epsilon: 0.4651937000002464    steps: 309     evaluation reward: 8.9\n",
      "episode: 2636   score: 13.0   memory length: 663543   epsilon: 0.46463320000024666    steps: 590     evaluation reward: 8.98\n",
      "episode: 2637   score: 6.0   memory length: 663883   epsilon: 0.4643102000002468    steps: 340     evaluation reward: 8.97\n",
      "episode: 2638   score: 14.0   memory length: 664395   epsilon: 0.46382380000024703    steps: 512     evaluation reward: 9.07\n",
      "episode: 2639   score: 8.0   memory length: 664837   epsilon: 0.4634039000002472    steps: 442     evaluation reward: 9.05\n",
      "episode: 2640   score: 6.0   memory length: 665230   epsilon: 0.4630305500002474    steps: 393     evaluation reward: 9.0\n",
      "episode: 2641   score: 7.0   memory length: 665595   epsilon: 0.46268380000024756    steps: 365     evaluation reward: 8.98\n",
      "episode: 2642   score: 7.0   memory length: 666033   epsilon: 0.46226770000024775    steps: 438     evaluation reward: 8.98\n",
      "episode: 2643   score: 9.0   memory length: 666495   epsilon: 0.46182880000024795    steps: 462     evaluation reward: 8.98\n",
      "episode: 2644   score: 5.0   memory length: 666820   epsilon: 0.4615200500002481    steps: 325     evaluation reward: 8.93\n",
      "episode: 2645   score: 17.0   memory length: 667472   epsilon: 0.4609006500002484    steps: 652     evaluation reward: 9.02\n",
      "episode: 2646   score: 6.0   memory length: 667829   epsilon: 0.46056150000024854    steps: 357     evaluation reward: 9.04\n",
      "episode: 2647   score: 9.0   memory length: 668345   epsilon: 0.46007130000024876    steps: 516     evaluation reward: 9.01\n",
      "episode: 2648   score: 3.0   memory length: 668575   epsilon: 0.45985280000024886    steps: 230     evaluation reward: 8.93\n",
      "episode: 2649   score: 6.0   memory length: 668952   epsilon: 0.459494650000249    steps: 377     evaluation reward: 8.81\n",
      "episode: 2650   score: 6.0   memory length: 669326   epsilon: 0.4591393500002492    steps: 374     evaluation reward: 8.79\n",
      "episode: 2651   score: 14.0   memory length: 669884   epsilon: 0.45860925000024944    steps: 558     evaluation reward: 8.79\n",
      "episode: 2652   score: 2.0   memory length: 670067   epsilon: 0.4584354000002495    steps: 183     evaluation reward: 8.73\n",
      "episode: 2653   score: 9.0   memory length: 670538   epsilon: 0.4579879500002497    steps: 471     evaluation reward: 8.73\n",
      "episode: 2654   score: 8.0   memory length: 670968   epsilon: 0.4575794500002499    steps: 430     evaluation reward: 8.71\n",
      "episode: 2655   score: 5.0   memory length: 671288   epsilon: 0.45727545000025005    steps: 320     evaluation reward: 8.66\n",
      "episode: 2656   score: 11.0   memory length: 671812   epsilon: 0.4567776500002503    steps: 524     evaluation reward: 8.72\n",
      "episode: 2657   score: 9.0   memory length: 672197   epsilon: 0.45641190000025045    steps: 385     evaluation reward: 8.69\n",
      "episode: 2658   score: 7.0   memory length: 672464   epsilon: 0.45615825000025056    steps: 267     evaluation reward: 8.65\n",
      "episode: 2659   score: 14.0   memory length: 672836   epsilon: 0.4558048500002507    steps: 372     evaluation reward: 8.77\n",
      "episode: 2660   score: 10.0   memory length: 673226   epsilon: 0.4554343500002509    steps: 390     evaluation reward: 8.83\n",
      "episode: 2661   score: 9.0   memory length: 673626   epsilon: 0.4550543500002511    steps: 400     evaluation reward: 8.85\n",
      "episode: 2662   score: 8.0   memory length: 674021   epsilon: 0.45467910000025125    steps: 395     evaluation reward: 8.82\n",
      "episode: 2663   score: 9.0   memory length: 674502   epsilon: 0.45422215000025146    steps: 481     evaluation reward: 8.79\n",
      "episode: 2664   score: 9.0   memory length: 674977   epsilon: 0.45377090000025166    steps: 475     evaluation reward: 8.78\n",
      "episode: 2665   score: 11.0   memory length: 675531   epsilon: 0.4532446000002519    steps: 554     evaluation reward: 8.78\n",
      "episode: 2666   score: 9.0   memory length: 675960   epsilon: 0.4528370500002521    steps: 429     evaluation reward: 8.83\n",
      "episode: 2667   score: 7.0   memory length: 676370   epsilon: 0.4524475500002523    steps: 410     evaluation reward: 8.76\n",
      "episode: 2668   score: 5.0   memory length: 676706   epsilon: 0.4521283500002524    steps: 336     evaluation reward: 8.71\n",
      "episode: 2669   score: 4.0   memory length: 676965   epsilon: 0.45188230000025253    steps: 259     evaluation reward: 8.71\n",
      "episode: 2670   score: 7.0   memory length: 677337   epsilon: 0.4515289000002527    steps: 372     evaluation reward: 8.73\n",
      "episode: 2671   score: 5.0   memory length: 677661   epsilon: 0.45122110000025284    steps: 324     evaluation reward: 8.71\n",
      "episode: 2672   score: 16.0   memory length: 678148   epsilon: 0.45075845000025305    steps: 487     evaluation reward: 8.78\n",
      "episode: 2673   score: 3.0   memory length: 678382   epsilon: 0.45053615000025315    steps: 234     evaluation reward: 8.66\n",
      "episode: 2674   score: 19.0   memory length: 678971   epsilon: 0.4499766000002534    steps: 589     evaluation reward: 8.83\n",
      "episode: 2675   score: 7.0   memory length: 679372   epsilon: 0.4495956500002536    steps: 401     evaluation reward: 8.86\n",
      "episode: 2676   score: 12.0   memory length: 679812   epsilon: 0.4491776500002538    steps: 440     evaluation reward: 8.93\n",
      "episode: 2677   score: 4.0   memory length: 680118   epsilon: 0.4488869500002539    steps: 306     evaluation reward: 8.93\n",
      "episode: 2678   score: 3.0   memory length: 680331   epsilon: 0.448684600000254    steps: 213     evaluation reward: 8.9\n",
      "episode: 2679   score: 12.0   memory length: 680929   epsilon: 0.44811650000025427    steps: 598     evaluation reward: 8.96\n",
      "episode: 2680   score: 9.0   memory length: 681404   epsilon: 0.4476652500002545    steps: 475     evaluation reward: 8.9\n",
      "episode: 2681   score: 12.0   memory length: 681943   epsilon: 0.4471532000002547    steps: 539     evaluation reward: 8.95\n",
      "episode: 2682   score: 9.0   memory length: 682281   epsilon: 0.44683210000025486    steps: 338     evaluation reward: 8.89\n",
      "episode: 2683   score: 4.0   memory length: 682542   epsilon: 0.446584150000255    steps: 261     evaluation reward: 8.81\n",
      "episode: 2684   score: 11.0   memory length: 682994   epsilon: 0.4461547500002552    steps: 452     evaluation reward: 8.84\n",
      "episode: 2685   score: 11.0   memory length: 683536   epsilon: 0.4456398500002554    steps: 542     evaluation reward: 8.87\n",
      "episode: 2686   score: 10.0   memory length: 683951   epsilon: 0.4452456000002556    steps: 415     evaluation reward: 8.82\n",
      "episode: 2687   score: 10.0   memory length: 684420   epsilon: 0.4448000500002558    steps: 469     evaluation reward: 8.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2688   score: 20.0   memory length: 685022   epsilon: 0.44422815000025606    steps: 602     evaluation reward: 8.98\n",
      "episode: 2689   score: 11.0   memory length: 685553   epsilon: 0.4437237000002563    steps: 531     evaluation reward: 9.01\n",
      "episode: 2690   score: 7.0   memory length: 686000   epsilon: 0.4432990500002565    steps: 447     evaluation reward: 9.0\n",
      "episode: 2691   score: 12.0   memory length: 686487   epsilon: 0.4428364000002567    steps: 487     evaluation reward: 9.07\n",
      "episode: 2692   score: 4.0   memory length: 686772   epsilon: 0.4425656500002568    steps: 285     evaluation reward: 9.05\n",
      "episode: 2693   score: 14.0   memory length: 687301   epsilon: 0.44206310000025706    steps: 529     evaluation reward: 9.07\n",
      "episode: 2694   score: 6.0   memory length: 687671   epsilon: 0.4417116000002572    steps: 370     evaluation reward: 9.08\n",
      "episode: 2695   score: 16.0   memory length: 688290   epsilon: 0.4411235500002575    steps: 619     evaluation reward: 9.19\n",
      "episode: 2696   score: 9.0   memory length: 688769   epsilon: 0.4406685000002577    steps: 479     evaluation reward: 9.18\n",
      "episode: 2697   score: 7.0   memory length: 689167   epsilon: 0.4402904000002579    steps: 398     evaluation reward: 9.19\n",
      "episode: 2698   score: 10.0   memory length: 689728   epsilon: 0.4397574500002581    steps: 561     evaluation reward: 9.22\n",
      "episode: 2699   score: 4.0   memory length: 690026   epsilon: 0.43947435000025825    steps: 298     evaluation reward: 9.16\n",
      "episode: 2700   score: 12.0   memory length: 690574   epsilon: 0.4389537500002585    steps: 548     evaluation reward: 9.1\n",
      "episode: 2701   score: 6.0   memory length: 690929   epsilon: 0.43861650000025865    steps: 355     evaluation reward: 9.07\n",
      "episode: 2702   score: 5.0   memory length: 691267   epsilon: 0.4382954000002588    steps: 338     evaluation reward: 8.96\n",
      "episode: 2703   score: 20.0   memory length: 691929   epsilon: 0.4376665000002591    steps: 662     evaluation reward: 9.06\n",
      "episode: 2704   score: 12.0   memory length: 692384   epsilon: 0.4372342500002593    steps: 455     evaluation reward: 9.16\n",
      "episode: 2705   score: 12.0   memory length: 692801   epsilon: 0.43683810000025947    steps: 417     evaluation reward: 9.2\n",
      "episode: 2706   score: 7.0   memory length: 693155   epsilon: 0.4365018000002596    steps: 354     evaluation reward: 9.11\n",
      "episode: 2707   score: 10.0   memory length: 693563   epsilon: 0.4361142000002598    steps: 408     evaluation reward: 9.1\n",
      "episode: 2708   score: 7.0   memory length: 693935   epsilon: 0.43576080000025996    steps: 372     evaluation reward: 9.08\n",
      "episode: 2709   score: 4.0   memory length: 694245   epsilon: 0.4354663000002601    steps: 310     evaluation reward: 9.07\n",
      "episode: 2710   score: 10.0   memory length: 694792   epsilon: 0.43494665000026034    steps: 547     evaluation reward: 9.12\n",
      "episode: 2711   score: 12.0   memory length: 695257   epsilon: 0.43450490000026054    steps: 465     evaluation reward: 9.17\n",
      "episode: 2712   score: 14.0   memory length: 695851   epsilon: 0.4339406000002608    steps: 594     evaluation reward: 9.22\n",
      "episode: 2713   score: 5.0   memory length: 696177   epsilon: 0.43363090000026094    steps: 326     evaluation reward: 9.23\n",
      "episode: 2714   score: 6.0   memory length: 696548   epsilon: 0.4332784500002611    steps: 371     evaluation reward: 9.21\n",
      "episode: 2715   score: 7.0   memory length: 696952   epsilon: 0.4328946500002613    steps: 404     evaluation reward: 9.22\n",
      "episode: 2716   score: 5.0   memory length: 697289   epsilon: 0.43257450000026143    steps: 337     evaluation reward: 9.16\n",
      "episode: 2717   score: 10.0   memory length: 697661   epsilon: 0.4322211000002616    steps: 372     evaluation reward: 9.18\n",
      "episode: 2718   score: 9.0   memory length: 698131   epsilon: 0.4317746000002618    steps: 470     evaluation reward: 9.18\n",
      "episode: 2719   score: 12.0   memory length: 698751   epsilon: 0.43118560000026207    steps: 620     evaluation reward: 9.19\n",
      "episode: 2720   score: 12.0   memory length: 699217   epsilon: 0.4307429000002623    steps: 466     evaluation reward: 9.2\n",
      "episode: 2721   score: 15.0   memory length: 699804   epsilon: 0.43018525000026253    steps: 587     evaluation reward: 9.3\n",
      "now time :  2018-12-14 11:19:27.204322\n",
      "episode: 2722   score: 9.0   memory length: 700248   epsilon: 0.4297634500002627    steps: 444     evaluation reward: 9.27\n",
      "episode: 2723   score: 10.0   memory length: 700709   epsilon: 0.4293255000002629    steps: 461     evaluation reward: 9.22\n",
      "episode: 2724   score: 6.0   memory length: 701054   epsilon: 0.4289977500002631    steps: 345     evaluation reward: 9.18\n",
      "episode: 2725   score: 20.0   memory length: 701545   epsilon: 0.4285313000002633    steps: 491     evaluation reward: 9.26\n",
      "episode: 2726   score: 6.0   memory length: 701910   epsilon: 0.42818455000026345    steps: 365     evaluation reward: 9.21\n",
      "episode: 2727   score: 19.0   memory length: 702375   epsilon: 0.42774280000026366    steps: 465     evaluation reward: 9.3\n",
      "episode: 2728   score: 8.0   memory length: 702799   epsilon: 0.42734000000026384    steps: 424     evaluation reward: 9.18\n",
      "episode: 2729   score: 4.0   memory length: 703088   epsilon: 0.42706545000026397    steps: 289     evaluation reward: 9.1\n",
      "episode: 2730   score: 10.0   memory length: 703626   epsilon: 0.4265543500002642    steps: 538     evaluation reward: 9.05\n",
      "episode: 2731   score: 10.0   memory length: 704133   epsilon: 0.4260727000002644    steps: 507     evaluation reward: 9.13\n",
      "episode: 2732   score: 14.0   memory length: 704743   epsilon: 0.4254932000002647    steps: 610     evaluation reward: 9.23\n",
      "episode: 2733   score: 5.0   memory length: 705065   epsilon: 0.42518730000026483    steps: 322     evaluation reward: 9.2\n",
      "episode: 2734   score: 7.0   memory length: 705465   epsilon: 0.424807300000265    steps: 400     evaluation reward: 9.14\n",
      "episode: 2735   score: 10.0   memory length: 705964   epsilon: 0.4243332500002652    steps: 499     evaluation reward: 9.16\n",
      "episode: 2736   score: 15.0   memory length: 706420   epsilon: 0.4239000500002654    steps: 456     evaluation reward: 9.18\n",
      "episode: 2737   score: 12.0   memory length: 706866   epsilon: 0.4234763500002656    steps: 446     evaluation reward: 9.24\n",
      "episode: 2738   score: 5.0   memory length: 707181   epsilon: 0.42317710000026576    steps: 315     evaluation reward: 9.15\n",
      "episode: 2739   score: 4.0   memory length: 707480   epsilon: 0.4228930500002659    steps: 299     evaluation reward: 9.11\n",
      "episode: 2740   score: 19.0   memory length: 707907   epsilon: 0.4224874000002661    steps: 427     evaluation reward: 9.24\n",
      "episode: 2741   score: 5.0   memory length: 708182   epsilon: 0.4222261500002662    steps: 275     evaluation reward: 9.22\n",
      "episode: 2742   score: 11.0   memory length: 708595   epsilon: 0.4218338000002664    steps: 413     evaluation reward: 9.26\n",
      "episode: 2743   score: 16.0   memory length: 709069   epsilon: 0.4213835000002666    steps: 474     evaluation reward: 9.33\n",
      "episode: 2744   score: 7.0   memory length: 709474   epsilon: 0.42099875000026676    steps: 405     evaluation reward: 9.35\n",
      "episode: 2745   score: 13.0   memory length: 710062   epsilon: 0.420440150000267    steps: 588     evaluation reward: 9.31\n",
      "episode: 2746   score: 10.0   memory length: 710559   epsilon: 0.41996800000026724    steps: 497     evaluation reward: 9.35\n",
      "episode: 2747   score: 10.0   memory length: 711072   epsilon: 0.41948065000026746    steps: 513     evaluation reward: 9.36\n",
      "episode: 2748   score: 7.0   memory length: 711451   epsilon: 0.41912060000026763    steps: 379     evaluation reward: 9.4\n",
      "episode: 2749   score: 12.0   memory length: 711977   epsilon: 0.41862090000026786    steps: 526     evaluation reward: 9.46\n",
      "episode: 2750   score: 18.0   memory length: 712411   epsilon: 0.41820860000026805    steps: 434     evaluation reward: 9.58\n",
      "episode: 2751   score: 10.0   memory length: 712789   epsilon: 0.4178495000002682    steps: 378     evaluation reward: 9.54\n",
      "episode: 2752   score: 6.0   memory length: 713157   epsilon: 0.4174999000002684    steps: 368     evaluation reward: 9.58\n",
      "episode: 2753   score: 5.0   memory length: 713460   epsilon: 0.4172120500002685    steps: 303     evaluation reward: 9.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2754   score: 13.0   memory length: 713936   epsilon: 0.4167598500002687    steps: 476     evaluation reward: 9.59\n",
      "episode: 2755   score: 21.0   memory length: 714448   epsilon: 0.41627345000026894    steps: 512     evaluation reward: 9.75\n",
      "episode: 2756   score: 3.0   memory length: 714694   epsilon: 0.41603975000026905    steps: 246     evaluation reward: 9.67\n",
      "episode: 2757   score: 11.0   memory length: 715104   epsilon: 0.41565025000026923    steps: 410     evaluation reward: 9.69\n",
      "episode: 2758   score: 11.0   memory length: 715518   epsilon: 0.4152569500002694    steps: 414     evaluation reward: 9.73\n",
      "episode: 2759   score: 15.0   memory length: 716086   epsilon: 0.41471735000026966    steps: 568     evaluation reward: 9.74\n",
      "episode: 2760   score: 10.0   memory length: 716611   epsilon: 0.4142186000002699    steps: 525     evaluation reward: 9.74\n",
      "episode: 2761   score: 17.0   memory length: 717132   epsilon: 0.4137236500002701    steps: 521     evaluation reward: 9.82\n",
      "episode: 2762   score: 13.0   memory length: 717649   epsilon: 0.41323250000027034    steps: 517     evaluation reward: 9.87\n",
      "episode: 2763   score: 9.0   memory length: 718084   epsilon: 0.41281925000027053    steps: 435     evaluation reward: 9.87\n",
      "episode: 2764   score: 10.0   memory length: 718435   epsilon: 0.4124858000002707    steps: 351     evaluation reward: 9.88\n",
      "episode: 2765   score: 5.0   memory length: 718751   epsilon: 0.4121856000002708    steps: 316     evaluation reward: 9.82\n",
      "episode: 2766   score: 7.0   memory length: 719140   epsilon: 0.411816050000271    steps: 389     evaluation reward: 9.8\n",
      "episode: 2767   score: 4.0   memory length: 719401   epsilon: 0.4115681000002711    steps: 261     evaluation reward: 9.77\n",
      "episode: 2768   score: 15.0   memory length: 719981   epsilon: 0.41101710000027136    steps: 580     evaluation reward: 9.87\n",
      "episode: 2769   score: 5.0   memory length: 720273   epsilon: 0.4107397000002715    steps: 292     evaluation reward: 9.88\n",
      "episode: 2770   score: 6.0   memory length: 720634   epsilon: 0.41039675000027165    steps: 361     evaluation reward: 9.87\n",
      "episode: 2771   score: 3.0   memory length: 720869   epsilon: 0.41017350000027175    steps: 235     evaluation reward: 9.85\n",
      "episode: 2772   score: 8.0   memory length: 721179   epsilon: 0.4098790000002719    steps: 310     evaluation reward: 9.77\n",
      "episode: 2773   score: 11.0   memory length: 721593   epsilon: 0.40948570000027207    steps: 414     evaluation reward: 9.85\n",
      "episode: 2774   score: 7.0   memory length: 721972   epsilon: 0.40912565000027223    steps: 379     evaluation reward: 9.73\n",
      "episode: 2775   score: 12.0   memory length: 722282   epsilon: 0.40883115000027237    steps: 310     evaluation reward: 9.78\n",
      "episode: 2776   score: 14.0   memory length: 722887   epsilon: 0.40825640000027263    steps: 605     evaluation reward: 9.8\n",
      "episode: 2777   score: 17.0   memory length: 723341   epsilon: 0.40782510000027283    steps: 454     evaluation reward: 9.93\n",
      "episode: 2778   score: 8.0   memory length: 723762   epsilon: 0.407425150000273    steps: 421     evaluation reward: 9.98\n",
      "episode: 2779   score: 11.0   memory length: 724218   epsilon: 0.4069919500002732    steps: 456     evaluation reward: 9.97\n",
      "episode: 2780   score: 6.0   memory length: 724554   epsilon: 0.40667275000027336    steps: 336     evaluation reward: 9.94\n",
      "episode: 2781   score: 9.0   memory length: 725013   epsilon: 0.40623670000027357    steps: 459     evaluation reward: 9.91\n",
      "episode: 2782   score: 8.0   memory length: 725396   epsilon: 0.40587285000027373    steps: 383     evaluation reward: 9.9\n",
      "episode: 2783   score: 10.0   memory length: 725825   epsilon: 0.4054653000002739    steps: 429     evaluation reward: 9.96\n",
      "episode: 2784   score: 19.0   memory length: 726402   epsilon: 0.4049171500002742    steps: 577     evaluation reward: 10.04\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './save_model/breakout_dqn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c5ecc691b42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# stop training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_reward\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./save_model/breakout_dqn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './save_model/breakout_dqn'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "        if render_breakout:\n",
    "            env.render()\n",
    "\n",
    "        # Select and perform an action\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "\n",
    "        \n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "\n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['ale.lives'])\n",
    "\n",
    "        life = info['ale.lives']\n",
    "        r = np.clip(reward, -1, 1)\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network\n",
    "            if(frame % Update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "\n",
    "        if frame % 50000 == 0:\n",
    "            print('now time : ', datetime.now())\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\")\n",
    "\n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 400\n",
    "            # stop training\n",
    "            if np.mean(evaluation_reward) > 10:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn\")\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
