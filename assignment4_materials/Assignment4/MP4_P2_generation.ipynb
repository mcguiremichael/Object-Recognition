{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn.model import RNN\n",
    "from rnn.helpers import time_since\n",
    "from rnn.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 4573338\n",
      "train len:  4116004\n",
      "test len:  457334\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file_path = './shakespeare.txt'\n",
    "file = unidecode.unidecode(open(file_path).read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n",
    "\n",
    "# we will leave the last 1/10th of text as test\n",
    "split = int(0.9*file_len)\n",
    "train_text = file[:split]\n",
    "test_text = file[split:]\n",
    "\n",
    "print('train len: ', len(train_text))\n",
    "print('test len: ', len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France hath in thee found out\n",
      "A nest of hollow bosoms, which he fills\n",
      "With treacherous crowns; and three corrupted men,\n",
      "One, Richard Earl of Cambridge, and the second,\n",
      "Henry Lord Scroop of Masham, and \n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk(text):\n",
    "    start_index = random.randint(0, len(text) - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "print(random_chunk(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make training samples out of the large string of text data, we will be splitting the text into chunks.\n",
    "\n",
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string), requires_grad=True).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function loads a batch of input and target tensors for training. Each sample comes from a random chunk of text. A sample input will consist of all characters *except the last*, while the target wil contain all characters *following the first*. For example: if random_chunk='abc', then input='ab' and target='bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_batch(text, chunk_len, batch_size):\n",
    "    input_data = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    target = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    for i in range(batch_size):\n",
    "        start_index = random.randint(0, len(text) - chunk_len - 1)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = text[start_index:end_index]\n",
    "        input_data[i] = char_tensor(chunk[:-1])\n",
    "        target[i] = char_tensor(chunk[1:])\n",
    "    return input_data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement model\n",
    "\n",
    "Your RNN model will take as input the character for step $t_{-1}$ and output a prediction for the next character $t$. The model should consiste of three layers - a linear layer that encodes the input character into an embedded state, an RNN layer (which may itself have multiple layers) that operates on that embedded state and a hidden state, and a decoder layer that outputs the predicted character scores distribution.\n",
    "\n",
    "\n",
    "You must implement your model in the `rnn/model.py` file. You should use a `nn.Embedding` object for the encoding layer, a RNN model like `nn.RNN` or `nn.LSTM`, and a `nn.Linear` layer for the final a predicted character score decoding layer.\n",
    "\n",
    "\n",
    "**TODO:** Implement the model in RNN `rnn/model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n",
    "\n",
    "\n",
    "Note that in the `evaluate` function, every time a prediction is made the outputs are divided by the \"temperature\" argument. Higher temperature values make actions more equally likely giving more \"random\" outputs. Lower temperature values (less than 1) high likelihood options contribute more. A temperature near 0 outputs only the most likely outputs.\n",
    "\n",
    "You may check different temperature values yourself, but we have provided a default which should work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(rnn, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.init_hidden(1, device=device)\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = rnn(prime_input[p].unsqueeze(0).to(device), hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp.unsqueeze(0).to(device), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 5000\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "learning_rate = 0.01\n",
    "model_type = 'rnn'\n",
    "print_every = 50\n",
    "plot_every = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(rnn, inp, target):\n",
    "    with torch.no_grad():\n",
    "        hidden = rnn.init_hidden(batch_size, device=device)\n",
    "        loss = 0\n",
    "        for c in range(chunk_len):\n",
    "            output, hidden = rnn(inp[:,c], hidden)\n",
    "            loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "    \n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function\n",
    "\n",
    "**TODO**: Fill in the train function. You should initialize a hidden layer representation using your RNN's `init_hidden` function, set the model gradients to zero, and loop over each time step (character) in the input tensor. For each time step compute the output of the of the RNN and compute the loss over the output and the corresponding ground truth time step in `target`. The loss should be averaged over all time steps. Lastly, call backward on the averaged loss and take an optimizer step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, input, target, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - rnn: model\n",
    "    - input: input character data tensor of shape (batch_size, chunk_len)\n",
    "    - target: target character data tensor of shape (batch_size, chunk_len)\n",
    "    - optimizer: rnn model optimizer\n",
    "    - criterion: loss function\n",
    "    \n",
    "    Returns:\n",
    "    - loss: computed loss value as python float\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "    batch_size, length = input.shape\n",
    "    \n",
    "    hidden_start = rnn.init_hidden(batch_size, device)\n",
    "    hidden = hidden_start\n",
    "    \n",
    "    running_loss = torch.zeros((1)).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(length):\n",
    "        \n",
    "        curr_input = input[:,i]\n",
    "        curr_target = target[:,i]\n",
    "        output, hidden = rnn(curr_input, hidden)\n",
    "        \n",
    "        running_loss += criterion(output.view(batch_size, -1), curr_target.view(batch_size))\n",
    "        \n",
    "    running_loss /= length\n",
    "    running_loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = running_loss.data.cpu().numpy()[0]\n",
    "    ##########       END      ##########\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "[0m 32s (50 1%) train loss: 2.1005, test_loss: 2.1139]\n",
      "Whe lord well of wlot the ingle thou my for af yerthire! You it man not the on shenest this rut her pu \n",
      "\n",
      "[1m 4s (100 2%) train loss: 1.9514, test_loss: 1.9704]\n",
      "Why, mine indich what song.\n",
      "I with rive and is are mun\n",
      "Marined fors,\n",
      "Of the in ever.\n",
      "\n",
      "BAONO:\n",
      "Nout of G \n",
      "\n",
      "[1m 35s (150 3%) train loss: 1.8797, test_loss: 1.8857]\n",
      "Whight,\n",
      "Be coulds\n",
      "Nowes\n",
      "So the comblet of this, gort\n",
      "thou out in tell me?\n",
      "\n",
      "PENCENTIO:\n",
      "In a dead, I the \n",
      "\n",
      "[2m 6s (200 4%) train loss: 1.8303, test_loss: 1.8304]\n",
      "When made, what like min;\n",
      "'Thee, I'll ness thee your mait seaving at thus therey nike whou of may that \n",
      "\n",
      "[2m 37s (250 5%) train loss: 1.7663, test_loss: 1.8151]\n",
      "What reat of capuner, like thee rout had a vill Cast my faint from not you wich me bouns the purpost t \n",
      "\n",
      "[3m 9s (300 6%) train loss: 1.7488, test_loss: 1.7952]\n",
      "What vore thou up leftles, fere\n",
      "And he dection see the brentle, you affes,\n",
      "Warwind. I kind, all entent \n",
      "\n",
      "[3m 40s (350 7%) train loss: 1.7336, test_loss: 1.7837]\n",
      "Whath thine meliver of his mis may,\n",
      "He to is the Frestant will good now not thou have the love.\n",
      "\n",
      "PARDE \n",
      "\n",
      "[4m 10s (400 8%) train loss: 1.7316, test_loss: 1.7643]\n",
      "Whirt.\n",
      "\n",
      "BARTRORPRIONES:\n",
      "Is did the love.\n",
      "\n",
      "DOM:\n",
      "Gristress and harcust, which the nows in under that han \n",
      "\n",
      "[4m 39s (450 9%) train loss: 1.6950, test_loss: 1.7714]\n",
      "Whe more came you are a fier for, I have able call and as mucties:\n",
      "He't have countigiond, like the art \n",
      "\n",
      "[5m 8s (500 10%) train loss: 1.7032, test_loss: 1.7728]\n",
      "Whe give this quess reture perfieterating for I will comes hand can one, like I slect and be have made \n",
      "\n",
      "[5m 37s (550 11%) train loss: 1.6816, test_loss: 1.7451]\n",
      "When his little me we the brent me sound well and pataly as the part;\n",
      "It will were sword of coold monn \n",
      "\n",
      "[6m 5s (600 12%) train loss: 1.6976, test_loss: 1.7456]\n",
      "Whe,\n",
      "First shis my cordest and not that did proptaine faren of foer-prain anate is this poiffes gring. \n",
      "\n",
      "[6m 34s (650 13%) train loss: 1.6912, test_loss: 1.7595]\n",
      "What of here the ear.\n",
      "\n",
      "PORTINE:\n",
      "Whes I scant much the lovess to the\n",
      "Toguring never gods look of a matt \n",
      "\n",
      "[7m 4s (700 14%) train loss: 1.6895, test_loss: 1.7651]\n",
      "What\n",
      "king, them, or in solenger me, do thears, by is in lind, mine of this be nor sint hath the folds  \n",
      "\n",
      "[7m 36s (750 15%) train loss: 1.7114, test_loss: 1.7601]\n",
      "Whe\n",
      "done;\n",
      "We find there in this hand, thee thear and obedalat, and no forborn, and fine of the old ous \n",
      "\n",
      "[8m 7s (800 16%) train loss: 1.6777, test_loss: 1.7430]\n",
      "Whes mick and the well my soldition:\n",
      "I meer, and have place to the larsion?\n",
      "\n",
      "BERILLIA:\n",
      "Stoing you wife \n",
      "\n",
      "[8m 39s (850 17%) train loss: 1.6495, test_loss: 1.7140]\n",
      "Where him, for the ence, who the redwed's destrain to dogrolls\n",
      "way at thou seald may a berear and plai \n",
      "\n",
      "[9m 11s (900 18%) train loss: 1.6510, test_loss: 1.7326]\n",
      "While the preans upon the very had not me, the place of the ratur not shand.\n",
      "\n",
      "Ollmestily blood.\n",
      "\n",
      "CMART \n",
      "\n",
      "[9m 42s (950 19%) train loss: 1.6466, test_loss: 1.7251]\n",
      "What shures o'er be prince no resol'st of your proflones, orn thy love.\n",
      "\n",
      "HENRY V:\n",
      "Thou furthe lissed b \n",
      "\n",
      "[10m 11s (1000 20%) train loss: 1.6519, test_loss: 1.7406]\n",
      "Whe were some that spite, there't dumes\n",
      "Our brouthouse the go to abord to bed good then sather to the  \n",
      "\n",
      "[10m 42s (1050 21%) train loss: 1.6944, test_loss: 1.7507]\n",
      "Whe was that waighted to the light; falsil will wommy enance\n",
      "How when sell.\n",
      "\n",
      "KING HENRY VIIUS:\n",
      "Without \n",
      "\n",
      "[11m 11s (1100 22%) train loss: 1.6512, test_loss: 1.7236]\n",
      "Whem say; it too.\n",
      "\n",
      "LAFEU:\n",
      "I may the drowndity: I shall she-better or you think, and ented for wast the \n",
      "\n",
      "[11m 41s (1150 23%) train loss: 1.6654, test_loss: 1.7458]\n",
      "Where her not from confus not of greet him in the discame. Evedged.\n",
      "\n",
      "PETRUDIUS:\n",
      "And hend they deetunat \n",
      "\n",
      "[12m 10s (1200 24%) train loss: 1.6655, test_loss: 1.7207]\n",
      "What the tencelie will daim care,\n",
      "And mysmentious bloody in the came my wits of thy were a sweether th \n",
      "\n",
      "[12m 39s (1250 25%) train loss: 1.6419, test_loss: 1.7067]\n",
      "Whank.\n",
      "\n",
      "RICHARDER:\n",
      "I bellow, ere enween\n",
      "as but your fly servants with the carry of you, dremand metuch \n",
      "\n",
      "[13m 8s (1300 26%) train loss: 1.6350, test_loss: 1.7294]\n",
      "What the mountian to sildenta's at son,\n",
      "I will you? Bolds of when full my thing; and hone mound but in \n",
      "\n",
      "[13m 37s (1350 27%) train loss: 1.6762, test_loss: 1.7562]\n",
      "What that leather so mightly door so me nammid; if there like;\n",
      "And singe's the true you not my come.\n",
      "\n",
      " \n",
      "\n",
      "[14m 6s (1400 28%) train loss: 1.6546, test_loss: 1.7276]\n",
      "Whillal the find for peril in courten combonden,\n",
      "When treate.\n",
      "\n",
      "ROSALINE:\n",
      "Then have thainge-sood! And y \n",
      "\n",
      "[14m 36s (1450 28%) train loss: 1.6148, test_loss: 1.7103]\n",
      "What beast thou fly disceros.\n",
      "\n",
      "GONERSHEMNES:\n",
      "You are in the sen to the will better Father,\n",
      "I cause com \n",
      "\n",
      "[15m 6s (1500 30%) train loss: 1.6440, test_loss: 1.7265]\n",
      "What\n",
      "dock a man commassion; the end. You cannot word that I\n",
      "shall look with love come.\n",
      "\n",
      "PRINCESTER:\n",
      "Wh \n",
      "\n",
      "[15m 35s (1550 31%) train loss: 1.6439, test_loss: 1.7153]\n",
      "Whe come\n",
      "By all of heart: we are every not for with doth my fled my moss; be make thy time,\n",
      "That you t \n",
      "\n",
      "[16m 4s (1600 32%) train loss: 1.6474, test_loss: 1.7180]\n",
      "What true better, as the in his hercester of you all ass betwere;\n",
      "In sultenurite for 'twere you, which \n",
      "\n",
      "[16m 33s (1650 33%) train loss: 1.6515, test_loss: 1.7417]\n",
      "What mad, the corredious; that the goge's that the enden, and with thee with I not a sholly image them \n",
      "\n",
      "[17m 2s (1700 34%) train loss: 1.6577, test_loss: 1.7081]\n",
      "Whing and arty o'er. But false he against speep, sirst opet of all an as\n",
      "And fashing hear of Must than \n",
      "\n",
      "[17m 31s (1750 35%) train loss: 1.6402, test_loss: 1.7053]\n",
      "What, hath feart of rate:\n",
      "No,\n",
      "that say his duke thou drood them tongue,\n",
      "I cope and sorey priave the to \n",
      "\n",
      "[18m 1s (1800 36%) train loss: 1.6207, test_loss: 1.7240]\n",
      "Wh thine to been here not acque, for me, do has know on thee? I'll proved anasone of shall follow true \n",
      "\n",
      "[18m 30s (1850 37%) train loss: 1.6528, test_loss: 1.7122]\n",
      "What, did innaward.\n",
      "Loob in heart old love.\n",
      "\n",
      "SPEED:\n",
      "The can heart:\n",
      "You saie a wood.\n",
      "\n",
      "CAITIUS:\n",
      "Ay, my e \n",
      "\n",
      "[18m 59s (1900 38%) train loss: 1.6357, test_loss: 1.6914]\n",
      "What is he Orgha! they hath gold of the tife, send a for it.\n",
      "\n",
      "MARK ANTONY:\n",
      "I will the place, my lord.\n",
      " \n",
      "\n",
      "[19m 28s (1950 39%) train loss: 1.6032, test_loss: 1.6897]\n",
      "What be she the king to his burien a was I would pervil biding him so bliefpled love,--\n",
      "Carent;\n",
      "I will \n",
      "\n",
      "[19m 57s (2000 40%) train loss: 1.6456, test_loss: 1.7055]\n",
      "What will with your love my father house not us, go, you sorest my preservants,\n",
      "So shall face:\n",
      "You son \n",
      "\n",
      "[20m 26s (2050 41%) train loss: 1.6715, test_loss: 1.7097]\n",
      "Why yo and is wisheen this breeging at me in his emberoo, what have be of three well out it with the g \n",
      "\n",
      "[20m 56s (2100 42%) train loss: 1.6396, test_loss: 1.7439]\n",
      "What rall, be belowly at thou with that never head?\n",
      "\n",
      "SILENCE:\n",
      "I would remetter are murks not I discume \n",
      "\n",
      "[21m 25s (2150 43%) train loss: 1.6539, test_loss: 1.7451]\n",
      "What marrare did, if that pare, the quite donative you, and not shall never the now thy valition\n",
      "With  \n",
      "\n",
      "[21m 54s (2200 44%) train loss: 1.6511, test_loss: 1.7111]\n",
      "Wherta! for affairy thy burisent, I am passion barougher\n",
      "Awort them is chaspens your brave the good Co \n",
      "\n",
      "[22m 23s (2250 45%) train loss: 1.6184, test_loss: 1.7312]\n",
      "What comes in a will created on, and needs him I, let for a charge,\n",
      "I have hope mething add should the \n",
      "\n",
      "[22m 53s (2300 46%) train loss: 1.6596, test_loss: 1.7520]\n",
      "Whing me cheer, my eye the day in her upon you, in poor of help and discently play me be matcat to be  \n",
      "\n",
      "[23m 22s (2350 47%) train loss: 1.6226, test_loss: 1.7228]\n",
      "What noble of the sword that mine, an and it that terchant care about, May me, the friend of thring to \n",
      "\n",
      "[23m 51s (2400 48%) train loss: 1.6365, test_loss: 1.7002]\n",
      "Who, give to men can so finht, by the\n",
      "rantage.\n",
      "\n",
      "RICHAR:\n",
      "Why, image of into\n",
      "base a monster of graces wa \n",
      "\n",
      "[24m 21s (2450 49%) train loss: 1.6406, test_loss: 1.7183]\n",
      "What are shall had it the matter: all honful do your lost health good us the Dake part so seather. O t \n",
      "\n",
      "[24m 51s (2500 50%) train loss: 1.6373, test_loss: 1.7313]\n",
      "What happy who time armieson, I shall word.\n",
      "\n",
      "PAULINA:\n",
      "O not, and to to it men with it who's Antony the \n",
      "\n",
      "[25m 20s (2550 51%) train loss: 1.6493, test_loss: 1.7033]\n",
      "What neighing of Greacty?\n",
      "\n",
      "PERIACHITH:\n",
      "Is what stret her from that you now, and the spell a sleep;\n",
      "The \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25m 49s (2600 52%) train loss: 1.6365, test_loss: 1.7339]\n",
      "Why, be he to my trut and the jogh your pleame him is men more!\n",
      "\n",
      "OILINE:\n",
      "I come; like out on go, not I \n",
      "\n",
      "[26m 18s (2650 53%) train loss: 1.6625, test_loss: 1.7180]\n",
      "Whing hid to hath a bidout glain? my prains for in the restain and that that we and at seet go not\n",
      "I a \n",
      "\n",
      "[26m 47s (2700 54%) train loss: 1.6350, test_loss: 1.7239]\n",
      "Whingle his strokes Trook me\n",
      "and an hold his hand,\n",
      "I'll wish a lotkinger. But be that last pripes. The \n",
      "\n",
      "[27m 16s (2750 55%) train loss: 1.6133, test_loss: 1.7001]\n",
      "Whip the true too rest was heart looks?\n",
      "\n",
      "ROSALIND:\n",
      "I cut so a peace and ear a sool for is natuel me\n",
      "I  \n",
      "\n",
      "[27m 46s (2800 56%) train loss: 1.6522, test_loss: 1.7164]\n",
      "What thy war we thanks to much, and I have the monest-chate do to more more\n",
      "In wantle and no away this \n",
      "\n",
      "[28m 15s (2850 56%) train loss: 1.6421, test_loss: 1.6993]\n",
      "Wher have bune.\n",
      "\n",
      "FLORENCE:\n",
      "If I would away.\n",
      "\n",
      "ULYSSES:\n",
      "Come, sare life, thou had unto the repons, and m \n",
      "\n",
      "[28m 44s (2900 57%) train loss: 1.6495, test_loss: 1.7537]\n",
      "What begin:\n",
      "We cried?\n",
      "\n",
      "PITUS:\n",
      "The as shall they like a charse thy tith Cherrow and is that her of it u \n",
      "\n",
      "[29m 13s (2950 59%) train loss: 1.6265, test_loss: 1.7063]\n",
      "Where not have I that faulties,\n",
      "Compaince, no bid to the heart?\n",
      "\n",
      "IAGO:\n",
      "To myself, well to the will ban \n",
      "\n",
      "[29m 42s (3000 60%) train loss: 1.6252, test_loss: 1.7314]\n",
      "Whe welcome to him, but is her fatherty to side;\n",
      "And interate stand him, or will that we should be the \n",
      "\n",
      "[30m 12s (3050 61%) train loss: 1.6398, test_loss: 1.7420]\n",
      "While, blood content of the furthed on honour, it poor on this;\n",
      "Is, and the breath to not make thy gro \n",
      "\n",
      "[30m 41s (3100 62%) train loss: 1.6253, test_loss: 1.7533]\n",
      "Whink.\n",
      "\n",
      "KATHARINA:\n",
      "And as Is are and woman. The icues and her warm the diedly.\n",
      "\n",
      "HENIO:\n",
      "Good court of h \n",
      "\n",
      "[31m 10s (3150 63%) train loss: 1.6174, test_loss: 1.7276]\n",
      "Whings thy hort,\n",
      "We will should hopless'd me come to our first with gave opes his wort.\n",
      "There; I love; \n",
      "\n",
      "[31m 39s (3200 64%) train loss: 1.6478, test_loss: 1.7185]\n",
      "Where of this hence this been after: with it, here with yet have shall\n",
      "That when the\n",
      "speak and look hi \n",
      "\n",
      "[32m 8s (3250 65%) train loss: 1.6656, test_loss: 1.7142]\n",
      "Where the and their onest the revesh methant not, by the sesets and such or poor I will have gather, s \n",
      "\n",
      "[32m 38s (3300 66%) train loss: 1.6110, test_loss: 1.7318]\n",
      "Whe presty be the glase below' seen eyes all;\n",
      "Beniund in hand from speak of hirrageling to a servous c \n",
      "\n",
      "[33m 7s (3350 67%) train loss: 1.6412, test_loss: 1.7407]\n",
      "Where,--\n",
      "\n",
      "KING CLAUDIUS:\n",
      "RilDi' dost the fair me of make of the come that any man to your inesty, thou \n",
      "\n",
      "[33m 36s (3400 68%) train loss: 1.6379, test_loss: 1.7263]\n",
      "Whe even to moss?\n",
      "\n",
      "BENVOLUS:\n",
      "It promial against death and this faint mereign and\n",
      "makes;\n",
      "Nor other show \n",
      "\n",
      "[34m 5s (3450 69%) train loss: 1.6524, test_loss: 1.7085]\n",
      "Whing, that lifed nown and thereness good stood,\n",
      "He love.\n",
      "\n",
      "SPEEDES:\n",
      "But in himso back upon it them beh \n",
      "\n",
      "[34m 34s (3500 70%) train loss: 1.6230, test_loss: 1.7201]\n",
      "Whing him his from the\n",
      "affingely a good nature away!\n",
      "We have seet fire,\n",
      "To dread.\n",
      "\n",
      "LADY CAPULET:\n",
      "Hadst \n",
      "\n",
      "[35m 3s (3550 71%) train loss: 1.6225, test_loss: 1.7230]\n",
      "What we life.\n",
      "\n",
      "PARIS:\n",
      "I have I am ender to can I stand of eye sir.\n",
      "\n",
      "WARWICK:\n",
      "So think them to see the  \n",
      "\n",
      "[35m 32s (3600 72%) train loss: 1.6515, test_loss: 1.7383]\n",
      "Whing the king'd, that I have as eyes master lord was my stry's unwent tears again.\n",
      "\n",
      "APETALINA:\n",
      "But se \n",
      "\n",
      "[36m 2s (3650 73%) train loss: 1.6552, test_loss: 1.7290]\n",
      "Whing take of like good it in ours.\n",
      "\n",
      "SALENTERNES:\n",
      "A become; not battedant thou confess,\n",
      "For I wake wit \n",
      "\n",
      "[36m 31s (3700 74%) train loss: 1.6363, test_loss: 1.7085]\n",
      "While I am our fall--\n",
      "\n",
      "TITUS OF SYRACUSE:\n",
      "This the do, and furthelds, readratiale of him yet wake use  \n",
      "\n",
      "[37m 0s (3750 75%) train loss: 1.6248, test_loss: 1.6984]\n",
      "Wher.\n",
      "\n",
      "Come, sheate.\n",
      "\n",
      "PETRUCHIO:\n",
      "Not.\n",
      "\n",
      "PORTIA:\n",
      "And like such near, to the sight to strong and soldier  \n",
      "\n",
      "[37m 29s (3800 76%) train loss: 1.6576, test_loss: 1.7148]\n",
      "Where to my Lord maded content, stander that terreer in the dariaus,\n",
      "And this take the meal to he in h \n",
      "\n",
      "[37m 59s (3850 77%) train loss: 1.6312, test_loss: 1.7311]\n",
      "Wh, sir, it be in this hands, I'll sorrow the mistrow! Fither of thy kind it one solish was make dull  \n",
      "\n",
      "[38m 28s (3900 78%) train loss: 1.6352, test_loss: 1.7370]\n",
      "Wh mortage? let as a vece of and my mercimenger;\n",
      "And are disbled ore of my promen?\n",
      "\n",
      "CARDOND:\n",
      "I would d \n",
      "\n",
      "[38m 57s (3950 79%) train loss: 1.6162, test_loss: 1.6984]\n",
      "Whe own brother: the worthy offended of how in you wourt I;\n",
      "With sorrow such man, when they can speak. \n",
      "\n",
      "[39m 26s (4000 80%) train loss: 1.6578, test_loss: 1.7449]\n",
      "What I know the say me.\n",
      "\n",
      "PORTIA:\n",
      "But I will here you what it thy heart.\n",
      "\n",
      "MARETRIONE:\n",
      "I have subbury to \n",
      "\n",
      "[39m 55s (4050 81%) train loss: 1.6177, test_loss: 1.7337]\n",
      "Wh eyes my prince colds to reproy, in you have is\n",
      "nour such so known fellow,\n",
      "And awter'd; that he will \n",
      "\n",
      "[40m 25s (4100 82%) train loss: 1.6133, test_loss: 1.7250]\n",
      "Wh him his deart, why they shall fews that the can I canip leavess.\n",
      "\n",
      "BOYES:\n",
      "No, the words, and her he  \n",
      "\n",
      "[40m 54s (4150 83%) train loss: 1.6327, test_loss: 1.7488]\n",
      "Where what such run farewol and now,\n",
      "O from fingers that 'or by steam, my princess great that good Pec \n",
      "\n",
      "[41m 23s (4200 84%) train loss: 1.6090, test_loss: 1.6944]\n",
      "Wher goess, May but will caren'd of thee signises: good though make fall and trumber.'\n",
      "It pray charthe \n",
      "\n",
      "[41m 52s (4250 85%) train loss: 1.6413, test_loss: 1.7312]\n",
      "Where ridmon dogght with him.\n",
      "\n",
      "BARDOLPH:\n",
      "Gave-hen, clalt so Mine with health,\n",
      "this mear this as you ar \n",
      "\n",
      "[42m 22s (4300 86%) train loss: 1.6275, test_loss: 1.7264]\n",
      "Whes.\n",
      "\n",
      "Sor would fear stixt Proughtion would so fair.\n",
      "\n",
      "MARCELLO:\n",
      "Sicient a peace like cheeration the f \n",
      "\n",
      "[42m 51s (4350 87%) train loss: 1.6167, test_loss: 1.7351]\n",
      "Whil very vatish in you.\n",
      "\n",
      "COUNTESS:\n",
      "Weaven well and we prince you hear but we boy, and the such this o \n",
      "\n",
      "[43m 20s (4400 88%) train loss: 1.6200, test_loss: 1.7144]\n",
      "Whings love\n",
      "She purphequef, sir,\n",
      "And they, the very your cats your, I nousing, lady with heavens with  \n",
      "\n",
      "[43m 49s (4450 89%) train loss: 1.6603, test_loss: 1.7093]\n",
      "What it me you king and speed and drink a great like they the stime but I knity to modey\n",
      "He must 'tlow \n",
      "\n",
      "[44m 19s (4500 90%) train loss: 1.6244, test_loss: 1.7369]\n",
      "Whome.\n",
      "And is the so head, my lacks gone, by like an canson her day hath base, O the breath herous to  \n",
      "\n",
      "[44m 48s (4550 91%) train loss: 1.6520, test_loss: 1.7416]\n",
      "Whick for his couther he love, and in thy sen thee I knowed as it gaither, to but the name mistred wou \n",
      "\n",
      "[45m 17s (4600 92%) train loss: 1.6409, test_loss: 1.7223]\n",
      "Which is not leave her now is gentless to be trust the not a poor! like night, muscation,\n",
      "To good long \n",
      "\n",
      "[45m 46s (4650 93%) train loss: 1.6534, test_loss: 1.7731]\n",
      "Wh him\n",
      "Sight, you wonnawed of thee the cannot no chose and so in thee, gods ecch.\n",
      "\n",
      "FALSTAFF:\n",
      "Sir, gent \n",
      "\n",
      "[46m 16s (4700 94%) train loss: 1.6542, test_loss: 1.7377]\n",
      "Which in me\n",
      "thee, here to invy do such look they with his proven's when yet our propts, and breathon p \n",
      "\n",
      "[46m 45s (4750 95%) train loss: 1.6568, test_loss: 1.7055]\n",
      "Whe nows better the dumbsged where should to rout,\n",
      "And so have were I proute, and thring this is himse \n",
      "\n",
      "[47m 14s (4800 96%) train loss: 1.6466, test_loss: 1.7100]\n",
      "Why, I condertion, I more that the soldier, I'll a langing of thee.\n",
      "\n",
      "MERCHILLO:\n",
      "O, burn love,\n",
      "And he l \n",
      "\n",
      "[47m 43s (4850 97%) train loss: 1.6447, test_loss: 1.7048]\n",
      "Wh of with more?\n",
      "\n",
      "Second Calked not the made and for be moves of lives Bastror, good never movereed ou \n",
      "\n",
      "[48m 12s (4900 98%) train loss: 1.6475, test_loss: 1.7046]\n",
      "Whing you: and thought me our and paintly not she shall but his spoke me tears not.\n",
      "\n",
      "Fircks to while m \n",
      "\n",
      "[48m 41s (4950 99%) train loss: 1.6255, test_loss: 1.7481]\n",
      "Whing of his frit:\n",
      "I bemper them with their earges of him degion, how thy prince with the tro.\n",
      "\n",
      "HENRY  \n",
      "\n",
      "[49m 10s (5000 100%) train loss: 1.6280, test_loss: 1.7027]\n",
      "Whing of a savent mind thee delicy,\n",
      "But very oberer.\n",
      "\n",
      "HENRY\n",
      "POMPAR:\n",
      "Why, that here upon not what waw a \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=model_type, n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network\n",
    "# torch.save(classifier.state_dict(), './rnn_generator.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Training and Test Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33035ae080>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate text generation\n",
    "\n",
    "Check what the outputted text looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This made bloody my come, with him.\n",
      "\n",
      "CAPULEN:\n",
      "I will perse.\n",
      "\n",
      "QUEEN KATHOM:\n",
      "Then so slection have I would he shall be had my plentend\n",
      "Stomest meanius soldiers, we wall the word, and,\n",
      "By my brearring answear'd again, seet thou word.\n",
      "\n",
      "FORD PEDRLENTRUCHIO:\n",
      "What grack fare! I would 'too stands,\n",
      "Doubt the lest prince with the padend'd with my right; which not more; and you shall shorted rite, sir, My ear never go, garst\n",
      "That though not a sad their sense, would your\n",
      "lordance;\n",
      "And then land so no, those way head, you would must the vousicer! I'll mean\n",
      "What done; and it love king, and should doth prisord of seater'd in somether here upon the poor not a great the trumber, but so, and I must that you seeks fortune is what brow the rather or heaven My gewselford: and Antony on a perfend come on hath againds, sir, nor.\n",
      "\n",
      "Varrow be fanst you there battord then is soldier's:\n",
      "It had we should does. The child as it The so, for come no most was the well utters, tances this good our deserate: thy most was w\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Some things you should try to improve your network performance are:\n",
    "- Different RNN types. Switch the basic RNN network in your model to a GRU and LSTM to compare all three.\n",
    "- Try adding 1 or two more layers\n",
    "- Increase the hidden layer size\n",
    "- Changing the learning rate\n",
    "\n",
    "**TODO:** Try changing the RNN type and hyperparameters. Record your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "[0m 30s (50 1%) train loss: 2.0808, test_loss: 2.0933]\n",
      "Whe hearl to mable, shast,\n",
      "Is and I'll a him not HRENES:\n",
      "Ind the ceick the the love the coveres but le \n",
      "\n",
      "[1m 4s (100 2%) train loss: 1.8741, test_loss: 1.9157]\n",
      "Wh. KING, Vill and miticion, he sore suce, sing unjreped.\n",
      "\n",
      "PROSSalust dewemle fold me! Rome.\n",
      "\n",
      "CIO:\n",
      "I k \n",
      "\n",
      "[1m 36s (150 3%) train loss: 1.7974, test_loss: 1.8242]\n",
      "Who cunger, and poop was and hows dor a bear\n",
      "diebbin thy loves with thou sell,' think in are so,\n",
      "the l \n",
      "\n",
      "[2m 7s (200 4%) train loss: 1.7523, test_loss: 1.7793]\n",
      "Whit in farit,\n",
      "And name you toching of what was thee at this curage; strase for what we newer\n",
      "Of the p \n",
      "\n",
      "[2m 40s (250 5%) train loss: 1.6657, test_loss: 1.7294]\n",
      "Wheir man, not for wittest.\n",
      "\n",
      "ARCES:\n",
      "Nay, told you spend to a shough had be strimpance,\n",
      "There is the me \n",
      "\n",
      "[3m 15s (300 6%) train loss: 1.6692, test_loss: 1.7290]\n",
      "Wh, the child to my\n",
      "his long;\n",
      "But I am have it did my sarker shall ether contience\n",
      "That sake of the op \n",
      "\n",
      "[3m 46s (350 7%) train loss: 1.6522, test_loss: 1.7057]\n",
      "Whate let word you be than to things,\n",
      "What crofto be look empress bans.\n",
      "\n",
      "PRINCESS:\n",
      "There's of hears no \n",
      "\n",
      "[4m 18s (400 8%) train loss: 1.6279, test_loss: 1.7185]\n",
      "Whature of me for the earthis,\n",
      "The pained that bands aspeasaus the lie and expitastion\n",
      "And joins my pa \n",
      "\n",
      "[4m 49s (450 9%) train loss: 1.6261, test_loss: 1.6820]\n",
      "Whents.\n",
      "\n",
      "DROMIO:\n",
      "I paint the made of it heart honest\n",
      "Frake noy storms: I pressess, and earth love.\n",
      "I c \n",
      "\n",
      "[5m 20s (500 10%) train loss: 1.5970, test_loss: 1.6922]\n",
      "Why, the cless son?\n",
      "\n",
      "MOTH:\n",
      "Verpor, about his come he many not\n",
      "And one had her diuse to the countivices \n",
      "\n",
      "[5m 54s (550 11%) train loss: 1.5658, test_loss: 1.6863]\n",
      "Why, judge?\n",
      "\n",
      "LENVER:\n",
      "Mack, and Truech is kne's made with the eye is no\n",
      "horse hand be his wilds with hi \n",
      "\n",
      "[6m 26s (600 12%) train loss: 1.6149, test_loss: 1.6634]\n",
      "Whenfie?\n",
      "\n",
      "POLIXENES:\n",
      "Why, he is Rodand you, sir. Do well.\n",
      "\n",
      "MORTAND:\n",
      "The person, four fail, a deet her  \n",
      "\n",
      "[6m 56s (650 13%) train loss: 1.5746, test_loss: 1.6191]\n",
      "Whiat did Rome to feel so rose assure\n",
      "The done: and stand thou are hes to her forture\n",
      "bid elfore know  \n",
      "\n",
      "[7m 25s (700 14%) train loss: 1.5741, test_loss: 1.6224]\n",
      "Wham that whose his all abrod\n",
      "That an ectain with the her, to wargingn good bid\n",
      "Woudden, left than for \n",
      "\n",
      "[7m 53s (750 15%) train loss: 1.5723, test_loss: 1.6766]\n",
      "What by the space.\n",
      "\n",
      "SILINA:\n",
      "Carity, them, good dayge up for are should should make yet the\n",
      "With away,  \n",
      "\n",
      "[8m 22s (800 16%) train loss: 1.5602, test_loss: 1.6580]\n",
      "Whamf thy done?\n",
      "\n",
      "PANDARUS:\n",
      "With an reastors.\n",
      "\n",
      "SALIND:\n",
      "How we were not not piece, all a tight\n",
      "Nay, from \n",
      "\n",
      "[8m 55s (850 17%) train loss: 1.5413, test_loss: 1.6434]\n",
      "Whee? Like the heaven\n",
      "In command, and a presentoms,\n",
      "Bonest. I do pade to my credellent I hollown of yo \n",
      "\n",
      "[9m 27s (900 18%) train loss: 1.5460, test_loss: 1.6112]\n",
      "What need with his looks:\n",
      "Let that that a eyes to Rome.\n",
      "\n",
      "BENEDICK:\n",
      "Allows, to many one that they's bur \n",
      "\n",
      "[9m 58s (950 19%) train loss: 1.5499, test_loss: 1.6176]\n",
      "Where then,\n",
      "Wheldon thep in a deam. At enefort, and there begince,\n",
      "Have the out of the him not in desc \n",
      "\n",
      "[10m 28s (1000 20%) train loss: 1.5666, test_loss: 1.6471]\n",
      "When of the part you when the brother.\n",
      "\n",
      "TOUCHSTONE:\n",
      "I sad you of a before a virtoment and burn in a wa \n",
      "\n",
      "[10m 58s (1050 21%) train loss: 1.6026, test_loss: 1.6645]\n",
      "Which I am hearffy.\n",
      "\n",
      "HENERINDER:\n",
      "Good eversice cangely on, therefore,\n",
      "Of a thoughts to the cass been;  \n",
      "\n",
      "[11m 32s (1100 22%) train loss: 1.5550, test_loss: 1.6449]\n",
      "Whilles in Farth,\n",
      "But better to the shear you heart he will to the\n",
      "pans the contingless lives duty, wh \n",
      "\n",
      "[12m 4s (1150 23%) train loss: 1.5481, test_loss: 1.6328]\n",
      "Why, at me on the\n",
      "pear I heart. When thou should have the come so appear I,\n",
      "Can he is nurse, and true: \n",
      "\n",
      "[12m 34s (1200 24%) train loss: 1.5551, test_loss: 1.6492]\n",
      "Which gone his house,\n",
      "For quince of the plant the worst up not\n",
      "Strive king the vame.\n",
      "\n",
      "RATHARD:\n",
      "Madam w \n",
      "\n",
      "[13m 6s (1250 25%) train loss: 1.5602, test_loss: 1.6349]\n",
      "Wh: is up,\n",
      "I wasted for that have mass now that speak, a order with the seed you\n",
      "mides of his rosance, \n",
      "\n",
      "[13m 36s (1300 26%) train loss: 1.5404, test_loss: 1.6382]\n",
      "Why, fareation, and my walls.\n",
      " you, there gavine and they speak all listral.\n",
      "\n",
      "ORLANEUS:\n",
      "No, they will  \n",
      "\n",
      "[14m 7s (1350 27%) train loss: 1.5579, test_loss: 1.6449]\n",
      "Who is forth, was cold saving\n",
      "Than curneitions to the crowns to me;\n",
      "Third the mine in joy of must sand \n",
      "\n",
      "[14m 38s (1400 28%) train loss: 1.5451, test_loss: 1.6144]\n",
      "Which desire; for the consore.\n",
      "\n",
      "POLIXENES:\n",
      "Your rost of my sleep of our do, becatot\n",
      "Ay to so this all  \n",
      "\n",
      "[15m 8s (1450 28%) train loss: 1.5269, test_loss: 1.6407]\n",
      "Whish by LEccye me make you,\n",
      "Thy muse is must speak I not in me, why or but wise\n",
      "Would command and tho \n",
      "\n",
      "[15m 41s (1500 30%) train loss: 1.5280, test_loss: 1.6226]\n",
      "What be been out\n",
      "bid all in thee the wilties, not graventining sudds\n",
      "And the command on me: dear the c \n",
      "\n",
      "[16m 12s (1550 31%) train loss: 1.5601, test_loss: 1.6404]\n",
      "When her. I much thine,\n",
      "By Antone and faiest this diel; then,\n",
      "So come, to were it dies of it sirlds;\n",
      "A \n",
      "\n",
      "[16m 43s (1600 32%) train loss: 1.5503, test_loss: 1.6273]\n",
      "Whreal so.\n",
      "\n",
      "Second Gentleman:\n",
      "That we have not to your pretained leod brow'd\n",
      "To have made her Parals.\n",
      " \n",
      "\n",
      "[17m 14s (1650 33%) train loss: 1.5112, test_loss: 1.6292]\n",
      "What whose trassion,\n",
      "That plain become the cloakned him see,\n",
      "And in the outhts of the weal show.\n",
      "\n",
      "KING \n",
      "\n",
      "[17m 47s (1700 34%) train loss: 1.5282, test_loss: 1.6320]\n",
      "Whent.\n",
      "\n",
      "AUVILITIA:\n",
      "'Tis the Flaking my must such all on the king!\n",
      "\n",
      "TITUS ADER:\n",
      "Peace chope thing them  \n",
      "\n",
      "[18m 19s (1750 35%) train loss: 1.5461, test_loss: 1.6173]\n",
      "What. Still, let the king ear.\n",
      "\n",
      "PISTOL:\n",
      "Why, some of a have be shall hath littles,\n",
      "This be sides about \n",
      "\n",
      "[18m 51s (1800 36%) train loss: 1.5118, test_loss: 1.6429]\n",
      "Who meried that a sleep;\n",
      "That bittom thoughts? I have never nair.\n",
      "\n",
      "JAQUES:\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "It hath a \n",
      "\n",
      "[19m 22s (1850 37%) train loss: 1.5050, test_loss: 1.6342]\n",
      "Whoram, if the noble noth:\n",
      "And shall be not take in a mind to as so bat\n",
      "Were by charge: the wear in th \n",
      "\n",
      "[19m 55s (1900 38%) train loss: 1.5111, test_loss: 1.5804]\n",
      "Why, or the purnate\n",
      "He heard and these company the man?\n",
      "\n",
      "CASSIO:\n",
      "Dose, who doth the ever the true obju \n",
      "\n",
      "[20m 28s (1950 39%) train loss: 1.5426, test_loss: 1.6222]\n",
      "What, my lord; it is\n",
      "good mother the speak sister overs to his rest.\n",
      "\n",
      "COMINIUS:\n",
      "Should less in the see \n",
      "\n",
      "[21m 2s (2000 40%) train loss: 1.5370, test_loss: 1.6476]\n",
      "Whee, seeking, he know that bloody,\n",
      "When I'll no water both he harded and the night\n",
      "Dissabels charies. \n",
      "\n",
      "[21m 35s (2050 41%) train loss: 1.5412, test_loss: 1.6414]\n",
      "Whola! his stave of the person\n",
      "And day, an scorned me the embrace and wers of our kings;\n",
      "And thou losh \n",
      "\n",
      "[22m 8s (2100 42%) train loss: 1.4953, test_loss: 1.6625]\n",
      "Who spirewell us the sined,\n",
      "To the desire: here die you hold; be\n",
      "we suppided she faired of his beinst  \n",
      "\n",
      "[22m 38s (2150 43%) train loss: 1.5195, test_loss: 1.6109]\n",
      "While gone hand of the served\n",
      "pieces the manny as drunged, there's alone.\n",
      "\n",
      "PAROLLES:\n",
      "As my three do it \n",
      "\n",
      "[23m 10s (2200 44%) train loss: 1.5283, test_loss: 1.6399]\n",
      "When me told our long\n",
      "The marrily an preserve your forget, he words:\n",
      "But that comes of proverment too  \n",
      "\n",
      "[23m 42s (2250 45%) train loss: 1.4989, test_loss: 1.6071]\n",
      "When you can Page. I'll past desire\n",
      "That come and the become in the fair and son;\n",
      "Have as this not be  \n",
      "\n",
      "[24m 14s (2300 46%) train loss: 1.4899, test_loss: 1.6038]\n",
      "Whiled and now thou art one\n",
      "That the some put him silver not.\n",
      "\n",
      "CLEOPATRA:\n",
      "If I words, sir, let me now  \n",
      "\n",
      "[24m 47s (2350 47%) train loss: 1.4875, test_loss: 1.6392]\n",
      "Whenty,\n",
      "But more? full's upon thee, you\n",
      "speew you our for mort-heart, asick her notrasant,\n",
      "Woudden her \n",
      "\n",
      "[25m 19s (2400 48%) train loss: 1.5128, test_loss: 1.6425]\n",
      "What that this believe\n",
      "That believe it further, she hands were\n",
      "fear'd of the man from my being makes t \n",
      "\n",
      "[25m 52s (2450 49%) train loss: 1.5299, test_loss: 1.6350]\n",
      "Where down, I assaver, Links not water?\n",
      "\n",
      "POLIXENES:\n",
      "And, miot, leave\n",
      "And a love is come though we will \n",
      "\n",
      "[26m 25s (2500 50%) train loss: 1.5360, test_loss: 1.6309]\n",
      "Whis such all thought some\n",
      "true: I have this death have servantly from me:\n",
      "And go my cannot good reaso \n",
      "\n",
      "[26m 58s (2550 51%) train loss: 1.5244, test_loss: 1.6224]\n",
      "Who speak many say,\n",
      "These place and his morrow of service to the\n",
      "was the matter and peace.\n",
      "My lord of  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27m 31s (2600 52%) train loss: 1.5097, test_loss: 1.6321]\n",
      "When here we'll the burn his own\n",
      "The hand my moin uttrazed for the seate before to\n",
      "master more and so, \n",
      "\n",
      "[28m 4s (2650 53%) train loss: 1.5092, test_loss: 1.6657]\n",
      "What shall not on,\n",
      "hunty? soul use strake your fair the new,\n",
      "The must against your wise for,\n",
      "And thou  \n",
      "\n",
      "[28m 33s (2700 54%) train loss: 1.5152, test_loss: 1.6264]\n",
      "Who do et compascumish the\n",
      "him the vain: and the king.\n",
      "\n",
      "DON JOHNE:\n",
      "And in man, get the current to the  \n",
      "\n",
      "[29m 2s (2750 55%) train loss: 1.5271, test_loss: 1.6085]\n",
      "What in an enoug\n",
      "The father's doine of the court's bold,\n",
      "Or tell men, accurs and be mustables.\n",
      "\n",
      "PRINCE \n",
      "\n",
      "[29m 31s (2800 56%) train loss: 1.5059, test_loss: 1.6169]\n",
      "Who defent than he she.\n",
      "\n",
      "PORTIUS:\n",
      "Give you thy widder case us of my haste,\n",
      "Who once the Moulth thildin \n",
      "\n",
      "[29m 59s (2850 56%) train loss: 1.5276, test_loss: 1.6429]\n",
      "Why son of the prouddless.\n",
      "'Tis fair days: thou have 'tis hand some is myself,\n",
      "To the king it here the \n",
      "\n",
      "[30m 28s (2900 57%) train loss: 1.5261, test_loss: 1.6054]\n",
      "Why late, with his your woming my king?\n",
      "\n",
      "CLEOPATRA:\n",
      "Since, well, he should my seal speak you, Wirstabl \n",
      "\n",
      "[30m 58s (2950 59%) train loss: 1.5136, test_loss: 1.6189]\n",
      "Why, pascaities, thou altched begres\n",
      "Of Judance, his allike to conderner for for\n",
      "sing it his here is e \n",
      "\n",
      "[31m 33s (3000 60%) train loss: 1.4994, test_loss: 1.6129]\n",
      "Who cond in rail in him\n",
      "And in the fortune with the most so dead once.\n",
      "\n",
      "KING HENRY VIII:\n",
      "My lord? what \n",
      "\n",
      "[32m 8s (3050 61%) train loss: 1.5001, test_loss: 1.6137]\n",
      "Why lock'd, person make well heart;\n",
      "And desorate and brother, come, the deed for your seek at\n",
      "what his \n",
      "\n",
      "[32m 41s (3100 62%) train loss: 1.5194, test_loss: 1.6261]\n",
      "What an a will that believe of an to lady,\n",
      "As do a hand that I castle, and quit to the light\n",
      "But he kn \n",
      "\n",
      "[33m 12s (3150 63%) train loss: 1.5066, test_loss: 1.6174]\n",
      "Where speak to remement\n",
      "To carnion sounder and lasbids if the grave\n",
      "Ward; and then the Soldence to her \n",
      "\n",
      "[33m 44s (3200 64%) train loss: 1.5165, test_loss: 1.6070]\n",
      "When most a seed flower God,\n",
      "Words of the sleep a stands for my speaks\n",
      "Wall that ere man liventlysalin \n",
      "\n",
      "[34m 17s (3250 65%) train loss: 1.5047, test_loss: 1.6100]\n",
      "Whime me stays, I will not be all your\n",
      "make that gods of paled the best my remember the king\n",
      "Antim to  \n",
      "\n",
      "[34m 50s (3300 66%) train loss: 1.4981, test_loss: 1.6037]\n",
      "Who an all the roud and crandst hath lars\n",
      "And all a soldieria, sir.\n",
      "\n",
      "ROSENVIA:\n",
      "No, be way I, my lord.\n",
      " \n",
      "\n",
      "[35m 22s (3350 67%) train loss: 1.5076, test_loss: 1.6353]\n",
      "Where she will ned thee not to sun\n",
      "This pleased not doth not to the contrans?\n",
      "\n",
      "AUFICUS:\n",
      "In man still m \n",
      "\n",
      "[35m 56s (3400 68%) train loss: 1.5636, test_loss: 1.6880]\n",
      "Where it think and defencour perforpence.\n",
      "\n",
      "PORTIA:\n",
      "If thou day you, sir, she is a siggers and by.\n",
      "like \n",
      "\n",
      "[36m 31s (3450 69%) train loss: 1.4821, test_loss: 1.6233]\n",
      "When and so be matter mind it for\n",
      "Demplice seemans and you too maniman is a wine on\n",
      "Their son and lost \n",
      "\n",
      "[37m 6s (3500 70%) train loss: 1.4952, test_loss: 1.5839]\n",
      "What, or daughter as I\n",
      "love.\n",
      "\n",
      "CLAUDIO:\n",
      "My trother slain may his tears but of the note\n",
      "Here disdician,  \n",
      "\n",
      "[37m 37s (3550 71%) train loss: 1.5026, test_loss: 1.6279]\n",
      "When them, and I cannot so your\n",
      "forge this hither'd hour of Drags off your Lord Capep;\n",
      "Which tell out  \n",
      "\n",
      "[38m 11s (3600 72%) train loss: 1.4795, test_loss: 1.6360]\n",
      "Which a grace:\n",
      "Good where for those with comes, to suppless\n",
      "with me, flue to my father that this?\n",
      "\n",
      "BER \n",
      "\n",
      "[38m 44s (3650 73%) train loss: 1.5151, test_loss: 1.6089]\n",
      "Who is the piece and was better forth\n",
      "dear parting, dead with the talking him of his brother:\n",
      "For you  \n",
      "\n",
      "[39m 17s (3700 74%) train loss: 1.5049, test_loss: 1.6064]\n",
      "What strive your bale thy will;\n",
      "'Tis itself, let me way; and that great well, thou name\n",
      "In his foot li \n",
      "\n",
      "[39m 49s (3750 75%) train loss: 1.4898, test_loss: 1.6148]\n",
      "Wher this cheer his face to you.\n",
      "\n",
      "Second Lord;\n",
      "Be 'yod, there, sir.\n",
      "\n",
      "SIMININIUS:\n",
      "Let his and sake so e \n",
      "\n",
      "[40m 20s (3800 76%) train loss: 1.4871, test_loss: 1.6194]\n",
      "Who, not here the may no would thou\n",
      "but not scory miching in a mine.\n",
      "\n",
      "THERSIES:\n",
      "My looks, nor know the \n",
      "\n",
      "[40m 51s (3850 77%) train loss: 1.4844, test_loss: 1.6558]\n",
      "Why see them, changed, thought of me.\n",
      "\n",
      "FALSTAFF:\n",
      "You set to you see to my lord on:\n",
      "Let me in the leard \n",
      "\n",
      "[41m 26s (3900 78%) train loss: 1.5096, test_loss: 1.6234]\n",
      "Why has friend, is before Sir that\n",
      "day might a' know part the honour of the broken,\n",
      "Ere suffice that t \n",
      "\n",
      "[41m 59s (3950 79%) train loss: 1.4913, test_loss: 1.5871]\n",
      "Whourget will Beast beage; there!\n",
      "\n",
      "THESEUS:\n",
      "Shall a which a buse gentle shall beeyed\n",
      "Go of there is th \n",
      "\n",
      "[42m 33s (4000 80%) train loss: 1.5419, test_loss: 1.6494]\n",
      "Where is father?\n",
      "\n",
      "CLEON:\n",
      "For this mighty court, nor woman, that shall be made.\n",
      "\n",
      "HERMIO:\n",
      "No, sir, unpro \n",
      "\n",
      "[43m 4s (4050 81%) train loss: 1.4915, test_loss: 1.5729]\n",
      "What speriner, a' good a discoush.\n",
      "\n",
      "PANDARUS:\n",
      "You\n",
      "full to say, being meet meaniven, my good most onewo \n",
      "\n",
      "[43m 36s (4100 82%) train loss: 1.5038, test_loss: 1.6616]\n",
      "What parting in him of Nornor'd and\n",
      "ask to the pitter mine one you a constance,\n",
      "Of the faces on them f \n",
      "\n",
      "[44m 8s (4150 83%) train loss: 1.5072, test_loss: 1.6338]\n",
      "Where are eyes; let as the thought\n",
      "To the fortunes were not of answed grace\n",
      "take at that day to your u \n",
      "\n",
      "[44m 39s (4200 84%) train loss: 1.4956, test_loss: 1.6112]\n",
      "What lady.\n",
      "\n",
      "QUEEN CUCIO:\n",
      "Be she cannot do of my putrable to se:\n",
      "My grace honour, all him, a go all may \n",
      "\n",
      "[45m 10s (4250 85%) train loss: 1.5089, test_loss: 1.6088]\n",
      "When the grace with thee;\n",
      "And friends had 'twas desety\n",
      "What reverend all to barer-die.\n",
      "\n",
      "BOTOR FORD ILI \n",
      "\n",
      "[45m 39s (4300 86%) train loss: 1.4945, test_loss: 1.6097]\n",
      "WhARO: no not find in strangely, whose\n",
      "I place the valiant him gave his daughter, and not these mine.\n",
      " \n",
      "\n",
      "[46m 8s (4350 87%) train loss: 1.4921, test_loss: 1.6123]\n",
      "What I am too bad take must be disgeat\n",
      "And for the changed the grating diemble;\n",
      "I sons told for this g \n",
      "\n",
      "[46m 37s (4400 88%) train loss: 1.5372, test_loss: 1.6372]\n",
      "What you they such, for a charge thee.\n",
      "\n",
      "LUCIO:\n",
      "Nere to you with you cast spakes of the\n",
      "plater well wit \n",
      "\n",
      "[47m 5s (4450 89%) train loss: 1.4861, test_loss: 1.6246]\n",
      "What, I am dead as disting:\n",
      "But felmine so sent for my by face help,\n",
      "Till you to Caesar: go of his ple \n",
      "\n",
      "[47m 34s (4500 90%) train loss: 1.5017, test_loss: 1.6469]\n",
      "Wherefore that these all when\n",
      "And the fehed have with it intent of the\n",
      "seall. Calling me I do a fault, \n",
      "\n",
      "[48m 3s (4550 91%) train loss: 1.5057, test_loss: 1.6314]\n",
      "Whan he wand strute to make bet you that\n",
      "Is but the good more to not again; for combest\n",
      "The blood not  \n",
      "\n",
      "[48m 32s (4600 92%) train loss: 1.5012, test_loss: 1.6027]\n",
      "What I would subdise a shall have\n",
      "if of a great in the dear, and begin.\n",
      "\n",
      "PRINCE:\n",
      "Come, like you prume  \n",
      "\n",
      "[49m 1s (4650 93%) train loss: 1.5024, test_loss: 1.6260]\n",
      "Wherery, wilthess thou hast like tower\n",
      "To the sales on him death and all mine\n",
      "Hold it of thy good more \n",
      "\n",
      "[49m 29s (4700 94%) train loss: 1.4999, test_loss: 1.6033]\n",
      "What mysailot him, how she villain'd?\n",
      "\n",
      "BRUTUS:\n",
      "Ay, therefore he was between what we know coman\n",
      "A awe's \n",
      "\n",
      "[49m 58s (4750 95%) train loss: 1.5159, test_loss: 1.6466]\n",
      "Whorce; then turn'd the might.\n",
      "\n",
      "SOMENES:\n",
      "No, here, I will my do service to the bring;\n",
      "For him which I  \n",
      "\n",
      "[50m 26s (4800 96%) train loss: 1.5147, test_loss: 1.6580]\n",
      "What tell we nine and said, reverents;\n",
      "Do more the actords eyed thy prized in song,\n",
      "To so possess an t \n",
      "\n",
      "[50m 55s (4850 97%) train loss: 1.5189, test_loss: 1.6509]\n",
      "What again to receives\n",
      "Signiorgest: I shalt this tembem'd he fores,\n",
      "That my huntie of street? We is mi \n",
      "\n",
      "[51m 24s (4900 98%) train loss: 1.5217, test_loss: 1.6096]\n",
      "What to been sure me men; that comes\n",
      "waste me not ourselve? 'I hear of the madest, in give his word\n",
      "Sh \n",
      "\n",
      "[51m 53s (4950 99%) train loss: 1.4928, test_loss: 1.6030]\n",
      "Which a head, if dear thou do\n",
      "be adapided and manner a comes: but the power,\n",
      "And companiness by the tr \n",
      "\n",
      "[52m 21s (5000 100%) train loss: 1.5116, test_loss: 1.6321]\n",
      "When at him to be,\n",
      "That men say his speak be duke in the trirate, and been pay,\n",
      "Parts by husband with  \n",
      "\n",
      "Theried?\n",
      "\n",
      "MARK ANTONY:\n",
      "This is a somethinks in the king is at gallow,\n",
      "And presently; for the prived with he even!\n",
      "Here is none and to Merion,\n",
      "Which I want upon the blessable a creather;\n",
      "I do it out to make your suard\n",
      "My passis good discremish thee my love in neple\n",
      "She be art in a piece of comes.\n",
      "\n",
      "CASSIO:\n",
      "No, a husband's praise againer wind;\n",
      "When it she is his briench, the thiled\n",
      "What my servant and selfftom. S out one forness;\n",
      "Save it, and that it is fildpy that be do\n",
      "Sir, let our armear; and with it is high-deach\n",
      "three so be for well to did his gidder\n",
      "With the hope to be royation than here\n",
      "of the hands and as the lord as these hath a charmable:\n",
      "Send the safery think me in my wisdose me,\n",
      "but dreamman wrongled, here's a godsout the pray you.\n",
      "Alt, still-pleass'd great here, thither to be the\n",
      "of our dies. Here I would would not be but thy bidst with them. But a grange\n",
      "With away seven my love\n",
      "That my town at thee freal monstrucius,\n",
      "Is, this did would fling on the Lord Parilise.\n",
      "I will be all\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### GRU\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=\"gru\", n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')\n",
    "\n",
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "torch.Size([1, 100, 100]) torch.Size([1, 100, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 100, 100), got (100, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1dcb841d4137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training for %d epochs...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mload_random_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-5013a297b20b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rnn, input, target, optimizer, criterion)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcurr_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurr_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/michael/Documents/CS498DL/Object-Recognition/assignment4_materials/Assignment4/rnn/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0membedded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m##########       END      ##########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 147\u001b[0;31m                               'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    148\u001b[0m             check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    149\u001b[0m                               'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 100, 100), got (100, 100)"
     ]
    }
   ],
   "source": [
    "### LSTM\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=\"lstm\", n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')\n",
    "\n",
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "[0m 29s (50 1%) train loss: 2.4862, test_loss: 2.4599]\n",
      "Wh thage areme sst ore th, ine coin ant reld th hes cond areatey sow war, han mt the thnt! ill and o l \n",
      "\n",
      "[0m 58s (100 2%) train loss: 2.2256, test_loss: 2.2606]\n",
      "Whave and roat hist end reas yount an gous spow mon and, the, rave toan io aty mall chill fond ich hy  \n",
      "\n",
      "[1m 27s (150 3%) train loss: 2.1028, test_loss: 2.1391]\n",
      "Whou hime groused whall brontand it will angis in sill of than the wing the your herither all and mall \n",
      "\n",
      "[1m 56s (200 4%) train loss: 2.0417, test_loss: 2.0269]\n",
      "Whince to come me best that a the am, as wird 'brais the puster!\n",
      "He whill that and river?\n",
      "\n",
      "CHOR SODAT: \n",
      "\n",
      "[2m 25s (250 5%) train loss: 1.9640, test_loss: 1.9913]\n",
      "Whou are afe ol count hensed so to on her with me live!\n",
      "A ney are Dot; will devin sear there, midenoul \n",
      "\n",
      "[2m 54s (300 6%) train loss: 1.9591, test_loss: 1.9526]\n",
      "Whold suchon de farme to shad of eever are suardich is and courner\n",
      "sugy this thear not chall: which me \n",
      "\n",
      "[3m 24s (350 7%) train loss: 1.8897, test_loss: 1.9307]\n",
      "Whuck and so auts as the happ,\n",
      "If cand, died thou word:\n",
      "The to Wise to not thou he suat the nave shis  \n",
      "\n",
      "[3m 53s (400 8%) train loss: 1.8824, test_loss: 1.9134]\n",
      "What heart I good their parsts woud the veisiech thou sip a did dould sir.\n",
      "\n",
      "AFFAAR:\n",
      "Heglle, thou sure  \n",
      "\n",
      "[4m 22s (450 9%) train loss: 1.8572, test_loss: 1.8641]\n",
      "Whitho mady\n",
      "That houlds, and do hams her, stord,\n",
      "And be out a mowe:\n",
      "I he are do dead so quoth in, when \n",
      "\n",
      "[4m 51s (500 10%) train loss: 1.8505, test_loss: 1.8635]\n",
      "Whener eunt be as will.\n",
      "\n",
      "EDYRO:\n",
      "Let and at dearts I king thespold you she endled of ns and or him woul \n",
      "\n",
      "[5m 20s (550 11%) train loss: 1.8316, test_loss: 1.8434]\n",
      "What him blood with alds a hando love lord, woar'd be\n",
      "an if he great himsierout, my hall tos his bud h \n",
      "\n",
      "[5m 49s (600 12%) train loss: 1.8295, test_loss: 1.8245]\n",
      "Whan give belitife, the could here.\n",
      "\n",
      "Sarster:\n",
      "And greich the dreed\n",
      "bout, and fielles hid the cale.\n",
      "\n",
      "SI \n",
      "\n",
      "[6m 18s (650 13%) train loss: 1.7734, test_loss: 1.8338]\n",
      "Whelest deaness of brown, lither: I we cristore, my frippess?\n",
      "\n",
      "KING LEILUS:\n",
      "Which and the lain,\n",
      "Tiave\n",
      " \n",
      "\n",
      "[6m 47s (700 14%) train loss: 1.7863, test_loss: 1.8320]\n",
      "Whough and were\n",
      "Ingo bether boss.\n",
      "\n",
      "MESTARD:\n",
      "But hit her will: thy dasser the lookence,--fald hearth ou \n",
      "\n",
      "[7m 16s (750 15%) train loss: 1.7683, test_loss: 1.7837]\n",
      "Whom the hinglus,\n",
      "And with by thet befour to we is all to that I will good, when heart,\n",
      "I do amblite s \n",
      "\n",
      "[7m 45s (800 16%) train loss: 1.7555, test_loss: 1.7867]\n",
      "When the maith, the stook so, not therse to son\n",
      "Why rom proin the strall him him, one for of forinster \n",
      "\n",
      "[8m 14s (850 17%) train loss: 1.7418, test_loss: 1.7979]\n",
      "Whom of ither some crage;\n",
      "The do lord, and your keerion\n",
      "As you the cannot their the bodount, pride.\n",
      "Fo \n",
      "\n",
      "[8m 44s (900 18%) train loss: 1.7346, test_loss: 1.7790]\n",
      "What have not it do being their pale, I drue of the sweet for never may reffeed.\n",
      "\n",
      "LAUNCATNEANT:\n",
      "Had yo \n",
      "\n",
      "[9m 13s (950 19%) train loss: 1.7270, test_loss: 1.7634]\n",
      "Who do shasts I am die, my lord, like your sie some come he like to so than the to stare up therely la \n",
      "\n",
      "[9m 42s (1000 20%) train loss: 1.7033, test_loss: 1.7778]\n",
      "Which I grace that the aithushold she tear in let you she gold hath, to try in nober; God mine the hav \n",
      "\n",
      "[10m 11s (1050 21%) train loss: 1.7109, test_loss: 1.7452]\n",
      "Whyat them there in it coured, sir, she oun did him, good for it upon enting man you an this now,\n",
      "The  \n",
      "\n",
      "[10m 40s (1100 22%) train loss: 1.7206, test_loss: 1.7553]\n",
      "Why Rome and to nighted, so mans.\n",
      "\n",
      "SULEN:\n",
      "I'll perites to menis'ding survo! and your hands, made and t \n",
      "\n",
      "[11m 9s (1150 23%) train loss: 1.7181, test_loss: 1.7470]\n",
      "Whust my bring\n",
      "That sure his dake:\n",
      "I would my lord:\n",
      "O mine friend lay for heaven:\n",
      "There's thou this ca \n",
      "\n",
      "[11m 38s (1200 24%) train loss: 1.7210, test_loss: 1.7396]\n",
      "Whenge perment like reput to knorge of lookeles her notile eat then time.\n",
      "\n",
      "LAUDELLAN:\n",
      "And it with past \n",
      "\n",
      "[12m 7s (1250 25%) train loss: 1.6908, test_loss: 1.7583]\n",
      "Why of Painut his commattited:\n",
      "No. We is a wild so tell the contormed\n",
      "Tis the say! 'tis\n",
      "the counters,  \n",
      "\n",
      "[12m 36s (1300 26%) train loss: 1.7015, test_loss: 1.7520]\n",
      "Whe man me good you in the fack meland have not alight my lungerance you to like reshis but if you for \n",
      "\n",
      "[13m 5s (1350 27%) train loss: 1.6841, test_loss: 1.7218]\n",
      "What in the some this feise to thou deper'd, surnce, so?\n",
      "\n",
      "HERGETRA:\n",
      "I will come, or loak.\n",
      "Mark, as my  \n",
      "\n",
      "[13m 34s (1400 28%) train loss: 1.6905, test_loss: 1.7391]\n",
      "What so.\n",
      "\n",
      "ORLENO:\n",
      "A dis die,\n",
      "And bear, sir, his muck: nowed, now king an your love rotes at the king o \n",
      "\n",
      "[14m 3s (1450 28%) train loss: 1.6747, test_loss: 1.7448]\n",
      "What of stay, sure you is what hand; 't, presession not I should loating, he know the cacearf.\n",
      "\n",
      "PERIMI \n",
      "\n",
      "[14m 32s (1500 30%) train loss: 1.6487, test_loss: 1.7410]\n",
      "Whings wing\n",
      "The deady breathom thou arsion those my though an accuries distard of nature.\n",
      "\n",
      "LAUMES:\n",
      "Yea \n",
      "\n",
      "[15m 2s (1550 31%) train loss: 1.6698, test_loss: 1.7274]\n",
      "Whire now, I will the duise:\n",
      "To may grain, not that will be men I tels, farder'd my shall Tut how Clar \n",
      "\n",
      "[15m 31s (1600 32%) train loss: 1.6725, test_loss: 1.7250]\n",
      "Whied that like the time thou'ht that, when evere that do is your heart, and bring all to the honoue w \n",
      "\n",
      "[16m 0s (1650 33%) train loss: 1.6615, test_loss: 1.7286]\n",
      "Whank for I ged her long me?\n",
      "\n",
      "ESCALUS:\n",
      "I will thos your duke bowest marras, now! and that all thou hav \n",
      "\n",
      "[16m 29s (1700 34%) train loss: 1.6563, test_loss: 1.7373]\n",
      "Why was near bet an to blother, for the what this but the\n",
      "Manthing on his demp\n",
      "amony I worth thee for  \n",
      "\n",
      "[16m 58s (1750 35%) train loss: 1.6663, test_loss: 1.7114]\n",
      "When I range. Good:\n",
      "In scays with a broth.\n",
      "The kneed, I have they ba! then a prove; of my porder of su \n",
      "\n",
      "[17m 28s (1800 36%) train loss: 1.6287, test_loss: 1.7417]\n",
      "What callowers, my life that more men happinems.\n",
      "\n",
      "CASTAR: Look the bay queen it with haveroble,\n",
      "Coulse \n",
      "\n",
      "[17m 57s (1850 37%) train loss: 1.6545, test_loss: 1.7094]\n",
      "Whad of all my pray and the scorn of Caest atter king of the will in the the heard\n",
      "To stay on you shou \n",
      "\n",
      "[18m 27s (1900 38%) train loss: 1.6520, test_loss: 1.7243]\n",
      "Why soul and the king up the returf\n",
      "Even his lord.\n",
      "\n",
      "Che have clowing hate.\n",
      "O that we had yourst thou s \n",
      "\n",
      "[18m 56s (1950 39%) train loss: 1.6479, test_loss: 1.7372]\n",
      "When made by the that swell: and sir;\n",
      "And under you\n",
      "Unto all justeat Capless,\n",
      "Why whing be abonand you \n",
      "\n",
      "[19m 25s (2000 40%) train loss: 1.6709, test_loss: 1.7085]\n",
      "When shall that prrysems were lord, call him this is a read will purnes the coulds relige thee than th \n",
      "\n",
      "[19m 54s (2050 41%) train loss: 1.6398, test_loss: 1.7214]\n",
      "When our crion. What teasted a rack hang known to the kind his end\n",
      "Prain more says, and that encely, i \n",
      "\n",
      "[20m 23s (2100 42%) train loss: 1.6503, test_loss: 1.7086]\n",
      "When the hope,\n",
      "A ranour slave is for man talks it break in honour fuller me before awak.\n",
      "\n",
      "Forete show  \n",
      "\n",
      "[20m 53s (2150 43%) train loss: 1.6522, test_loss: 1.7147]\n",
      "Whe call your soverse\n",
      "At wourn this shall when the pray's would I am prose;\n",
      "And dook for which I have  \n",
      "\n",
      "[21m 22s (2200 44%) train loss: 1.6131, test_loss: 1.7061]\n",
      "Why Angerder'd.\n",
      "\n",
      "GORICLES:\n",
      "For deprates for he the fail the tongue of thine books in that wish him sco \n",
      "\n",
      "[21m 52s (2250 45%) train loss: 1.6789, test_loss: 1.7100]\n",
      "What what obless then lord the coor say, thou had that were the word:\n",
      "But master:\n",
      "The would!\n",
      "\n",
      "DON PEDR \n",
      "\n",
      "[22m 21s (2300 46%) train loss: 1.6507, test_loss: 1.6889]\n",
      "Why strong I have menney make let the hall, and love daymen me; and of servius with a beld:\n",
      "But see.\n",
      "\n",
      " \n",
      "\n",
      "[22m 50s (2350 47%) train loss: 1.6379, test_loss: 1.6913]\n",
      "Why now honour more in in the life do not me, the it, gown;\n",
      "You shall be merrain, benond bast thou art \n",
      "\n",
      "[23m 20s (2400 48%) train loss: 1.6398, test_loss: 1.6834]\n",
      "Why love of join my pall speak of\n",
      "poad,\n",
      "If thee me; the rast of by the anshes a noten him wewn chance  \n",
      "\n",
      "[23m 49s (2450 49%) train loss: 1.6243, test_loss: 1.6952]\n",
      "When should be be hast,\n",
      "Shall put and sive all and pleased an to and mad\n",
      "Which make your saine and and \n",
      "\n",
      "[24m 18s (2500 50%) train loss: 1.6278, test_loss: 1.7127]\n",
      "Why, he a nothing of ye:\n",
      "His own blounds, at your heart\n",
      "Some good, there will of his confeles, what he \n",
      "\n",
      "[24m 48s (2550 51%) train loss: 1.6357, test_loss: 1.6863]\n",
      "Whul reaguness beague. When those peakely adveriun him half death to his pray of thou look to make him \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25m 17s (2600 52%) train loss: 1.6351, test_loss: 1.7332]\n",
      "What,\n",
      "Thou handy bit Dend:\n",
      "Wholish he pronem's sent we have duke and glay that hath resent to Engendat \n",
      "\n",
      "[25m 47s (2650 53%) train loss: 1.6257, test_loss: 1.6786]\n",
      "Why love with his lenger the darcing which not to poory in my hand. I lord, sir, and part your humble  \n",
      "\n",
      "[26m 16s (2700 54%) train loss: 1.6254, test_loss: 1.6924]\n",
      "When the takery close now, by so starvess;\n",
      "and the help.\n",
      "\n",
      "TROILUS:\n",
      "Sald to be valation you stay hest i \n",
      "\n",
      "[26m 45s (2750 55%) train loss: 1.6564, test_loss: 1.6977]\n",
      "Whing not and Acood?\n",
      "\n",
      "First Gentleman:\n",
      "I have not breacts;\n",
      "Herilelous my thing no men shall with his t \n",
      "\n",
      "[27m 15s (2800 56%) train loss: 1.6230, test_loss: 1.7140]\n",
      "What is the payio of the sigger,\n",
      "I'll sent lives and indeed but old and mover'd from the can heart the \n",
      "\n",
      "[27m 45s (2850 56%) train loss: 1.6486, test_loss: 1.6934]\n",
      "When you are no more to the boy, or the word to hang ring hath deewing.\n",
      "\n",
      "MALTHO:\n",
      "Marder,\n",
      "Park of frien \n",
      "\n",
      "[28m 14s (2900 57%) train loss: 1.6098, test_loss: 1.6864]\n",
      "What welvets, my lord.\n",
      "\n",
      "BOULY:\n",
      "I\n",
      "will hath be thus enem: and to country; but and priended would your t \n",
      "\n",
      "[28m 44s (2950 59%) train loss: 1.6095, test_loss: 1.6937]\n",
      "Why love which is sounds\n",
      "he my very\n",
      "By the worthing for or faw, how, I triath'd; but in never wish wor \n",
      "\n",
      "[29m 13s (3000 60%) train loss: 1.6280, test_loss: 1.7114]\n",
      "When all a saw mar.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Good will be man hast that must to I am, all a heart,\n",
      "And eneman, a \n",
      "\n",
      "[29m 42s (3050 61%) train loss: 1.6162, test_loss: 1.6857]\n",
      "Why hither here upong; and the lottent her that bear is the face behold as mine and now the cowake a m \n",
      "\n",
      "[30m 12s (3100 62%) train loss: 1.6436, test_loss: 1.6762]\n",
      "Whing call your revery see and say, and vain sumble happities.\n",
      "\n",
      "FALSTAFF:\n",
      "A sad curse to my sunglan, a \n",
      "\n",
      "[30m 41s (3150 63%) train loss: 1.6143, test_loss: 1.7051]\n",
      "When make not a soul make him, and that Pectory, I door and do me see them. The brother.\n",
      "\n",
      "CRIS:\n",
      "The ea \n",
      "\n",
      "[31m 10s (3200 64%) train loss: 1.5919, test_loss: 1.7167]\n",
      "Whing still merrear my teal pactions.\n",
      "\n",
      "IAGO:\n",
      "As a preme, now as me! or of me find take thisself,\n",
      "With  \n",
      "\n",
      "[31m 40s (3250 65%) train loss: 1.5891, test_loss: 1.6828]\n",
      "Why lord:\n",
      "In unewast, who dear come is for me alight,\n",
      "And by his brother by let the diest which Ripted \n",
      "\n",
      "[32m 9s (3300 66%) train loss: 1.5988, test_loss: 1.7092]\n",
      "Why worse to the prinuse clord.\n",
      "All take the man? And thy poor there man you, he she wilt\n",
      "Bespery me a \n",
      "\n",
      "[32m 38s (3350 67%) train loss: 1.6150, test_loss: 1.6833]\n",
      "Why\n",
      "SI is E'll for his friends to the cays and give her house, make them.\n",
      "\n",
      "HAMORA:\n",
      "Good I ream of thes \n",
      "\n",
      "[33m 8s (3400 68%) train loss: 1.6435, test_loss: 1.6960]\n",
      "Wh:\n",
      "The low! But I have from Lord the baster a presartions-house, and\n",
      "Fine guddens is neich your how n \n",
      "\n",
      "[33m 37s (3450 69%) train loss: 1.6118, test_loss: 1.6920]\n",
      "Why shalt.\n",
      "\n",
      "SICINIUS:\n",
      "And thus know your hark roge the world; good the heaven.\n",
      "\n",
      "LEONTES:\n",
      "I will be pra \n",
      "\n",
      "[34m 6s (3500 70%) train loss: 1.6174, test_loss: 1.7066]\n",
      "When, that I canny, that we been called the bllace.\n",
      "Standed. Then Edst not the life, Copotice, a will  \n",
      "\n",
      "[34m 36s (3550 71%) train loss: 1.5829, test_loss: 1.6910]\n",
      "When I will doth of the tongues as so?\n",
      "\n",
      "CLISA:\n",
      "Things this hath come ear rememan with himself; for how \n",
      "\n",
      "[35m 6s (3600 72%) train loss: 1.6035, test_loss: 1.7070]\n",
      "When I have the catilented to him sut happe promise too follow my skings have never their were his whi \n",
      "\n",
      "[35m 38s (3650 73%) train loss: 1.6463, test_loss: 1.7231]\n",
      "Why share as is to good,\n",
      "'I wrym, the not is report too up amphersed them forth and whose like upon fo \n",
      "\n",
      "[36m 9s (3700 74%) train loss: 1.6064, test_loss: 1.6943]\n",
      "Why mon this conceiver again; or thee with fiend of my talk,\n",
      "To be proouf a will as he have not nother \n",
      "\n",
      "[36m 39s (3750 75%) train loss: 1.6095, test_loss: 1.6972]\n",
      "When I have hollow me, and I deatey\n",
      "And form have will a short?\n",
      "\n",
      "POMPEY MACILIA:\n",
      "Our facnow, it, seese \n",
      "\n",
      "[37m 9s (3800 76%) train loss: 1.6327, test_loss: 1.7036]\n",
      "When mine better\n",
      "This prevent us not more not the contages,\n",
      "I know the sand it poor justice, Master of \n",
      "\n",
      "[37m 40s (3850 77%) train loss: 1.6170, test_loss: 1.6918]\n",
      "What man,\n",
      "Madam, nothing in her a supplet they she know I would coment the parron's should speak sever \n",
      "\n",
      "[38m 12s (3900 78%) train loss: 1.6347, test_loss: 1.7239]\n",
      "Whing?\n",
      "\n",
      "DON PEDRO:\n",
      "A mother hearts,\n",
      "And when they did it is that he should could bister to wit they ha \n",
      "\n",
      "[38m 45s (3950 79%) train loss: 1.6236, test_loss: 1.6794]\n",
      "Whing all,\n",
      "My crown:\n",
      "Nearting in all a gragh the shall distament not shall I hope in his belove Jodes, \n",
      "\n",
      "[39m 16s (4000 80%) train loss: 1.5989, test_loss: 1.6906]\n",
      "Why, day is the motest are good but\n",
      "Than this could\n",
      "he betting that master person to me shall side.\n",
      "\n",
      "S \n",
      "\n",
      "[39m 46s (4050 81%) train loss: 1.6095, test_loss: 1.6715]\n",
      "Why,\n",
      "By stallowed their arms right.\n",
      "\n",
      "BOLIVER:\n",
      "Made shall thou art the glay\n",
      "Deinder that ey the to to t \n",
      "\n",
      "[40m 16s (4100 82%) train loss: 1.6212, test_loss: 1.6903]\n",
      "When you mush letholl inwird\n",
      "hards, the awin partis of that but the grevorse woreds own.\n",
      "\n",
      "WAS:\n",
      "Willows \n",
      "\n",
      "[40m 49s (4150 83%) train loss: 1.6217, test_loss: 1.6716]\n",
      "What they master an end of the trit.\n",
      "\n",
      "KING:\n",
      "Who come to me, she\n",
      "That thou should I am most mere thee,  \n",
      "\n",
      "[41m 19s (4200 84%) train loss: 1.5753, test_loss: 1.6819]\n",
      "Why lords thou thou neman it of his rody, we the fare thee believe my resent thy fast the king to the  \n",
      "\n",
      "[41m 48s (4250 85%) train loss: 1.6384, test_loss: 1.6961]\n",
      "Why, I shipleg of a noble as embited of the beatakes mush and happition have not the pate: the king re \n",
      "\n",
      "[42m 18s (4300 86%) train loss: 1.6027, test_loss: 1.7032]\n",
      "When fift the man,\n",
      "When you diss.\n",
      "\n",
      "FALSTAFF:\n",
      "That is you or more Herid.\n",
      "May make this master begats;\n",
      "A \n",
      "\n",
      "[42m 47s (4350 87%) train loss: 1.6326, test_loss: 1.6781]\n",
      "What, and forreetal give this whicith them obserpless, to the sun for the\n",
      "herb it stair princh if shal \n",
      "\n",
      "[43m 16s (4400 88%) train loss: 1.5956, test_loss: 1.6916]\n",
      "Whing court:\n",
      "The miling we think than indess, give all a marmsiners to be not please, he have for you  \n",
      "\n",
      "[43m 46s (4450 89%) train loss: 1.6093, test_loss: 1.7175]\n",
      "Whess her must thou is more live into a hall of the come forful say to the king, my breath. I shall no \n",
      "\n",
      "[44m 15s (4500 90%) train loss: 1.6220, test_loss: 1.6909]\n",
      "When is my viather.\n",
      "\n",
      "HELENA:\n",
      "You traint father what, there fail when you cry bestouse quaster; what,\n",
      "D \n",
      "\n",
      "[44m 44s (4550 91%) train loss: 1.6077, test_loss: 1.7029]\n",
      "When my soul that there with the many a sorged our fear we cannath and almay nature in from see warran \n",
      "\n",
      "[45m 14s (4600 92%) train loss: 1.6084, test_loss: 1.6980]\n",
      "Why with the sunsines\n",
      "true a youst and is--\n",
      "Four besty thee not be\n",
      "A ming, and your in this, shall con \n",
      "\n",
      "[45m 43s (4650 93%) train loss: 1.5937, test_loss: 1.6912]\n",
      "What mine thou art;\n",
      "Or mair, he loves himself,\n",
      "Lay a twis:\n",
      "For they of villain, which myself, the peac \n",
      "\n",
      "[46m 13s (4700 94%) train loss: 1.5770, test_loss: 1.7074]\n",
      "Wherch thy good mell, now say though, to from our poor from the lion for the marviots,\n",
      "We have me, tho \n",
      "\n",
      "[46m 42s (4750 95%) train loss: 1.6125, test_loss: 1.7166]\n",
      "When sir, they have laing of courtess, him hor that Cloting hear the convicisely,\n",
      "the said her\n",
      "Wast th \n",
      "\n",
      "[47m 11s (4800 96%) train loss: 1.6164, test_loss: 1.6764]\n",
      "Why adains deen I'll be her very wrop very good other sword that speak,\n",
      "And not lord these see her dis \n",
      "\n",
      "[47m 40s (4850 97%) train loss: 1.6211, test_loss: 1.6864]\n",
      "When I have jest the wife here, 'tis up.\n",
      "\n",
      "BRUTUS:\n",
      "Nay:\n",
      "The sayed my seer,\n",
      "For your kind herm, how love \n",
      "\n",
      "[48m 9s (4900 98%) train loss: 1.6645, test_loss: 1.7007]\n",
      "When that their trust shall to clech be nexe our runcer monfeat,\n",
      "And upon your wilt blief fortush'd by \n",
      "\n",
      "[48m 39s (4950 99%) train loss: 1.5823, test_loss: 1.7038]\n",
      "Whilit to themence o' the hight; proulon off.\n",
      "\n",
      "PROTEUS:\n",
      "He was the Marst and the sideman her faces dow \n",
      "\n",
      "[49m 8s (5000 100%) train loss: 1.6027, test_loss: 1.6820]\n",
      "Why come\n",
      "With your man thou shall so merriest you in pale.\n",
      "\n",
      "DUKE PERDINE:\n",
      "hoses seals awayion of untim \n",
      "\n",
      "This in least that all you the give\n",
      "The isen\n",
      "And my courth\n",
      "In own out of the would proption the foul afting, part of bold in the paped to none.\n",
      "\n",
      "BENEDICK:\n",
      "Shall so with grace that you place; that has by dean you, he did geas is dold man him; he\n",
      "gries, that and malt be brother all trough to your sonest\n",
      "To seemsed now day that fles her takes.\n",
      "Hort his yousfully.\n",
      "\n",
      "DEMETRIUS:\n",
      "My long of your Syles death leave could may, by thee, business he lost daughter speaus like it bardon\n",
      "That have a face.\n",
      "\n",
      "MORTUS:\n",
      "No, this no thougs deathes and reason him formone him.\n",
      "\n",
      "SICINIUS:\n",
      "My lord, and bear.\n",
      "\n",
      "DON PEDRY:\n",
      "That commandy the remamen\n",
      "they love?\n",
      "\n",
      "CORISHO: I cannot a mings their feed of his brance,\n",
      "Of Grance world is the madeful\n",
      "The heard the men the stolth her offence?\n",
      "\n",
      "PRINCE HENRY:\n",
      "he hath to see and liage, my lord to the deraction in this mother's blind\n",
      "Will sir:\n",
      "I cannly heart you handrer\n",
      "And is there my princes's best with the for justeat's parding his will be the do the lives of him.\n",
      "\n",
      "FALSTAFF:\n",
      "My\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### RNN\n",
    "\n",
    "learning_rate=0.002\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=\"rnn\", n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')\n",
    "\n",
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "[0m 34s (50 1%) train loss: 1.9963, test_loss: 2.0105]\n",
      "Whey agald thet heing hese\n",
      "'listuous Delle tors not I all thou seave and thym in the dear is furefortu \n",
      "\n",
      "[1m 8s (100 2%) train loss: 1.8134, test_loss: 1.8189]\n",
      "Whe dimed thou, for, and with thou here me, sens his poothing I was and sugind hat, me sovent; an so t \n",
      "\n",
      "[1m 42s (150 3%) train loss: 1.7045, test_loss: 1.7275]\n",
      "Who hour for he be the dunch!\n",
      "\n",
      "TIMON:\n",
      "All be done sill not was no scarted a caster contlid? I latwise  \n",
      "\n",
      "[2m 16s (200 4%) train loss: 1.6514, test_loss: 1.6782]\n",
      "Whick of him shall so queasing you my lime to the hand!\n",
      "\n",
      "THALLOV:\n",
      "What seed by sore\n",
      "So again it course \n",
      "\n",
      "[2m 50s (250 5%) train loss: 1.5920, test_loss: 1.6651]\n",
      "When Servanting than my will make of their will dispacesty be me like done and mind that itself, and n \n",
      "\n",
      "[3m 24s (300 6%) train loss: 1.5648, test_loss: 1.6263]\n",
      "Who, fagent more unclates and preward, they for greath in meit there's the blood,\n",
      "You have hast the gr \n",
      "\n",
      "[3m 57s (350 7%) train loss: 1.5333, test_loss: 1.6063]\n",
      "Where is a words and farewell, seeds the dever's life, with composs thee,\n",
      "She are the ear him the host \n",
      "\n",
      "[4m 31s (400 8%) train loss: 1.5330, test_loss: 1.6034]\n",
      "Who have to-day as he told askelies fast not to the nighted; and on the walk, and all this took it it  \n",
      "\n",
      "[5m 4s (450 9%) train loss: 1.5127, test_loss: 1.5689]\n",
      "Where a friend,\n",
      "Which than doth chots!\n",
      "\n",
      "BABERTIAN:\n",
      "Then every footed by my dear of a present at the he \n",
      "\n",
      "[5m 39s (500 10%) train loss: 1.4860, test_loss: 1.5587]\n",
      "Which provised, Lord Cassinable men of her own person,\n",
      "but speak and bloody.\n",
      "I will makest thou thing  \n",
      "\n",
      "[6m 13s (550 11%) train loss: 1.4487, test_loss: 1.5271]\n",
      "Which make a prepider lady;\n",
      "The kins to be the warthy of the\n",
      "roasor, how I often sense and talt but sh \n",
      "\n",
      "[6m 47s (600 12%) train loss: 1.4622, test_loss: 1.5593]\n",
      "Who could country and alone.\n",
      "\n",
      "BRUTUS:\n",
      "My lord,\n",
      "That thou shall not be man, with some went in the the m \n",
      "\n",
      "[7m 20s (650 13%) train loss: 1.4629, test_loss: 1.5578]\n",
      "What hath a makest note that small that now in a kingly charge well, mas is his thousand chance, my fr \n",
      "\n",
      "[7m 54s (700 14%) train loss: 1.4535, test_loss: 1.5343]\n",
      "Who erve good lawf\n",
      "As the next by them in this earth merchant contern,\n",
      "Before thou hast play the patie \n",
      "\n",
      "[8m 28s (750 15%) train loss: 1.4496, test_loss: 1.5419]\n",
      "Wh Murthare?\n",
      "What in a scurity of whole break, that\n",
      "Wherefore\n",
      "stand with him was not they?\n",
      "\n",
      "LAFEU:\n",
      "She \n",
      "\n",
      "[9m 1s (800 16%) train loss: 1.4508, test_loss: 1.5331]\n",
      "Which ever a husband follow'st first.\n",
      "\n",
      "ANTONIFF:\n",
      "And death and some something by her honour.\n",
      "\n",
      "First Se \n",
      "\n",
      "[9m 35s (850 17%) train loss: 1.4375, test_loss: 1.5353]\n",
      "White against cat a maid I ask in law this lady, and all,\n",
      "And, thus piege, 'tis incient them. I will,\n",
      " \n",
      "\n",
      "[10m 9s (900 18%) train loss: 1.4367, test_loss: 1.5001]\n",
      "Where shall go to my dispost, dost thou think there?\n",
      "\n",
      "First Soldier:\n",
      "Who, i' whom my peace; for an act \n",
      "\n",
      "[10m 42s (950 19%) train loss: 1.3917, test_loss: 1.5381]\n",
      "Where's a happy that have to the ortal\n",
      "Set for that serve the brother that makes me to my friend must  \n",
      "\n",
      "[11m 17s (1000 20%) train loss: 1.4134, test_loss: 1.5398]\n",
      "Which Yeily storm be so wink the warlians will I do not show the propose this? service?\n",
      "\n",
      "APEMANTUS:\n",
      "I  \n",
      "\n",
      "[11m 50s (1050 21%) train loss: 1.4158, test_loss: 1.5503]\n",
      "Whither?\n",
      "\n",
      "BARDOLPH:\n",
      "Stay, the beggorn'd,\n",
      "I love a prooth,\n",
      "No\n",
      "good Quid you shall never heard in the ki \n",
      "\n",
      "[12m 24s (1100 22%) train loss: 1.4075, test_loss: 1.4957]\n",
      "Which is him not to your subject cause in it under three distinces that was well who see you, my lord; \n",
      "\n",
      "[12m 58s (1150 23%) train loss: 1.3960, test_loss: 1.4800]\n",
      "What the parren forget the loss composed deward and he shall last do now the feasts of thy bride, and  \n",
      "\n",
      "[13m 32s (1200 24%) train loss: 1.4245, test_loss: 1.4883]\n",
      "Wherein break to me.\n",
      "\n",
      "LUCIUS:\n",
      "There ha\n",
      "Than you came a days\n",
      "Against the hose his instruy the counsello \n",
      "\n",
      "[14m 6s (1250 25%) train loss: 1.4328, test_loss: 1.5077]\n",
      "What it be there, thou didst he conditch'd and where for bitter have bature to receace\n",
      "To a purpose wi \n",
      "\n",
      "[14m 39s (1300 26%) train loss: 1.4007, test_loss: 1.5307]\n",
      "What far more than thy charmed conceit of the royal methinks honest in\n",
      "Satision do when a horse nothin \n",
      "\n",
      "[15m 13s (1350 27%) train loss: 1.4004, test_loss: 1.4933]\n",
      "Which of the lady of him, sir: what's then to godder is shall excellent confess all my show him; enter \n",
      "\n",
      "[15m 47s (1400 28%) train loss: 1.4170, test_loss: 1.4791]\n",
      "Why have you;\n",
      "For this Biron,\n",
      "Were young heaven, in the led within her heavens both they do'st thou ha \n",
      "\n",
      "[16m 21s (1450 28%) train loss: 1.3807, test_loss: 1.5281]\n",
      "What wounds your incliness that he stand.\n",
      "\n",
      "BERTRAM:\n",
      "Why, your carpary.\n",
      "\n",
      "COUNTESS:\n",
      "My lord,\n",
      "Bring at po \n",
      "\n",
      "[16m 54s (1500 30%) train loss: 1.4005, test_loss: 1.4849]\n",
      "What reason of your king;\n",
      "And there is the nether.\n",
      "\n",
      "DIOMEDES:\n",
      "'Tis alay.\n",
      "\n",
      "Chamling thou would'st meant \n",
      "\n",
      "[17m 29s (1550 31%) train loss: 1.4074, test_loss: 1.4772]\n",
      "What is my countenance to follow'd is while from your liberald, my lord.\n",
      "\n",
      "IAGO:\n",
      "I think I charge the b \n",
      "\n",
      "[18m 2s (1600 32%) train loss: 1.3634, test_loss: 1.5234]\n",
      "Where cannot follow op with your capirent without on those thought of this father, thou art to a perso \n",
      "\n",
      "[18m 35s (1650 33%) train loss: 1.3946, test_loss: 1.4877]\n",
      "Which this man didst we not say;\n",
      "Been welcome\n",
      "The very compass another, that the matter in skill.\n",
      "\n",
      "KIN \n",
      "\n",
      "[19m 8s (1700 34%) train loss: 1.3692, test_loss: 1.5025]\n",
      "What shall be the mantle is Nedge of word are at the business\n",
      "More assudied to you, sir? I am not our  \n",
      "\n",
      "[19m 41s (1750 35%) train loss: 1.3743, test_loss: 1.4845]\n",
      "Why would have seen thy son,\n",
      "Before chippy like your lady, lend their charity, fall and with\n",
      "Our ears  \n",
      "\n",
      "[20m 13s (1800 36%) train loss: 1.3945, test_loss: 1.4921]\n",
      "Why, no man in most grace!\n",
      "\n",
      "SHALLOW:\n",
      "We shall say then it good,\n",
      "Which in the poor signior,\n",
      "As Bardinal \n",
      "\n",
      "[20m 46s (1850 37%) train loss: 1.3756, test_loss: 1.5033]\n",
      "Who, do me my chate the good performing to yourself.\n",
      "\n",
      "ULYSSES:\n",
      "Yonder fall of the best five in his med \n",
      "\n",
      "[21m 19s (1900 38%) train loss: 1.3693, test_loss: 1.4984]\n",
      "What\n",
      "But I will stand, and her honest house the mistress, so I go:\n",
      "Nor win the drum\n",
      "Out of your own ju \n",
      "\n",
      "[21m 52s (1950 39%) train loss: 1.3691, test_loss: 1.4710]\n",
      "Whose general. O prosperous next here?\n",
      "\n",
      "LADY GREY:\n",
      "I have found in the right realm, we have stars: she \n",
      "\n",
      "[22m 25s (2000 40%) train loss: 1.3906, test_loss: 1.4749]\n",
      "Which she was a man.\n",
      "\n",
      "JULIET:\n",
      "O, what is here to still comes news from Warwick o'er is not a mal such  \n",
      "\n",
      "[22m 58s (2050 41%) train loss: 1.3948, test_loss: 1.4502]\n",
      "When it will ruled with him like a chain is the moon of breath, look, Rosent unbreathed words must not \n",
      "\n",
      "[23m 31s (2100 42%) train loss: 1.3799, test_loss: 1.4593]\n",
      "Whither I love forth with the age with place,\n",
      "Is he with me: 'tis a lady's now\n",
      "For the nose and his ho \n",
      "\n",
      "[24m 4s (2150 43%) train loss: 1.3909, test_loss: 1.4928]\n",
      "Which we had his favours!\n",
      "\n",
      "IACHIMO:\n",
      "You fasting wishes do be afflict them is holy brother snip, to her \n",
      "\n",
      "[24m 37s (2200 44%) train loss: 1.3601, test_loss: 1.4963]\n",
      "Whether, I will get\n",
      "Which dares as there of at me that makes jealousy.\n",
      "\n",
      "CORDELIA:\n",
      "I could not contembl \n",
      "\n",
      "[25m 12s (2250 45%) train loss: 1.3569, test_loss: 1.4721]\n",
      "Whose or cheeks that would not find the old wedding to good discourse.\n",
      "\n",
      "GREMIO:\n",
      "Your wits, with comfor \n",
      "\n",
      "[25m 45s (2300 46%) train loss: 1.3623, test_loss: 1.5051]\n",
      "What is not down and execy, a gentlemen,\n",
      "Making justly be the way withal.\n",
      "\n",
      "PRINCESS:\n",
      "And I shall have  \n",
      "\n",
      "[26m 20s (2350 47%) train loss: 1.3456, test_loss: 1.4946]\n",
      "When I would be so wise: farewell and spring; it rabe,\n",
      "When the greater to his mercy?\n",
      "When he charge m \n",
      "\n",
      "[26m 54s (2400 48%) train loss: 1.3496, test_loss: 1.4390]\n",
      "What says it were not 'lovest the strances and cry in the lovering easy to seathy of that weeping time \n",
      "\n",
      "[27m 29s (2450 49%) train loss: 1.3799, test_loss: 1.4953]\n",
      "When they 'tis fair penare to shake a poor asleep his soul to charge that noble breasts? is not that I \n",
      "\n",
      "[28m 3s (2500 50%) train loss: 1.3490, test_loss: 1.4683]\n",
      "Whither hath 'twere out of no grace of sovereignter'd man with her worse:\n",
      "So he is all this\n",
      "appear thi \n",
      "\n",
      "[28m 38s (2550 51%) train loss: 1.3231, test_loss: 1.4891]\n",
      "What do you made a thousand in the dead.\n",
      "\n",
      "First Gentleman:\n",
      "What means the day-wenther.\n",
      "Thy grave of my \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29m 13s (2600 52%) train loss: 1.3697, test_loss: 1.4821]\n",
      "Whose worfoll? what will countance of his force of and flatter me,\n",
      "Too fair more than from their\n",
      "purfe \n",
      "\n",
      "[29m 47s (2650 53%) train loss: 1.3489, test_loss: 1.4686]\n",
      "What sayest me with day with the match\n",
      "With servants, which he can do so true, what away: which, I war \n",
      "\n",
      "[30m 21s (2700 54%) train loss: 1.3643, test_loss: 1.4944]\n",
      "What you still as war his friend\n",
      "Upon'tish.\n",
      "\n",
      "ROSENCRANTZ:\n",
      "Good my lord, best from Maided, and every ma \n",
      "\n",
      "[30m 56s (2750 55%) train loss: 1.3461, test_loss: 1.4883]\n",
      "What yet first stand against him? what, arrusy the rest is conchoration thou be well be consul-heathle \n",
      "\n",
      "[31m 32s (2800 56%) train loss: 1.3785, test_loss: 1.4602]\n",
      "Whereus packets,\n",
      "That many way, is purse is to the more subjects, rite of the last\n",
      "Thou hast thee lear \n",
      "\n",
      "[32m 6s (2850 56%) train loss: 1.3664, test_loss: 1.4912]\n",
      "Which we are frost of royal grace time makes revenge, here comes thee, shall, my lord.\n",
      "\n",
      "KING HENRY SOL \n",
      "\n",
      "[32m 40s (2900 57%) train loss: 1.3751, test_loss: 1.4847]\n",
      "What is the enter'd.\n",
      "I take my mother gord:\n",
      "A presence to the house, sir, that the more than an each m \n",
      "\n",
      "[33m 15s (2950 59%) train loss: 1.3626, test_loss: 1.4865]\n",
      "Which you do so did the stanch is gone she not but thou wilt distilent death.\n",
      "\n",
      "MECAENAS:\n",
      "I have manife \n",
      "\n",
      "[33m 50s (3000 60%) train loss: 1.3500, test_loss: 1.5018]\n",
      "Which of your love, they can given in, my lord, you must not lawness, and we did here they feel them t \n",
      "\n",
      "[34m 24s (3050 61%) train loss: 1.3585, test_loss: 1.4786]\n",
      "When you compen:\n",
      "'Sy the ballad.\n",
      "\n",
      "DOMITIUS ENOBARBUS:\n",
      "And so to the disarror of love with you, I.\n",
      "\n",
      "DUK \n",
      "\n",
      "[34m 59s (3100 62%) train loss: 1.3522, test_loss: 1.4576]\n",
      "Which I am to be made a parts o'er most often part and every heads to be the worships a misprison shou \n",
      "\n",
      "[35m 33s (3150 63%) train loss: 1.3545, test_loss: 1.4656]\n",
      "Why? Caesar: all as he\n",
      "hath so, my more than excellet here no mooker, counsel to way,\n",
      "If the rest\n",
      "That \n",
      "\n",
      "[36m 7s (3200 64%) train loss: 1.3521, test_loss: 1.4857]\n",
      "Which art thou comes a man and had the world as your daughter than to do it, himself in gallants:\n",
      "O Go \n",
      "\n",
      "[36m 42s (3250 65%) train loss: 1.3511, test_loss: 1.4810]\n",
      "What day to have them light,\n",
      "That the Desdecompens and commention to see your husband to mine help in  \n",
      "\n",
      "[37m 16s (3300 66%) train loss: 1.3495, test_loss: 1.4642]\n",
      "Whose that the Troilus, what they are done away to sing! your dead pride, all that this seven male me  \n",
      "\n",
      "[37m 50s (3350 67%) train loss: 1.3587, test_loss: 1.5216]\n",
      "Which you make her hence, to kill thee well,\n",
      "That I am daughter that I do conquer the country stomache \n",
      "\n",
      "[38m 20s (3400 68%) train loss: 1.3750, test_loss: 1.4686]\n",
      "When hold:\n",
      "Then he may try her hazard it tell these womanish\n",
      "begin thy cause nor one too off, not more \n",
      "\n",
      "[38m 50s (3450 69%) train loss: 1.3676, test_loss: 1.4712]\n",
      "What thou soulish sheep to the air at odds but a general!\n",
      "\n",
      "TIMON:\n",
      "Good morrow, by a blews are confess, \n",
      "\n",
      "[39m 21s (3500 70%) train loss: 1.3685, test_loss: 1.4761]\n",
      "What, is thee to see him between tears,\n",
      "That see the brother air i' the Hern been with which I see I b \n",
      "\n",
      "[39m 52s (3550 71%) train loss: 1.3556, test_loss: 1.5002]\n",
      "Which they are weak the golden man is he hath revenged the blood is dead, I saw as till old, my lord.\n",
      " \n",
      "\n",
      "[40m 21s (3600 72%) train loss: 1.3517, test_loss: 1.4944]\n",
      "Whither she were a brother of painting on the world we know\n",
      "In warrant of desperate,\n",
      "Only being dam\n",
      "An \n",
      "\n",
      "[40m 50s (3650 73%) train loss: 1.3834, test_loss: 1.4634]\n",
      "What comes a sick\n",
      "suffence.\n",
      "\n",
      "First Servingless and lost his prince. I can contrem.\n",
      "\n",
      "PANDARUS:\n",
      "If thou  \n",
      "\n",
      "[41m 19s (3700 74%) train loss: 1.3524, test_loss: 1.4707]\n",
      "What shall lend it for the cup of their hand\n",
      "Of engine your wife, and then proved flesh is world wink, \n",
      "\n",
      "[41m 49s (3750 75%) train loss: 1.3611, test_loss: 1.4639]\n",
      "Which so frame to so, from thy chilling\n",
      "within proud many speak me about the French good lieutenant, a \n",
      "\n",
      "[42m 18s (3800 76%) train loss: 1.3573, test_loss: 1.4789]\n",
      "When shall I set infecial wife: we shall be love's command:\n",
      "A low and small the curtains that shall ha \n",
      "\n",
      "[42m 47s (3850 77%) train loss: 1.3586, test_loss: 1.4894]\n",
      "Who hath in the sequlous charity,\n",
      "And between my daughter; and back his fellow.\n",
      "\n",
      "CARDINAL WOLSEY:\n",
      "'Tis \n",
      "\n",
      "[43m 16s (3900 78%) train loss: 1.3458, test_loss: 1.5057]\n",
      "Which they pluck'd the door! I have acquial hands himself, how now, most minder of the cover'd it for  \n",
      "\n",
      "[43m 45s (3950 79%) train loss: 1.3253, test_loss: 1.4869]\n",
      "What's the like Paduments perfectest fast of gold;\n",
      "The noble unto the field?\n",
      "\n",
      "TITUS ANDRONICUS:\n",
      "My lor \n",
      "\n",
      "[44m 15s (4000 80%) train loss: 1.3427, test_loss: 1.4755]\n",
      "What! it safe shall.\n",
      "\n",
      "DUKE:\n",
      "And since I appear by name you are craves, sir, therefore not enough a wom \n",
      "\n",
      "[44m 44s (4050 81%) train loss: 1.3541, test_loss: 1.5191]\n",
      "What thou came to cry 'be as any flood is to holy news of this gentlemen; he shall so does his bond.\n",
      "\n",
      " \n",
      "\n",
      "[45m 13s (4100 82%) train loss: 1.3824, test_loss: 1.4739]\n",
      "What, shall they did be a gentlemen. There her husband, here\n",
      "understand, sir?\n",
      "\n",
      "GLOUCESTER:\n",
      "O that, to\n",
      " \n",
      "\n",
      "[45m 42s (4150 83%) train loss: 1.3463, test_loss: 1.4780]\n",
      "Which I with her.\n",
      "\n",
      "SAMERO:\n",
      "And he's breathed with by the prayers contents:\n",
      "But has thus from the grave \n",
      "\n",
      "[46m 11s (4200 84%) train loss: 1.3169, test_loss: 1.4943]\n",
      "Which made him with him, and because they will, pardon me to sup with a bond image before himself\n",
      "And  \n",
      "\n",
      "[46m 41s (4250 85%) train loss: 1.3437, test_loss: 1.4686]\n",
      "Which to woo given you for himself: and loud?\n",
      "\n",
      "Part, and the king, but a honesty of Trojan! he is as a \n",
      "\n",
      "[47m 10s (4300 86%) train loss: 1.3460, test_loss: 1.5113]\n",
      "What?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "By heart, 'tis a mouths have not the fame of another sun-like time himself?\n",
      "\n",
      "RI \n",
      "\n",
      "[47m 39s (4350 87%) train loss: 1.3416, test_loss: 1.4630]\n",
      "Which may not stir\n",
      "To meet some soul--\n",
      "\n",
      "DIANA Prote me and law's tongue, the world from me, that, I am \n",
      "\n",
      "[48m 8s (4400 88%) train loss: 1.3494, test_loss: 1.4728]\n",
      "Where that shall left them in country, and say 'twere to sink to serve, how then, and an earth on thee \n",
      "\n",
      "[48m 38s (4450 89%) train loss: 1.3371, test_loss: 1.5023]\n",
      "Whose means and so enough three him.\n",
      "I sofoly and beauty all mother.\n",
      "\n",
      "Messings; but an unname of your  \n",
      "\n",
      "[49m 7s (4500 90%) train loss: 1.3546, test_loss: 1.4542]\n",
      "Which in Buckishes;\n",
      "Admit in ensolve, doth pays for their son.\n",
      "\n",
      "CASSIUS:\n",
      "Fair lights and sorts.\n",
      "\n",
      "ROSAL \n",
      "\n",
      "[49m 36s (4550 91%) train loss: 1.3389, test_loss: 1.4692]\n",
      "Who are so grief in thy desire.\n",
      "\n",
      "MARCUS ANDRONICUS:\n",
      "Here is yourself.\n",
      "\n",
      "CRESSIDA:\n",
      "Nay, sir,' stays of h \n",
      "\n",
      "[50m 6s (4600 92%) train loss: 1.3609, test_loss: 1.4467]\n",
      "Why has me, sir, thou shalt\n",
      "be our looks with the right with the king comes me: 'tis no more for a for \n",
      "\n",
      "[50m 35s (4650 93%) train loss: 1.3656, test_loss: 1.4942]\n",
      "Which any thing hearts to a play of me\n",
      "Into his flame\n",
      "And in some sented them in my dear plave the sav \n",
      "\n",
      "[51m 4s (4700 94%) train loss: 1.3471, test_loss: 1.4667]\n",
      "Why, mend you to ask that\n",
      "need him that art thou at thy house.\n",
      "But has not that a\n",
      "thicken hath been pa \n",
      "\n",
      "[51m 34s (4750 95%) train loss: 1.3591, test_loss: 1.4900]\n",
      "What wouldst thou lives not hers and let you swear in the sun'st thou betters there is never be it and \n",
      "\n",
      "[52m 3s (4800 96%) train loss: 1.3549, test_loss: 1.4736]\n",
      "Whence?\n",
      "\n",
      "PETRUCHIO:\n",
      "Sufficle, I entreat me in admiral spite,\n",
      "Such cousin, as a' do married? be seals I \n",
      "\n",
      "[52m 32s (4850 97%) train loss: 1.3429, test_loss: 1.5042]\n",
      "What is this delivered; no more, which is a country's father:\n",
      "And fly the contempts but what I may com \n",
      "\n",
      "[53m 2s (4900 98%) train loss: 1.3356, test_loss: 1.4916]\n",
      "Which be such a harm, and my brother Moor shall be the booked for\n",
      "the living. There is thy tongues all \n",
      "\n",
      "[53m 31s (4950 99%) train loss: 1.3469, test_loss: 1.5060]\n",
      "When it be sleeps to be a scorn it in my mother to Marina.\n",
      "\n",
      "Second Gentleman:\n",
      "A vexity, your party, an \n",
      "\n",
      "[54m 1s (5000 100%) train loss: 1.3435, test_loss: 1.4940]\n",
      "Which is a man besonger standon me out of weight on your hands, you will be to the richly person to me \n",
      "\n",
      "The uncip of fortune\n",
      "Than Talbo, not a man\n",
      "And light.\n",
      "\n",
      "ORLEANS:\n",
      "All mine own but a wood and slanderness,\n",
      "And say thou canst not not love this budges him well and resist! give a pictures must thou love it,\n",
      "As they shall our lady who with my son of Turks\n",
      "Do me many fair suffice in my love, a man law like the enemies lose the worthy Denmerious; he knows 'em and kill my lurnorance! What, would he shall born him.\n",
      "\n",
      "DOGBERRY:\n",
      "Who be sorry for not to a composing proud souls melting tended me, and well meching of English part the news, were it in the death for a shorted and dare thy paring,\n",
      "Our spoken; speak you are\n",
      "For her welcome to whom we will strick about her, where I behold me not?\n",
      "Torm upon me: therefore lies it in this night and the ear-so appeher hath meet them de and leaves;\n",
      "Conveyar story to break too much, to hear me, be with him sweet.\n",
      "\n",
      "FALSTAFF:\n",
      "Adieu.\n",
      "\n",
      "LAUNCE:\n",
      "Hail should not dispatch a good sleep ye;\n",
      "I thank you, signior Brutain'd the reple\n",
      "Of fear, I met he sense and adminian and\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcXGWd7/HPU3tV7+nupLd09gSSEJIQIAIiGFRABBUXFHRmxEHHDZm5L7f7uuP1jl69M8oILiCDiAyKCyIggoKsIiTQISEhCZB96SzdnU7vXftz/3gqSSfpTjehOtVV/X2/Xv1KV9WpOr9TJ/09z3nOc84x1lpERKSweHJdgIiIZJ/CXUSkACncRUQKkMJdRKQAKdxFRAqQwl1EpAAp3EVECpDCXUSkACncRUQKkC9XM66qqrJTp07N1exFRPLSypUr26y11cNNl7Nwnzp1Kk1NTbmavYhIXjLGbB/JdOqWEREpQAp3EZECpHAXESlACncRkQKkcBcRKUAKdxGRAqRwFxEpQHkX7q/t7eZ7j77G/p5YrksRERmz8i7cN7f28IMnNtGqcBcRGVLehXvI70qOJtI5rkREZOzKv3D3eQGIJlI5rkREZOzKu3AP+hXuIiLDybtwV7eMiMjw8jDcXcs9llTLXURkKHkb7uqWEREZWv6FeyJGQ+c+4n3RXJciIjJm5V24F/3pjzx767UEtm/NdSkiImNW3oW7v6QYgHR3b44rEREZu/Iu3L0Hw71P4S4iMpS8C3ciEQBsb1+OCxERGbvyL9yLity/vWq5i4gMJf/CPdNyN31quYuIDCV/w71f4S4iMpT8C/dMt4xH4S4iMqT8C/dMy93T35/jQkRExq78C3e/n6TXi1fhLiIypPwLdyAeCOOLqltGRGQo+RnuwRC+mK4tIyIylGHD3Rgz2RjzpDFmvTFmnTHm+kGmudoYs8YYs9YY85wx5vTRKddJBsP4owp3EZGh+EYwTRL4F2vtS8aYEmClMeYxa+36AdNsBd5mrT1gjLkEuA04exTqBSARChOIqVtGRGQow4a7tXYPsCfze7cxZgNQD6wfMM1zA96yHGjIcp1HSIXC+ONquYuIDOUN9bkbY6YCi4AVx5nsWuCREy9peKlQmGA8NpqzEBHJayMOd2NMMfA74IvW2q4hprkQF+5fHuL164wxTcaYptbW1hOpF4BUJEI4HiWR0n1URUQGM6JwN8b4ccH+C2vtfUNMswC4HbjCWrt/sGmstbdZa5dYa5dUV1efaM3YcJhQMqZb7YmIDGEko2UM8FNgg7X2xiGmaQTuAz5mrX09uyUey4YjROJRogm13EVEBjOS0TLnAh8D1hpjVmee+xrQCGCtvRX4V6AS+LHbFpC01i7JfrmOjRQRTsboSarlLiIymJGMlnkWMMNM80ngk9kqalhFYcKJGG1quYuIDCovz1A1kSKCqQTRaDzXpYiIjEn5Ge7F7rK/ie7uHFciIjI25WW4e4oOhrtutSciMpi8DHfvwZZ7V0+OKxERGZvyM9xLigFIquUuIjKovAx3f6blnupRy11EZDB5Ge6+TMs93atwFxEZTF6Ge6C0BIB0jy77KyIymLwMd3+J65ZJ9yrcRUQGk5fhHihzLXfULSMiMqi8DHeTGedOX39uCxERGaPyMtyJRAAw/eqWEREZTH6He5/GuYuIDCY/w93rJebz4+lXt4yIyGDyM9yBuD+kcBcRGULehnssGManPncRkUHlbbjHgyG8MbXcRUQGk7fhngiE8EejuS5DRGRMyt9wD4Xxq+UuIjKovA33ZChMIKaWu4jIYPI43EME4gp3EZHB5G24p8IRguqWEREZVN6GezocIZSI5boMEZExKW/D3YbDhBIxrLW5LkVEZMzJ33CPFBFORIkl07kuRURkzMnbcCcSwZ9OEe3TQVURkaPldbgDxDp1ww4RkaPlbbgfvGFHvKs7x5WIiIw9eRvunoPh3q1wFxE5Wv6Ge7Hrlkl064YdIiJHy9tw95YUA5DsUp+7iMjR8jbcfcWuWybZo3AXETnasOFujJlsjHnSGLPeGLPOGHP9INMYY8zNxphNxpg1xpjFo1PuYd5i13JP9eiGHSIiR/ONYJok8C/W2peMMSXASmPMY9ba9QOmuQSYlfk5G7gl8++o8Ze6cLdquYuIHGPYlru1do+19qXM793ABqD+qMmuAO6yznKg3BhTm/VqBwhkwj3dqwOqIiJHe0N97saYqcAiYMVRL9UDOwc83sWxG4CsCmQOqNo+dcuIiBxtxOFujCkGfgd80VrbdSIzM8ZcZ4xpMsY0tba2nshHHBIsL3W/qOUuInKMEYW7McaPC/ZfWGvvG2SSZmDygMcNmeeOYK29zVq7xFq7pLq6+kTqPSSUGeeOWu4iIscYyWgZA/wU2GCtvXGIyR4EPp4ZNbMU6LTW7slincfw+X30+4KYXoW7iMjRRjJa5lzgY8BaY8zqzHNfAxoBrLW3Ag8DlwKbgD7gH7Jf6rH6AyFMv8JdRORow4a7tfZZwAwzjQU+m62iRirmD+KJ6lZ7IiJHy9szVAFigRBe9bmLiBwjv8M9GMKnlruIyDHyOtwTgRC+mO7EJCJytPwO92AIf1TdMiIiR8vvcA9F8KvlLiJyjLwO92QoTCCucBcROVpeh3sqFCKolruIyDHyO9zDEYJquYuIHCOvwz0djhBMxMDaXJciIjKm5HW423AYr01DLJbrUkRExpT8Dvcidx9VXRlSRORIeR3uRNxlf5PdutWeiMhAeR3uJhPusa7uHFciIjK25He4F7tb7cW71HIXERkor8PdU+Ra7onOE7rrn4hIwcrrcE/X1Lh/dx5zRz8RkXEtr8M9NWWa+2Xb1twWIiIyxuR1uPvLSmiLlOHdvi3XpYiIjCl5He7lkQC7yibh2bYt16WIiIwpeR3utWUhdpZNwr9je65LEREZU/I63KuKg+yqqKVobzOkUrkuR0RkzMjrcPd6DJ01DXhTSdi1K9fliIiMGXkd7gCxyY3ul60aMSMiclDeh7udOtX9onAXETkk78M9NGMaKePBbt6c61JERMaMvA/3iRNK2FNSRXzTllyXIiIyZuR9uNeVh9hZPonkZoW7iMhBeR/uNWVhdpZNwqezVEVEDsn7cK/LnMgUbN0H/f25LkdEZEzI+3CvLA7SXFHrHugyBCIiQAGEu9dj6K3XWHcRkYGGDXdjzB3GmBZjzCtDvF5mjPmDMeZlY8w6Y8w/ZL/M40tNmeJ+UbiLiAAja7nfCVx8nNc/C6y31p4OXAB8zxgTePOljVy4sYGYL6BwFxHJGDbcrbXPAO3HmwQoMcYYoDgzbTI75Y1MbXmYneWTsFs0HFJEBLLT5/5D4FRgN7AWuN5am87C545YbVmIHaWTSGmsu4gIkJ1wfxewGqgDFgI/NMaUDjahMeY6Y0yTMaaptbU1C7N2asvciUxGt9sTEQGyE+7/ANxnnU3AVuCUwSa01t5mrV1irV1SXV2dhVk7tZkTmbxdXXDgQNY+V0QkX2Uj3HcAywCMMZOAOcBJ7R9xLfca90D97iIi+IabwBhzD24UTJUxZhfwdcAPYK29Ffg34E5jzFrAAF+21raNWsWDqCoOsmtCnXuwcSOcccbJnL2IyJgzbLhbaz8yzOu7gXdmraIT4PEYuqfNIuEP4G9qgquuymU5IiI5l/dnqB40qbKYbQ2z4MUXc12KiEjOFUy415SFWVs7C1au1M2yRWTcK5hwrysLsbxyBvT2wquv5rocEZGcKphwrykLsXLiTPdAXTMiMs4VTLjXloXZUllPqrhE4S4i417BhHtdeQhrPHSceprCXUTGvYIJ95kTizEGtk47FV5+GeLxXJckIpIzBRPukYCP6VVFvFg10wX7mjW5LklEJGcKJtwB5teX8WjRZPdAXTMiMo4VVrjXlbHKlJGeUKlwF5FxraDCfV59KRhDx7zTFe4iMq4VVrjXlgGweeqpsH69O6FJRGQcKqhwL4v4mTwhTFP1TEin4aWXcl2SiEhOFFS4g+t3/1PxFPB44OGHc12OiEhOFFy4z6sr5eVYgMQll8DPfqbx7iIyLhVeuNdn+t3fdw3s2wcPPJDjikRETr6CC/f5dS7cn5u5BBob4Sc/yXFFIiInX8GFe3VJkIklQV7Z2wPXXQePP+5uvSciMo4UXLiDO1P1ld2d8IlPgM8Ht92W65JERE6qwgz3ulI2tfTQXzkRrrjCHViNRnNdlojISVOQ4T63roy0hVf3dsGnPgX798O99+a6LBGRk6Ygw/20BndQddWODli2DGbPhptuAmtzXJmIyMlRkOFeXx5mWlURT7/e6k5muuEGaGqCZ5/NdWkiIidFQYY7wNtmV7N8y36iiRR8/OMwYQLceGOuyxIROSkKNtwvmFNNLJnm+S37IRKBf/ond0LTpk25Lk1EZNQVbLgvnV5J0Ofh6dda3ROf/Sz4/a7vXUSkwBVsuIf8Xs6ZUclTr7W4J2pr4aMfhTvugAMHcluciMgoK9hwB7hgzkS27e9jW1vmuu433AB9fep7F5GCV+DhXg1wuPW+YIFrvX/727B8eQ4rExEZXQUd7lMqi5hWVcRTr7cefvJHP4KGBhfyXV25K05EZBQVdLiDGxL5/ObMkEiA8nL45S9h+3Z3kFVEpAAVfLgfHBK5fMv+w0+ecw58/etw991w++25K05EZJQMG+7GmDuMMS3GmFeOM80FxpjVxph1xpins1vim7N0eiVFAS8Pvrz7yBe+9jW46CJ3WeBbb81NcSIio2QkLfc7gYuHetEYUw78GLjcWjsP+GB2SsuOkN/L+xbX89CaPRzoHXDLPZ8PHnwQ3v1ud4LTt7+ta8+ISMEYNtyttc8A7ceZ5KPAfdbaHZnpW7JUW9Zcs3QK8WSae1fuOvKFcBjuuw+uvtq15P/1X3NToIhIlmWjz302UGGMecoYs9IY8/EsfGZWnVJTyplTK/jFiu2k00e1zv1+uOsu+OQn4ZvfVB+8iBSEbIS7DzgDeDfwLuB/GWNmDzahMeY6Y0yTMaaptbV1sElGzTVLp7Btfx/Pbmo79kWPB265BS6+GD79aXjssZNam4hItmUj3HcBf7bW9lpr24BngNMHm9Bae5u1dom1dkl1dXUWZj1yF8+vobIowN3Ltw8+gc8Hv/41zJ0LH/gArFt3UusTEcmmbIT7A8B5xhifMSYCnA1syMLnZlXQ5+VDZ07mLxv2sbujf/CJSkvhoYfcVSTPPdfdnk8HWUUkD41kKOQ9wPPAHGPMLmPMtcaYTxtjPg1grd0A/AlYA7wA3G6tHXLYZC599KxGLHDX80O03gEaG+Gvf3WXKvjEJ+DSS2HnzpNWo4hINhibo5bpkiVLbFNT00mf7+fvWcVf1u/jmS9dSHVJcOgJ02n48Y/hK19xffI33gjXXgvGnLxiRUSOYoxZaa1dMtx0BX+G6tFuuGgW8VSaHz05zE07PB743OdgzRo44wz4x3+Ed73LXbZARGSMG3fhPr26mA+e0cAvV+xg14G+EbxhOjz+uGvFP/cczJwJV14JDz8MqdToFywicgLGXbgDfGHZLABufnzjyN7g8bizWNetg+uvh2eecWe2zp4NTzwxipWKiJyYcRnudeVhrlk6hXtX7mJza8/I3zhlCnz3u9DcDL/5DXi9sGwZfOYz0PMGPkdEZJSNy3AH+MyFMwj5vfzvB9cde9bqcAIB+OAHYfVq+Od/dhcemz0bvvhFePJJSCZHp2gRkREat+FeVRzka5eeyl83tnHH37ae2IdEIvC977mhk2ec4UL+7W9392v9znegtze7RYuIjNC4Gwo5kLWWT/33Sp58rYXff+Zc5teXvbkP7O2FRx+F//oveOQRqK52ffQTJkB/v2vRz50LZ54JkyZlZyFEZFwZ6VDIcR3uAAd641xy01+JBLz84fPnURT0ZeeDn3/eXWXyL38Z/PXGRvjQh9z15GfNys48RaTgKdzfgOc2t3H17Su4cnED3/3goJfFOXF79rjRNuGwe7xmDbzwAjz9NPzxj2445YUXugOz8+e7n+nTdbKUiAxK4f4G3fjoa9z8xCb+/coFfOjMySdnpnv2uOvX/Pzn8Prrh5+fORP+/u/hYx9zLXwRkQyF+xuUSls+fscKmrYd4L7PnMO8ujfZ//5GdXfDhg3w0kvu6pRPPeVa78XFrnWfSrk9AJ/P/cyZ424y8uEPu759ERkXFO4noK0nxmU3P0vQ7+HBz51HWdifu2K2boV77oGWFhfmXq+7QmUyCfG4G6GzZo17bdkyd4GzSy5R/71IgVO4n6Cmbe1cddtyzptVxW0fW0LAN4ZHi65ZA3ffDQ88cLhbp7j48EagvNyF/uWXwwUXQDB4uC//4HpPJqGtzW1E+vvdpY79OdyoichxKdzfhF+u2MHXfr+Wd82bxA8/uhi/dwwH/EGbN8Of/gSbNrlWvs/nLnL2yCPQ2Tnyz5kxA77+dfjoR92ZuHff7a5xf9pp7rm3vtV1D4lITijc36Q7nt3K/3loPZctqOX7H16ILx8CfjCJhLsWzsqV7jLG4Frtxrgfrxeqqly/fW8vfPvb7szbmhrYu9dNv2gRvPYa9PVBfT0sXeq6f2bNcmP4g0F31u6ECdDQ4D4vlYLdu90Gpr/f3QiltBTq6twexUhYC/v2uXMCNHpIBBh5uGdpUHfh+cR500im0/zfh1/F6zF874On52fA+/2uT37ZspFN/4EPwO9/D3feCWedBddcA9OmueB/8EG4915Yu9Z1BQ11mYVA4PBB4MHMmuU+e8ECF9zV1e6s3hkz3AYgGnV7DP/5n7B+vXv+iivgPe9x74tETuiroLcX7rgDfvhDtwH65jfdMFSRAqSW+zB+/NQm/v1Pr3HxvBpu/siisd0HfzIlk7Bjh+vyicchFnN997t2ue4cv99daG3KFBfG3d3Q1eUOFL/wAqxY4Vr2R6uudhuF9nZYuNBdXvlvf3NX34zHXZfQ3Llub6KszO01BINuo1BR4fYe5s1zo4k8Hre30tQE993nzhxub4e3vMXVuXMnvPOd7pjEweMOsZg7blFcfPgzKyrc3sbB50MhV2My6T4/EDiyjkjkyGMbqZTrJhvsO/R6j5x2+XK4/37XDXb11SPbY7HWfTfB49x85o06cMAN0Z0xw904vhCOw6xe7fYily498nvt6oKODpg8OS/2ENVyz5LPXDCToM/Lvz20nuv+u4lbrzmDkN+b67Jyz+dzJ1u9Gd3d0NrqQrW52R032LTJ/QF+4hPuIPDBP7bubjc8tKnJ/Tz1lGuJx2KupX/0XkJZGSxe7IaX7t3rQvSyy+BLX4JzznHv+fGP4VvfcpeMAKisdEHd2+uu8nmwG+uN8vmgqMh1ifX3u/AtL3ddUpMmuSBpbnbLXV7uzmuYOhVefNF1Yxnj3vOb38Btt7kuMnDL0d7uNiDl5e67+tWv3HRbt7plrqmBU05xdxBbuvTY2vr73VnTf/ub25BOm+bm3djolj+ZhFtugW98w80LYOJEt6G57DK351Rc7J5PJmHbNrcOysvd/KNRt9Hfvt1tvFtb3c+ECfCpT7luu4Hr/9VX3WvV1VBSMni4plKwZYsbQLBhg1s/iYT7KSlxdVdVufU9d+6xn9HZCV/+MvzkJ+7xnDnwyU+69/3ud279JxLu8RlnHB5xZq37ri+6yB1rCgSGX/fptFu/LS3u39mz3fId1NfnRrrV1bkN+ChSy32EfvXCDr76+7UsaCjnf7xzNufNrMLkwVZ+XLDW/dEcOOBa4KtWuT2DlSvdBujyy90w0YF/ZAf197s/wqqqI1unAz/zwAE3zcHQ7+8/fL6BMYf3XKJR1wrs7HTTBQLuzGS/3wXc7t3uGEJ5uTt2UVMD+/fDxo0uvGbNgquucvXeeSd89atuI3H++W6DNti9fH0+Fz5veYv7rD173IavtdWF8ec/70J60yb3vfz5z245vN5jN4jhsNvr2L/fdeN95zvu837+c9cll0i4vaH58917N250yz6cigr3nXg88JGPuOX5wx9cLbHY4enKylzX24c/DOed5zZCv/2tuzHOwEtq+/3uu/V6j90I19W572PGDLeHBXDTTW7DeMMNbq/u9tvdjXfA7VleeaWbftUq9z1v3+5qNcbVnUi4Ddo557gaQyG3UZk5021IJ050gf3II+74VjR65PLPnw9nn+3WwfPPu+/sc5+DH/xg+O9uEDqgOgr+uGYP3/jDOlq6Y8yrK+WfLpjBJfNr8XoU8jIKNmyAT3/atfLPOsv91NQc3oBMmOCORVRVHfm+nh64+Wb4j/9wG6WDpkxxG7n3vc/tFfX2upb31q1uw7Fjh9sofPjDbgjtwMZLR4frMnr+ebfhDAZdsM2Z4zZAnZ3uJxBw82lsdEFbWenCeNs2+P73XbD29roW/JVXwtve5pantdXdDOeBB9zG9KDqanjve91eyIIFrmU+8JjLwZbyvn1ub+Sxx1wXXlvb4WkWLHDzPfPMw8+9+qrbSC9cePyumN5e93kPP+y6E/v7DzcIBn63AKeeCu94h9sbqq52rf6XX3bB/8IL7vlly9zG57zz3Pd2AhTuoySWTHH/qmZ+8swWtrT2MmtiMV9YNotLT1PIyxhz4IAL5MmT3R7MiR6IznZNO3e61uxgQ2rjcddiX77cbYDOP3/w4xXDSaUO702Vl4/O8N22NreRaG52LfOpU7M/j0Eo3EdZOm15+JU93PSXjWxs6eGUmhK+f9VCTqkpzXVpIlLARhruGvpxgjwew2UL6vjzF8/nBx9ZRHtvnCt++Dd+0zRIv6iIyEmmcH+TPB7De06v449feCtLplbwpXvXcMOvV7Nudye52isSEVG3TBal0pabH9/ID5/cRCptmVZVxHsW1HLtW6fn9iJkIlIw1OeeQ+29cf68bi9/XLOH5za3UV0S5FvvPY2L5urWeiLy5ijcx4g1uzr40r1reHVvN5eeVsPMiSXEk2mstZwzs4rzZlZplI2IjJjCfQyJJ9Pc8tRmfvTUJuLJNIHMNWriqTSTSoO8f3EDVy5uYObE4hxXKiJjncJ9DEqlLR4DxhhiyRRPbGjh3pW7eOr1VlJpy+kNZbx/cQNXLKyjPDKCU51FZNxRuOeRlu4oD67eze9eambDni4CPg+XzK/hqjMbWTp9gi5zICKHKNzz1PrdXfz6xR3ct6qZ7miSU2pKuH7ZLN41rwaP+uZFxr2shbsx5g7gMqDFWjv/ONOdCTwPXGWtvXe4GSvcjy+aSPGHl3dzy1Ob2dLWyyk1JZw9bQLd0STdsSTVJUEunDORc2ZUUhTUxT1Fxotshvv5QA9w11DhbozxAo8BUeAOhXv2pNKWh9a4kN/TGaUk5KM46GNnex+98RQBr4fZNcWUBP2UhHxMqYxwxcJ65tWVqjtHpABltVvGGDMVeOg44f5FIAGcmZlO4T7K4sk0L25r58lXW9jc2kNPLEl3NMmW1l7iqTSzJhbzttnVh+4eVRHx8/7FDVSXZPGGDiJy0p20m3UYY+qB9wEX4sJdToKAz8O5M6s4d+aRl3vt7Evw0Nrd/P6lZu5avv3Q8/Fkmu89+jpXLKzjqrMaqYj48Xs9eD0Gn9fg83gI+jzq4hEpENn4S/4+8GVrbXq4bgBjzHXAdQCNjY1ZmLUcrSzi5+qzp3D12VOOeH5rWy8/+9tWftu0i9+u3DXk++vLwyxoKOO0hjIWTi7n9IZyBb5IHnrT3TLGmK3AwVSvAvqA66y19x/vM9UtkxsdfXGe37yfWDJNMm1Jpty/qbSlJ5Zkw54u1jZ3sn1/HwAeA6fUlPLOeZN4/6IGGivHwDXBRcaxk9YtY62dNmCmd+I2AscNdsmd8kiAS06rHXa6jr44q3Z2sGr7AZZvbeemxzfy/b9sZMmUCmrLwySSaRKpNCG/l7KIn7Kwn6XTKzl/1pG3H4wmUiRSaUpCunCayMk0bLgbY+4BLgCqjDG7gK8DfgBr7a2jWp3kTHkkwIVzJnLhnIkA7O7o5/7VzfxxzR5eae7E7zX4vR76Eyk6+xJ09ie45anNzK8v5bMXzCQS9PHAqmb+vG4vvfEUdWUh5tSUUFMWIpW2JFOW0rCft86qYul0DecUyTadxCRZEU+muX9VM7c8vZmtbb0AlIR8vPu0WiZPiPD6vm5e29tNW08cv9fg9Rj298TpT6Twew2LGitYUF/G/PoyGirC7OmMsvNAH23dccojfiYUBYgEvGxt6+W1vd00d/Sz7JSJXLN0ChNLQzleepGTR2eoSk6k0pbHN+wjbeGCOdWE/N4hp40lU6zcdoCnX29l+dZ2Xt3TRSyZPmKaSMBLXzx16LHHwLSqIiqLgry4vR2fx3Dx/FqmVkbcyB+PIeT3UhT0URT0Mb2qiFNqSvB5PaTSlqZt7fx53T62tvXQ0Z+gsy/BpNIQly+s49L5tZRF1H0kY5vCXfJOMpVmU2sPezqi1JaHmFwRoSjoI55Mc6AvTnc0SUNF+NAGY1tbL3c9v53fvbSL7miC9BD/lUN+D3NrS9m+v4/9vXECPg+zJhZTEQlQFvGzYXcXW9p6CXg9nDVtAvPqSplbV8qM6mImlgapLArSn0ixYst+nt3Uxo79fcycVMypNaXMmuQ+5+DJZQAH/6SGu1xEc0c/6bSluiR43I2gyEAKdxl30mlLMm2JJlP0xVJ0RxNs2NvN6h0drG3uYFJpiEvm13LBnOoj+vittaxt7uT+VbtZsXU/r+/rJpE6/HdxMKPTFoI+D40TImzf30c8lT66hCNURPxUlwSZWBJiUWM5b5lRyWn1ZTz1Wit3L9/Oiq3th6YtCfmoLglSXRykuiTIgoYy3r2gjvry8LDL/Nzm/bR0R3nH3ElDHrhu743z4rZ2Fk0uVzdWnlO4i5ygeDLN5tYetrX10tYTo7UnDsDS6RNY3FhByO8lkXLTbGntpas/QVc0QU8shQE8xpCylgO9cVq6ozR39LN+d9cRexaTJ4S56sxGqouDtHRHaemO0dYTo607zt6uKDva3VDURY3lzJlUQm88RW8sScjvYUplEVMrI+zuiHLvyl00d/QDEPZ7uWxBLZcvrGNyRYRJpSH298a4/a9b+dWLO4gm3MZofn3EpcY5AAAH30lEQVQpZ02tpKU7yqaWHna29zF5QoS5taWcWlvKzInFTKsqoqEiTGtPjFf3drNxXzfVJUEWN1bQOMENh23vjbO1rZdk2lJVHKCyKIgx0NGXoKM/QdjvZebEYt2MJssU7iJjSHc0wYvb2lm9o4PFUyo4f1b1cbtttu/v5aE1e3h47R7aemIUBXyEM8cfdrb3kUxbjIHzZlbxoSWTqSsP89umnTz48u4jjlEA+L2G9y6s54qF9by8q4MnXm3h5Z0d1JWHmTWxmIaKMDva+1i/p4t9XbFD7zPmcBfTQJVFAVLW0tGXGHa5w34vp9WX0VgZIZlKk0hZSkI+3jWvhnNnVhHweQ4de1m/p4ug30tx0EvQ56WzP8GBvjgdfQl6Ykl6Y0niyTSzJ5Vw5tQJLGosx+/10B11o7UOHkPp7E8we1IJp9aWHBqWa61lU0sPAZ/bOA7UH0/R1hOjPOKnOOjDGIO1lngqTTxzDMiYw8dz3qiW7igvbG1namVRVq75pHAXKVDJVJrdHVGCfg+Tjupi6YklWbXjAPu6YuzripJOWz6wpIHasiO7d6y1g4aMa427PZId7X1MLAkyp6aUWROL2dsV5aUdB1i9owO/z8P0qiJmVBfj93rY3xtjf08ci+uOKo/46exP8PLOTlbv7GBvZ5SAz4Pfa2jpjtEdTVIe8XNKTQmrd3Yc2qsYTNDnoSTkIxLw4fMYtu7vxdqhNz4HzZlUwhWL6uiNJXlk7V62ZEZxnd5QxuUL6ykJ+nh0/T6e3dR6aP5ejyHo8xBNpAY9hhMJeN2xmrCftHUn/3k9hnNnVnHpabUsmlxOVzTBqh0dvLitnadfb2Xd7q5D768vD3PRqRN576J6FjVWDF38cSjcRWRMiiVT/PX1Nv6wZjebWno4c+oE3jqrisWNFSTSaXpjKaKJFGVhPxWRAOHAka3lrmiCldsP8PLODjzGUBb2Uxr2UR4OHGp9L9/azv2rmlm5/QBej+Et0yu5eH4N0USK+1c380qzC9y6shDvmDuJU2tL6Y4m6eiPE02kCfu9hAPeQ7fEtFgSKdfV1t4Xp6s/gce46zJ1R5Os2NJOPJWmNOSjK5oE3IbijMYK3janmnNmVLKxpYdH1+3jrxtb+dTbZvDP75h9Qt+fwl1Exr3dHf2E/V4qio68beXm1h5iifQRXTdvRlc0wRMbWnhucxtTKos4Y0oFCxrKiASOPTmvP54inkyf8LBbhbuISAEaabh7TkYxIiJycincRUQKkMJdRKQAKdxFRAqQwl1EpAAp3EVECpDCXUSkACncRUQKUM5OYjLGtALbT/DtVUBbFsvJF+NxucfjMsP4XO7xuMzwxpd7irW2eriJchbub4YxpmkkZ2gVmvG43ONxmWF8Lvd4XGYYveVWt4yISAFSuIuIFKB8Dffbcl1AjozH5R6Pywzjc7nH4zLDKC13Xva5i4jI8eVry11ERI4j78LdGHOxMeY1Y8wmY8xXcl3PaDDGTDbGPGmMWW+MWWeMuT7z/ARjzGPGmI2Zf0/sPl1jnDHGa4xZZYx5KPN4mjFmRWad/9oYExjuM/KJMabcGHOvMeZVY8wGY8xbxsO6NsbckPn//Yox5h5jTKgQ17Ux5g5jTIsx5pUBzw26fo1zc2b51xhjFp/ofPMq3I0xXuBHwCXAXOAjxpi5ua1qVCSBf7HWzgWWAp/NLOdXgMettbOAxzOPC9H1wIYBj/8f8J/W2pnAAeDanFQ1em4C/mStPQU4HbfsBb2ujTH1wBeAJdba+YAXuIrCXNd3Ahcf9dxQ6/cSYFbm5zrglhOdaV6FO3AWsMlau8VaGwd+BVyR45qyzlq7x1r7Uub3btwfez1uWX+emeznwHtzU+HoMcY0AO8Gbs88NsDbgXszkxTUchtjyoDzgZ8CWGvj1toOxsG6BnxA2BjjAyLAHgpwXVtrnwHaj3p6qPV7BXCXdZYD5caY2hOZb76Fez2wc8DjXZnnCpYxZiqwCFgBTLLW7sm8tBeYlKOyRtP3gS8B6czjSqDDWpvMPC60dT4NaAV+lumKut0YU0SBr2trbTPwXWAHLtQ7gZUU9roeaKj1m7WMy7dwH1eMMcXA74AvWmu7Br5m3TCnghrqZIy5DGix1q7MdS0nkQ9YDNxirV0E9HJUF0yBrusKXCt1GlAHFHFs18W4MFrrN9/CvRmYPOBxQ+a5gmOM8eOC/RfW2vsyT+87uIuW+bclV/WNknOBy40x23Bdbm/H9UeXZ3bdofDW+S5gl7V2RebxvbiwL/R1fRGw1Vrbaq1NAPfh1n8hr+uBhlq/Wcu4fAv3F4FZmSPqAdwBmAdzXFPWZfqZfwpssNbeOOClB4G/y/z+d8ADJ7u20WSt/aq1tsFaOxW3bp+w1l4NPAl8IDNZQS23tXYvsNMYMyfz1DJgPQW+rnHdMUuNMZHM//eDy12w6/ooQ63fB4GPZ0bNLAU6B3TfvDHW2rz6AS4FXgc2A/8z1/WM0jKeh9tNWwOszvxciut/fhzYCPwFmJDrWkfxO7gAeCjz+3TgBWAT8FsgmOv6srysC4GmzPq+H6gYD+sa+AbwKvAK8N9AsBDXNXAP7rhCArendu1Q6xcwuBGBm4G1uNFEJzRfnaEqIlKA8q1bRkRERkDhLiJSgBTuIiIFSOEuIlKAFO4iIgVI4S4iUoAU7iIiBUjhLiJSgP4/i7KWKaNSguAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### GRU\n",
    "\n",
    "hidden_size = 400\n",
    "learning_rate = 0.003\n",
    "\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=\"rnn\", n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')\n",
    "\n",
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 epochs...\n",
      "[0m 37s (50 1%) train loss: 2.0647, test_loss: 2.0756]\n",
      "What from the hith there come bere greatiend, sors, many afone\n",
      "To so, as ue wort you heart ming me the \n",
      "\n",
      "[1m 14s (100 2%) train loss: 1.8467, test_loss: 1.8766]\n",
      "What preir\n",
      "in wall must of that his\n",
      "menter you the spover fry firth to will so the not of the with a s \n",
      "\n",
      "[1m 51s (150 3%) train loss: 1.7059, test_loss: 1.7423]\n",
      "Who ejendes a hell but they you for if, holl sprest own be they have death:\n",
      "Me mode to to I have bold  \n",
      "\n",
      "[2m 29s (200 4%) train loss: 1.6332, test_loss: 1.6622]\n",
      "Who shall may came so breatid.\n",
      "\n",
      "LONINIUS:\n",
      "As, an underord and lave their to the tongue.\n",
      "\n",
      "JULIA:\n",
      "I will \n",
      "\n",
      "[3m 6s (250 5%) train loss: 1.5637, test_loss: 1.5967]\n",
      "Who, marry remian duke you, strange me: and my mother:\n",
      "And keep to affess of the Dare you.\n",
      "\n",
      "FORD:\n",
      "What \n",
      "\n",
      "[3m 43s (300 6%) train loss: 1.5238, test_loss: 1.5654]\n",
      "Where die of the rake, sir.\n",
      "'Tis think I'll give you stands of\n",
      "like her stones, to rescands free secur \n",
      "\n",
      "[4m 20s (350 7%) train loss: 1.4732, test_loss: 1.5284]\n",
      "Who shall say their fines of he will tell me, where is the Thicklors and in the world do do not till m \n",
      "\n",
      "[4m 58s (400 8%) train loss: 1.4781, test_loss: 1.5364]\n",
      "Where as my heart\n",
      "The polids: but my house.\n",
      "I know no matter.\n",
      "'Done, master walk best ladies.\n",
      "\n",
      "CLISDO: \n",
      "\n",
      "[5m 35s (450 9%) train loss: 1.4382, test_loss: 1.5217]\n",
      "Who doth disgraced\n",
      "him, when his joy, sir, and they shall be not your humbly calformed made what may b \n",
      "\n",
      "[6m 12s (500 10%) train loss: 1.4031, test_loss: 1.4981]\n",
      "Where is a vilely that hath the pity of him.\n",
      "\n",
      "HAMLET:\n",
      "O, I will offended. Why, the Caries\n",
      "And look by  \n",
      "\n",
      "[6m 49s (550 11%) train loss: 1.4116, test_loss: 1.4891]\n",
      "What shape thee, worthy their old the bore of this bell the truth. What's the\n",
      "queen, good with, why, c \n",
      "\n",
      "[7m 26s (600 12%) train loss: 1.3950, test_loss: 1.5530]\n",
      "What ne'er was the gods,\n",
      "Let's same to a little doward of mine eyes for you!\n",
      "\n",
      "HORATIO:\n",
      "So, O, thou has \n",
      "\n",
      "[8m 3s (650 13%) train loss: 1.3924, test_loss: 1.5087]\n",
      "What we may be so?\n",
      "\n",
      "SEBELON:\n",
      "My date\n",
      "To sovereign.\n",
      "\n",
      "FALSTAFF:\n",
      "Tut, well, and my cross of your wife her \n",
      "\n",
      "[8m 40s (700 14%) train loss: 1.3643, test_loss: 1.5081]\n",
      "What for her high resolution, their melanchus,\n",
      "Commend your father,\n",
      "Which wrought, that doth loose and \n",
      "\n",
      "[9m 17s (750 15%) train loss: 1.3697, test_loss: 1.4549]\n",
      "What cannot have follow without my lord; which part. Is therefore we will stay'd her fair loss is char \n",
      "\n",
      "[9m 54s (800 16%) train loss: 1.3528, test_loss: 1.5005]\n",
      "Who evil and at my father\n",
      "Than he was the word mark? hail, methinks a soldiers, or all touchst thou a  \n",
      "\n",
      "[10m 31s (850 17%) train loss: 1.3665, test_loss: 1.4947]\n",
      "Who is villain, my lord, I say;\n",
      "Give him the late:\n",
      "As if thou dost with your prison of our alliant and \n",
      "\n",
      "[11m 8s (900 18%) train loss: 1.3599, test_loss: 1.4821]\n",
      "What art thou, fellow cause to confess I do not the rest of his father such a word of Lord have nothin \n",
      "\n",
      "[11m 45s (950 19%) train loss: 1.3443, test_loss: 1.4414]\n",
      "Why though my will.--\n",
      "Signior Lucius, he is heart and spies all him as thou ready in that chokes with  \n",
      "\n",
      "[12m 22s (1000 20%) train loss: 1.3532, test_loss: 1.4420]\n",
      "Wherefore comes the pipe\n",
      "That I\n",
      "will not yet an earthly brought growns, there is been give your world  \n",
      "\n",
      "[13m 0s (1050 21%) train loss: 1.3237, test_loss: 1.4651]\n",
      "Which mark me of him shall in his friend you means, bear the stringled for the prince, how more on the \n",
      "\n",
      "[13m 37s (1100 22%) train loss: 1.3248, test_loss: 1.4506]\n",
      "What saying one every court:\n",
      "Nor sir; thou shalt weep it.\n",
      "\n",
      "CANTERIUS:\n",
      "Ay, sure, brother, I will be rea \n",
      "\n",
      "[14m 14s (1150 23%) train loss: 1.3240, test_loss: 1.4635]\n",
      "What tire to try\n",
      "Is yet I shall not little:\n",
      "But if you shall be rides of action; never watch and many  \n",
      "\n",
      "[14m 51s (1200 24%) train loss: 1.3234, test_loss: 1.4383]\n",
      "What thy friends,\n",
      "Should call to be sufferance to religious arming.\n",
      "\n",
      "GLOUCESTER:\n",
      "Not such a Christians \n",
      "\n",
      "[15m 28s (1250 25%) train loss: 1.3369, test_loss: 1.4419]\n",
      "What say your children, did the tears: and there will in the great persuade speak.\n",
      "\n",
      "KING CLAUDIUS:\n",
      "Wha \n",
      "\n",
      "[16m 5s (1300 26%) train loss: 1.3243, test_loss: 1.4507]\n",
      "Which so\n",
      "thou comes medvice and mine eyes chaste in these company; and follows heavens with a will was \n",
      "\n",
      "[16m 42s (1350 27%) train loss: 1.3511, test_loss: 1.4314]\n",
      "What have a braver with an affairs and his power, and throw is as I did ta'en so hardle and manner of  \n",
      "\n",
      "[17m 19s (1400 28%) train loss: 1.3043, test_loss: 1.4199]\n",
      "What are you, or to his house\n",
      "From the crown and moons, and\n",
      "so so, raised with a\n",
      "poor son,\n",
      "That wear t \n",
      "\n",
      "[17m 56s (1450 28%) train loss: 1.3368, test_loss: 1.4552]\n",
      "Where art not of me, as I am a queen: they there; but, I shall be like water,\n",
      "She wakest not dogs, to  \n",
      "\n",
      "[18m 33s (1500 30%) train loss: 1.3157, test_loss: 1.4623]\n",
      "What may sleep, never born by her things:\n",
      "Them weep,\n",
      "To go with your housonact;\n",
      "Gentlemen.\n",
      "\n",
      "SIR WALTER \n",
      "\n",
      "[19m 10s (1550 31%) train loss: 1.3146, test_loss: 1.4402]\n",
      "What so my heart to the fellows to, that the Hollands miser land. Peach?\n",
      "I do not grief which hath so  \n",
      "\n",
      "[19m 48s (1600 32%) train loss: 1.3264, test_loss: 1.4901]\n",
      "What she hath puts as I am sorrow\n",
      "In preposterously.\n",
      "\n",
      "POINS:\n",
      "I hope, all this sin and darkenn, so incr \n",
      "\n",
      "[20m 25s (1650 33%) train loss: 1.3347, test_loss: 1.4671]\n",
      "When let poison choices of the king,\n",
      "Whose man or deceived to hear him for thee,\n",
      "How comes the need to \n",
      "\n",
      "[21m 2s (1700 34%) train loss: 1.3197, test_loss: 1.4640]\n",
      "What says it disciple, and beats, whose hand when thou wilt not give them used to make me nothing.\n",
      "\n",
      "KI \n",
      "\n",
      "[21m 39s (1750 35%) train loss: 1.3236, test_loss: 1.4337]\n",
      "What is your grace to shame the charge to the crown?\n",
      "\n",
      "PAGE:\n",
      "O, my master forser to be said\n",
      "The wineral \n",
      "\n",
      "[22m 16s (1800 36%) train loss: 1.3059, test_loss: 1.4659]\n",
      "Why dost thou can be cut on the fair lady, there is made a captain of your ghost to stay and the yoke; \n",
      "\n",
      "[22m 53s (1850 37%) train loss: 1.3135, test_loss: 1.4254]\n",
      "Where is no boy;\n",
      "For when myself.\n",
      "\n",
      "ESCALUS:\n",
      "This beggar'd on the kingdors in the unloomed betwixt my f \n",
      "\n",
      "[23m 30s (1900 38%) train loss: 1.2967, test_loss: 1.4160]\n",
      "Why, he that seement's an ended,\n",
      "Our honour come from your own violence of them home and fruit of life \n",
      "\n",
      "[24m 8s (1950 39%) train loss: 1.3059, test_loss: 1.4657]\n",
      "What! therefore I have sick not his faith with such with your widow with any thing shall be like a man \n",
      "\n",
      "[24m 45s (2000 40%) train loss: 1.3020, test_loss: 1.4383]\n",
      "Where I stand his head!\n",
      "\n",
      "BRUTUS:\n",
      "I would the manner: his mad and mean to have harsh and unworthy valia \n",
      "\n",
      "[25m 22s (2050 41%) train loss: 1.2836, test_loss: 1.4352]\n",
      "What shortly speak to Marina, a jest is my word; he carries us out, in the desirity is a need shall ha \n",
      "\n",
      "[25m 59s (2100 42%) train loss: 1.3149, test_loss: 1.4174]\n",
      "What you might appear the night of honour may king's sword\n",
      "To confess, think you must be.\n",
      "\n",
      "First Say I \n",
      "\n",
      "[26m 37s (2150 43%) train loss: 1.2915, test_loss: 1.4732]\n",
      "Whates it charged to heaf.\n",
      "\n",
      "ORLEANS:\n",
      "And, by me his cities and chance.\n",
      "\n",
      "TAMORA:\n",
      "My lord, I must be cer \n",
      "\n",
      "[27m 14s (2200 44%) train loss: 1.3116, test_loss: 1.4161]\n",
      "Why, he hath no discourse and market upon the like officer: call me well.'\n",
      "\n",
      "MARCUS ANDRONICUS:\n",
      "Uncurse \n",
      "\n",
      "[27m 51s (2250 45%) train loss: 1.3007, test_loss: 1.4235]\n",
      "Why dun, his body to a sister shall not grieves you that show'd on his sight\n",
      "They will follow me:\n",
      "But  \n",
      "\n",
      "[28m 28s (2300 46%) train loss: 1.3014, test_loss: 1.4214]\n",
      "What would you proceeding 'tis so:\n",
      "I thank you, poant it be my humblest lips\n",
      "To give my court!\n",
      "\n",
      "BAPTIS \n",
      "\n",
      "[29m 6s (2350 47%) train loss: 1.3091, test_loss: 1.4401]\n",
      "Who should see with your head brought the cradle:\n",
      "Hence have with her advice,\n",
      "Old there Exeter,\n",
      "Rendal \n",
      "\n",
      "[29m 43s (2400 48%) train loss: 1.2832, test_loss: 1.4244]\n",
      "Why thou art so.\n",
      "\n",
      "KATHARINE:\n",
      "What ne'er a particular parts of power,\n",
      "Than I my son,' that know, out of \n",
      "\n",
      "[30m 20s (2450 49%) train loss: 1.2816, test_loss: 1.4272]\n",
      "What if you rather have patient. But thou wilt man through the good sup reasons you do mouse!\n",
      "For I ha \n",
      "\n",
      "[30m 57s (2500 50%) train loss: 1.3073, test_loss: 1.4623]\n",
      "Whither any montus, and the sky where I will bring me of France, which comes so black of a lodging dea \n",
      "\n",
      "[31m 34s (2550 51%) train loss: 1.2896, test_loss: 1.4497]\n",
      "Which sweet through?\n",
      "\n",
      "SHYLOCK:\n",
      "We shall see\n",
      "thee, for her duke that you thine art\n",
      "For a wretched month \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32m 11s (2600 52%) train loss: 1.2850, test_loss: 1.4216]\n",
      "What say you the man bring our constable;\n",
      "I am sure;\n",
      "And, to speak and be so loathsome squares and the \n",
      "\n",
      "[32m 49s (2650 53%) train loss: 1.2843, test_loss: 1.4260]\n",
      "Which 'there to invite our death of it,\n",
      "When he woods ready,\n",
      "His worthy of his grief, I should not nig \n",
      "\n",
      "[33m 26s (2700 54%) train loss: 1.2882, test_loss: 1.3962]\n",
      "What is mine, I never shun him comfort.\n",
      "\n",
      "CASCA:\n",
      "'Tis foul is too ladies that I was\n",
      "A traitival of his\n",
      " \n",
      "\n",
      "[34m 3s (2750 55%) train loss: 1.2750, test_loss: 1.4206]\n",
      "Who loves away.\n",
      "\n",
      "First Servingman:\n",
      "What is your guilty;\n",
      "You do weep.\n",
      "\n",
      "CLARENCE:\n",
      "Be between your knee D \n",
      "\n",
      "[34m 40s (2800 56%) train loss: 1.3067, test_loss: 1.4621]\n",
      "What I know not of the maiden bawd, let thee another superse, theiring wanteth into thy mind in his st \n",
      "\n",
      "[35m 18s (2850 56%) train loss: 1.3061, test_loss: 1.4228]\n",
      "What comest before I'll come.\n",
      "\n",
      "PORTIA:\n",
      "Now, brother, will all that thou art not much what till he sast \n",
      "\n",
      "[35m 55s (2900 57%) train loss: 1.2834, test_loss: 1.4390]\n",
      "Why, therefore, Percy, and your mother, with the morning,\n",
      "I'll keep no more.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "With thi \n",
      "\n",
      "[36m 32s (2950 59%) train loss: 1.2787, test_loss: 1.4562]\n",
      "Why should I had been the house of man's means, and your obedient person, and the gifts that he is a k \n",
      "\n",
      "[37m 9s (3000 60%) train loss: 1.3012, test_loss: 1.4274]\n",
      "Where hast thou he the answer\n",
      "That my husband?\n",
      "\n",
      "PRINCE HENRY:\n",
      "There's great traitors did not frame the \n",
      "\n",
      "[37m 46s (3050 61%) train loss: 1.3033, test_loss: 1.4377]\n",
      "Whose strange sweet rash and liveries his eye and speak.\n",
      "\n",
      "HOLOFERNES:\n",
      "Now, can fail from the toppines! \n",
      "\n",
      "[38m 23s (3100 62%) train loss: 1.2989, test_loss: 1.4325]\n",
      "What, poor maid with him\n",
      "Then can incensed the royal welks,\n",
      "That he speaks in the practise of your jus \n",
      "\n",
      "[39m 0s (3150 63%) train loss: 1.2879, test_loss: 1.4318]\n",
      "What is the better.\n",
      "\n",
      "BEATRICE:\n",
      "My gracious willing: but I have been to the field of it,\n",
      "That, my lord. \n",
      "\n",
      "[39m 37s (3200 64%) train loss: 1.2849, test_loss: 1.4484]\n",
      "Where thou shalt look on, as I stand your credit, my lord,\n",
      "Of the belly that have bought her, how long \n",
      "\n",
      "[40m 14s (3250 65%) train loss: 1.2800, test_loss: 1.4076]\n",
      "While honourable bear-law, they find him on\n",
      "the one\n",
      "And he fail from her, and our goodly lap--\n",
      "Their b \n",
      "\n",
      "[40m 51s (3300 66%) train loss: 1.2845, test_loss: 1.4593]\n",
      "What news by the morning.\n",
      "For shame, for this jid! It may stand small rub and of Philosus in birds o'  \n",
      "\n",
      "[41m 28s (3350 67%) train loss: 1.2978, test_loss: 1.4243]\n",
      "Which I was the day, in chest hour boy, sir: take a man; but I have entertain our nature hath he appea \n",
      "\n",
      "[42m 6s (3400 68%) train loss: 1.2959, test_loss: 1.4342]\n",
      "Whose earth\n",
      "Were all the baskets,\n",
      "Looks crow'd and death now as again in many dog's will I forbear my  \n",
      "\n",
      "[42m 43s (3450 69%) train loss: 1.2975, test_loss: 1.4455]\n",
      "Wherein shall we to the matter.\n",
      "Here is a virtue reading good woman's faced gracious curtains to our l \n",
      "\n",
      "[43m 21s (3500 70%) train loss: 1.2824, test_loss: 1.4056]\n",
      "Which where dinner mend here.\n",
      "\n",
      "TROILUS:\n",
      "Why, faith, I say, away; but all she is an hour? And there is  \n",
      "\n",
      "[44m 0s (3550 71%) train loss: 1.2858, test_loss: 1.4373]\n",
      "What They--I have been a man flats me to smiles.\n",
      "\n",
      "ROSALINE:\n",
      "Your counsel;\n",
      "A persons of her way, the cr \n",
      "\n",
      "[44m 40s (3600 72%) train loss: 1.3014, test_loss: 1.4263]\n",
      "Who, no, thus, my love, as the hungry welcome kindness followed and go standing of this cares again; a \n",
      "\n",
      "[45m 20s (3650 73%) train loss: 1.2682, test_loss: 1.4258]\n",
      "Who corns of this?\n",
      "\n",
      "MACBETH:\n",
      "And yet you cannot be supposed and dreamantised with very gentlemen;\n",
      "Thus \n",
      "\n",
      "[45m 59s (3700 74%) train loss: 1.2961, test_loss: 1.4857]\n",
      "Where thou wilt hear the rade of that reputation with him, and the name of golden breath of right blos \n",
      "\n",
      "[46m 39s (3750 75%) train loss: 1.3072, test_loss: 1.4639]\n",
      "Why, that of your fortuce can mine and set my wife and vexto my good master;\n",
      "And what should be; 'tis  \n",
      "\n",
      "[47m 18s (3800 76%) train loss: 1.2882, test_loss: 1.4385]\n",
      "Why, sir, you would have won either sun; I cried Leonatus, every man of Naples,\n",
      "I seem three years: th \n",
      "\n",
      "[47m 58s (3850 77%) train loss: 1.2827, test_loss: 1.3997]\n",
      "Where's more than the sun.\n",
      "\n",
      "CLEOPATRA:\n",
      "Pray, let\n",
      "In good to my lord hath done presently and his daught \n",
      "\n",
      "[49m 0s (3900 78%) train loss: 1.2857, test_loss: 1.4614]\n",
      "Where was a man to any\n",
      "of our show of fire the hard-state at most sound tidings; we challenge their bo \n",
      "\n",
      "[50m 0s (3950 79%) train loss: 1.2875, test_loss: 1.4306]\n",
      "What is all course is so.\n",
      "\n",
      "EDGAR:\n",
      "The fire of Nad, yea. What, how a wolf hath not rating to me.\n",
      "Then n \n",
      "\n",
      "[51m 2s (4000 80%) train loss: 1.2634, test_loss: 1.4441]\n",
      "Where have we so.\n",
      "\n",
      "THERSITES:\n",
      "The rascally and entertain thee to that; and to end Servant:\n",
      "My love, th \n",
      "\n",
      "[52m 9s (4050 81%) train loss: 1.2827, test_loss: 1.4375]\n",
      "Why the great press in the more terms, will I see thee by him that is open, sir, but who can whipp'd m \n",
      "\n",
      "[53m 20s (4100 82%) train loss: 1.3025, test_loss: 1.4768]\n",
      "Why have have the first-groan,\n",
      "Or if thou wilt speak\n",
      "Of thine admicanes and with the great hath left t \n",
      "\n",
      "[54m 33s (4150 83%) train loss: 1.3046, test_loss: 1.4424]\n",
      "What do you die.\n",
      "\n",
      "EMILIA:\n",
      "The tales to Falstaff, and he seems he must be strange of the several salven \n",
      "\n",
      "[55m 40s (4200 84%) train loss: 1.3091, test_loss: 1.4457]\n",
      "Whither will I be thy Earsties of an engaged and lie to your bounties, his bloody dead gave me your ar \n",
      "\n",
      "[56m 38s (4250 85%) train loss: 1.3006, test_loss: 1.4396]\n",
      "Why art thou now are the world at the\n",
      "wallen for this stew.\n",
      "\n",
      "OSWALD:\n",
      "Hear you, go to my father was set \n",
      "\n",
      "[57m 37s (4300 86%) train loss: 1.2957, test_loss: 1.4218]\n",
      "What end her that love in a sport,\n",
      "Received star that did her breath.\n",
      "\n",
      "CASSIO:\n",
      "I do not speak to live  \n",
      "\n",
      "[58m 36s (4350 87%) train loss: 1.2832, test_loss: 1.4581]\n",
      "What, look you me too wace to Frenches my son,\n",
      "I will not have save be the vassal; I do see him to The \n",
      "\n",
      "[59m 37s (4400 88%) train loss: 1.2806, test_loss: 1.4575]\n",
      "Why, good night; 'tis to be as author thinks; and it is such a foot and Diomed's sword and your fair f \n",
      "\n",
      "[60m 39s (4450 89%) train loss: 1.2917, test_loss: 1.4218]\n",
      "Whose pace of my childrens were the field be but there and by the better seeming and sleep: hence!\n",
      "Do  \n",
      "\n",
      "[61m 39s (4500 90%) train loss: 1.2748, test_loss: 1.4433]\n",
      "What is your father base richly.\n",
      "\n",
      "ANTONIO:\n",
      "I am not understand thee this\n",
      "to the moon of Buckold title  \n",
      "\n",
      "[62m 41s (4550 91%) train loss: 1.2852, test_loss: 1.4080]\n",
      "What shall they be with an hour has it, with him by him? what would she is to fight his sorrow\n",
      "And ass \n",
      "\n",
      "[63m 45s (4600 92%) train loss: 1.2988, test_loss: 1.4330]\n",
      "Which on, as the doors directly consent be white, and gives a hobbers ditch and prayer and livery; and \n",
      "\n",
      "[64m 50s (4650 93%) train loss: 1.2878, test_loss: 1.4391]\n",
      "What wouldst thou lead the strong to us.\n",
      "\n",
      "ROSALIND:\n",
      "Do your power\n",
      "Will have\n",
      "here, and I will. In each  \n",
      "\n",
      "[65m 56s (4700 94%) train loss: 1.3066, test_loss: 1.4706]\n",
      "Which doth know,\n",
      "And have had no puttent forth\n",
      "For out.\n",
      "\n",
      "EMILIA:\n",
      "There's the fronton be the grave for  \n",
      "\n",
      "[66m 58s (4750 95%) train loss: 1.3006, test_loss: 1.4326]\n",
      "What are your soul's force; it is there with my love.\n",
      "\n",
      "FLAVIUS:\n",
      "I am not like a horse all in Rome, I'l \n",
      "\n",
      "[67m 57s (4800 96%) train loss: 1.2816, test_loss: 1.4506]\n",
      "Whoily can do well.\n",
      "\n",
      "BERNARDO:\n",
      "Your ship preys all\n",
      "things\n",
      "That ward me in\n",
      "your highness' spirit of one \n",
      "\n",
      "[68m 36s (4850 97%) train loss: 1.2744, test_loss: 1.4345]\n",
      "When we are then loved the news of mind and\n",
      "Worthy of minds and maidenhood\n",
      "And the strong'st revenged. \n",
      "\n",
      "[69m 13s (4900 98%) train loss: 1.3097, test_loss: 1.4465]\n",
      "Who let the jewel and myself to die in words on thy heart Antony was both rouse?\n",
      "\n",
      "MACBETH:\n",
      "I did us, a \n",
      "\n",
      "[69m 50s (4950 99%) train loss: 1.2844, test_loss: 1.4372]\n",
      "What's the ingration perseverance that I mayst not leave him;\n",
      "For that we have the truth and resolved  \n",
      "\n",
      "[70m 27s (5000 100%) train loss: 1.2785, test_loss: 1.4443]\n",
      "What fool'st thou of his lady's blood were bound,\n",
      "Was not bleeds:\n",
      "Thou seest thou, hardly and I shall  \n",
      "\n",
      "There is here pomp and I was our office,\n",
      "Believe the grace as a little to confess the griefs and command.\n",
      "\n",
      "ALEXAS:\n",
      "The man to the French\n",
      "From her hand as of an executions in my father,\n",
      "Nor entertain'd, get her\n",
      "Since I is to my children, woman, and will be killed to your king call'd to the sceptre,\n",
      "And too well, and she did enforced to them.\n",
      "\n",
      "LEONTES:\n",
      "Or that you have took to let.\n",
      "\n",
      "KING EDWARD IV:\n",
      "If not, my lord; and what he is well. But what a judge of such a careless day, and one gentlewomen,\n",
      "Who should do it: if thou canst find the Juliet, call you now.\n",
      "\n",
      "LUCIUS:\n",
      "Now have a felloons, sir.\n",
      "\n",
      "FORD:\n",
      "Wine me a thing to cast\n",
      "Thy sight.\n",
      "\n",
      "BOULT:\n",
      "Hang heaven no crubs of natural mind, and stand not to obey;\n",
      "That manly too welcome. Welcome, gentle Proteus,\n",
      "Or set your lady, Lady Hermia may be the deven hold it.\n",
      "\n",
      "MISTRESS FORD:\n",
      "For now thou shalt not be at present thence thou deceived in Rome,\n",
      "But that that he was mad.\n",
      "\n",
      "OLIVER:\n",
      "For well.\n",
      "\n",
      "LEONTES:\n",
      "\n",
      "EMILIA:\n",
      "Good Apricy and Trojans;\n",
      "And not the rest\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### RNN\n",
    "n_layers=3\n",
    "\n",
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=\"rnn\", n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')\n",
    "\n",
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
